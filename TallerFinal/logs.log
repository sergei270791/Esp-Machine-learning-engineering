2025-11-16 22:25:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 22:25:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 22:25:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 22:25:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 22:28:22,674:INFO:PyCaret ClassificationExperiment
2025-11-16 22:28:22,674:INFO:Logging name: clf-default-name
2025-11-16 22:28:22,674:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-16 22:28:22,674:INFO:version 3.3.2
2025-11-16 22:28:22,674:INFO:Initializing setup()
2025-11-16 22:28:22,674:INFO:self.USI: 2649
2025-11-16 22:28:22,674:INFO:self._variable_keys: {'fold_groups_param', 'fold_generator', 'memory', 'y', 'fix_imbalance', 'target_param', 'y_train', 'X', 'X_train', 'idx', 'logging_param', 'gpu_param', 'n_jobs_param', 'USI', 'gpu_n_jobs_param', 'html_param', 'pipeline', 'is_multiclass', 'X_test', 'log_plots_param', 'exp_id', 'exp_name_log', 'seed', 'data', '_ml_usecase', '_available_plots', 'fold_shuffle_param', 'y_test'}
2025-11-16 22:28:22,674:INFO:Checking environment
2025-11-16 22:28:22,674:INFO:python_version: 3.11.4
2025-11-16 22:28:22,674:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-16 22:28:22,678:INFO:machine: AMD64
2025-11-16 22:28:22,678:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-16 22:28:22,678:INFO:Memory: svmem(total=8403275776, available=1280585728, percent=84.8, used=7122690048, free=1280585728)
2025-11-16 22:28:22,679:INFO:Physical Core: 4
2025-11-16 22:28:22,679:INFO:Logical Core: 8
2025-11-16 22:28:22,679:INFO:Checking libraries
2025-11-16 22:28:22,679:INFO:System:
2025-11-16 22:28:22,679:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-16 22:28:22,679:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-16 22:28:22,679:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-16 22:28:22,679:INFO:PyCaret required dependencies:
2025-11-16 22:28:23,312:INFO:                 pip: 23.1.2
2025-11-16 22:28:23,312:INFO:          setuptools: 80.9.0
2025-11-16 22:28:23,312:INFO:             pycaret: 3.3.2
2025-11-16 22:28:23,313:INFO:             IPython: 9.6.0
2025-11-16 22:28:23,313:INFO:          ipywidgets: 8.1.7
2025-11-16 22:28:23,314:INFO:                tqdm: 4.67.1
2025-11-16 22:28:23,314:INFO:               numpy: 1.26.4
2025-11-16 22:28:23,314:INFO:              pandas: 2.1.4
2025-11-16 22:28:23,314:INFO:              jinja2: 3.1.6
2025-11-16 22:28:23,314:INFO:               scipy: 1.11.4
2025-11-16 22:28:23,315:INFO:              joblib: 1.3.2
2025-11-16 22:28:23,315:INFO:             sklearn: 1.4.2
2025-11-16 22:28:23,315:INFO:                pyod: 2.0.5
2025-11-16 22:28:23,315:INFO:            imblearn: 0.14.0
2025-11-16 22:28:23,315:INFO:   category_encoders: 2.7.0
2025-11-16 22:28:23,315:INFO:            lightgbm: 4.6.0
2025-11-16 22:28:23,315:INFO:               numba: 0.61.0
2025-11-16 22:28:23,315:INFO:            requests: 2.32.5
2025-11-16 22:28:23,315:INFO:          matplotlib: 3.7.5
2025-11-16 22:28:23,315:INFO:          scikitplot: 0.3.7
2025-11-16 22:28:23,315:INFO:         yellowbrick: 1.5
2025-11-16 22:28:23,315:INFO:              plotly: 5.24.1
2025-11-16 22:28:23,315:INFO:    plotly-resampler: Not installed
2025-11-16 22:28:23,315:INFO:             kaleido: 1.1.0
2025-11-16 22:28:23,319:INFO:           schemdraw: 0.15
2025-11-16 22:28:23,319:INFO:         statsmodels: 0.14.5
2025-11-16 22:28:23,319:INFO:              sktime: 0.26.0
2025-11-16 22:28:23,319:INFO:               tbats: 1.1.3
2025-11-16 22:28:23,319:INFO:            pmdarima: 2.0.4
2025-11-16 22:28:23,319:INFO:              psutil: 7.1.2
2025-11-16 22:28:23,320:INFO:          markupsafe: 3.0.3
2025-11-16 22:28:23,320:INFO:             pickle5: Not installed
2025-11-16 22:28:23,320:INFO:         cloudpickle: 3.1.1
2025-11-16 22:28:23,320:INFO:         deprecation: 2.1.0
2025-11-16 22:28:23,320:INFO:              xxhash: 3.6.0
2025-11-16 22:28:23,320:INFO:           wurlitzer: Not installed
2025-11-16 22:28:23,320:INFO:PyCaret optional dependencies:
2025-11-16 22:28:29,354:INFO:                shap: 0.44.1
2025-11-16 22:28:29,354:INFO:           interpret: 0.7.3
2025-11-16 22:28:29,354:INFO:                umap: 0.5.7
2025-11-16 22:28:29,354:INFO:     ydata_profiling: 4.17.0
2025-11-16 22:28:29,356:INFO:  explainerdashboard: 0.5.1
2025-11-16 22:28:29,356:INFO:             autoviz: Not installed
2025-11-16 22:28:29,356:INFO:           fairlearn: 0.7.0
2025-11-16 22:28:29,356:INFO:          deepchecks: Not installed
2025-11-16 22:28:29,356:INFO:             xgboost: Not installed
2025-11-16 22:28:29,356:INFO:            catboost: Not installed
2025-11-16 22:28:29,356:INFO:              kmodes: Not installed
2025-11-16 22:28:29,360:INFO:             mlxtend: Not installed
2025-11-16 22:28:29,360:INFO:       statsforecast: Not installed
2025-11-16 22:28:29,360:INFO:        tune_sklearn: Not installed
2025-11-16 22:28:29,360:INFO:                 ray: Not installed
2025-11-16 22:28:29,360:INFO:            hyperopt: Not installed
2025-11-16 22:28:29,360:INFO:              optuna: Not installed
2025-11-16 22:28:29,360:INFO:               skopt: Not installed
2025-11-16 22:28:29,360:INFO:              mlflow: 3.5.1
2025-11-16 22:28:29,360:INFO:              gradio: Not installed
2025-11-16 22:28:29,360:INFO:             fastapi: 0.121.0
2025-11-16 22:28:29,360:INFO:             uvicorn: 0.38.0
2025-11-16 22:28:29,360:INFO:              m2cgen: Not installed
2025-11-16 22:28:29,360:INFO:           evidently: Not installed
2025-11-16 22:28:29,360:INFO:               fugue: Not installed
2025-11-16 22:28:29,360:INFO:           streamlit: Not installed
2025-11-16 22:28:29,360:INFO:             prophet: Not installed
2025-11-16 22:28:29,360:INFO:None
2025-11-16 22:28:29,360:INFO:Set up data.
2025-11-16 22:28:29,386:INFO:Set up folding strategy.
2025-11-16 22:28:29,386:INFO:Set up train/test split.
2025-11-16 22:28:29,411:INFO:Set up index.
2025-11-16 22:28:29,411:INFO:Assigning column types.
2025-11-16 22:28:29,419:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-16 22:28:29,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 22:28:29,537:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 22:28:29,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:29,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:29,699:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 22:28:29,702:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 22:28:29,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:29,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:29,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-16 22:28:29,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 22:28:29,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:29,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 22:28:30,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,151:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-16 22:28:30,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:30,526:INFO:Preparing preprocessing pipeline...
2025-11-16 22:28:30,532:INFO:Set up simple imputation.
2025-11-16 22:28:30,536:INFO:Set up encoding of ordinal features.
2025-11-16 22:28:30,539:INFO:Set up encoding of categorical features.
2025-11-16 22:28:30,539:INFO:Set up imbalanced handling.
2025-11-16 22:28:30,539:INFO:Set up feature normalization.
2025-11-16 22:28:30,817:INFO:Finished creating preprocessing pipeline.
2025-11-16 22:28:30,902:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-16 22:28:30,902:INFO:Creating final display dataframe.
2025-11-16 22:28:31,475:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              2649
2025-11-16 22:28:31,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:31,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:31,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:31,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 22:28:31,950:INFO:setup() successfully completed in 9.79s...............
2025-11-16 22:28:43,636:INFO:Initializing compare_models()
2025-11-16 22:28:43,636:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-16 22:28:43,636:INFO:Checking exceptions
2025-11-16 22:28:43,640:INFO:Preparing display monitor
2025-11-16 22:28:43,699:INFO:Initializing Logistic Regression
2025-11-16 22:28:43,699:INFO:Total runtime is 0.0 minutes
2025-11-16 22:28:43,712:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:43,712:INFO:Initializing create_model()
2025-11-16 22:28:43,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:43,714:INFO:Checking exceptions
2025-11-16 22:28:43,714:INFO:Importing libraries
2025-11-16 22:28:43,714:INFO:Copying training dataset
2025-11-16 22:28:43,721:INFO:Defining folds
2025-11-16 22:28:43,721:INFO:Declaring metric variables
2025-11-16 22:28:43,730:INFO:Importing untrained model
2025-11-16 22:28:43,741:INFO:Logistic Regression Imported successfully
2025-11-16 22:28:43,756:INFO:Starting cross validation
2025-11-16 22:28:43,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:28:53,690:INFO:Calculating mean and std
2025-11-16 22:28:53,690:INFO:Creating metrics dataframe
2025-11-16 22:28:53,690:INFO:Uploading results into container
2025-11-16 22:28:53,690:INFO:Uploading model into container now
2025-11-16 22:28:53,690:INFO:_master_model_container: 1
2025-11-16 22:28:53,690:INFO:_display_container: 2
2025-11-16 22:28:53,690:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-16 22:28:53,690:INFO:create_model() successfully completed......................................
2025-11-16 22:28:53,954:INFO:SubProcess create_model() end ==================================
2025-11-16 22:28:53,954:INFO:Creating metrics dataframe
2025-11-16 22:28:54,002:INFO:Initializing K Neighbors Classifier
2025-11-16 22:28:54,002:INFO:Total runtime is 0.17172001202901205 minutes
2025-11-16 22:28:54,020:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:54,020:INFO:Initializing create_model()
2025-11-16 22:28:54,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:54,020:INFO:Checking exceptions
2025-11-16 22:28:54,020:INFO:Importing libraries
2025-11-16 22:28:54,020:INFO:Copying training dataset
2025-11-16 22:28:54,047:INFO:Defining folds
2025-11-16 22:28:54,047:INFO:Declaring metric variables
2025-11-16 22:28:54,068:INFO:Importing untrained model
2025-11-16 22:28:54,087:INFO:K Neighbors Classifier Imported successfully
2025-11-16 22:28:54,125:INFO:Starting cross validation
2025-11-16 22:28:54,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:28:54,784:INFO:Calculating mean and std
2025-11-16 22:28:54,784:INFO:Creating metrics dataframe
2025-11-16 22:28:54,784:INFO:Uploading results into container
2025-11-16 22:28:54,784:INFO:Uploading model into container now
2025-11-16 22:28:54,784:INFO:_master_model_container: 2
2025-11-16 22:28:54,784:INFO:_display_container: 2
2025-11-16 22:28:54,794:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 22:28:54,796:INFO:create_model() successfully completed......................................
2025-11-16 22:28:55,231:INFO:SubProcess create_model() end ==================================
2025-11-16 22:28:55,239:INFO:Creating metrics dataframe
2025-11-16 22:28:55,279:INFO:Initializing Naive Bayes
2025-11-16 22:28:55,279:INFO:Total runtime is 0.19299572706222534 minutes
2025-11-16 22:28:55,297:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:55,297:INFO:Initializing create_model()
2025-11-16 22:28:55,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:55,300:INFO:Checking exceptions
2025-11-16 22:28:55,300:INFO:Importing libraries
2025-11-16 22:28:55,300:INFO:Copying training dataset
2025-11-16 22:28:55,325:INFO:Defining folds
2025-11-16 22:28:55,327:INFO:Declaring metric variables
2025-11-16 22:28:55,352:INFO:Importing untrained model
2025-11-16 22:28:55,368:INFO:Naive Bayes Imported successfully
2025-11-16 22:28:55,408:INFO:Starting cross validation
2025-11-16 22:28:55,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:28:55,948:INFO:Calculating mean and std
2025-11-16 22:28:55,948:INFO:Creating metrics dataframe
2025-11-16 22:28:55,955:INFO:Uploading results into container
2025-11-16 22:28:55,956:INFO:Uploading model into container now
2025-11-16 22:28:55,957:INFO:_master_model_container: 3
2025-11-16 22:28:55,957:INFO:_display_container: 2
2025-11-16 22:28:55,957:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-16 22:28:55,959:INFO:create_model() successfully completed......................................
2025-11-16 22:28:56,297:INFO:SubProcess create_model() end ==================================
2025-11-16 22:28:56,304:INFO:Creating metrics dataframe
2025-11-16 22:28:56,335:INFO:Initializing Decision Tree Classifier
2025-11-16 22:28:56,335:INFO:Total runtime is 0.2105908751487732 minutes
2025-11-16 22:28:56,346:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:56,346:INFO:Initializing create_model()
2025-11-16 22:28:56,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:56,351:INFO:Checking exceptions
2025-11-16 22:28:56,351:INFO:Importing libraries
2025-11-16 22:28:56,352:INFO:Copying training dataset
2025-11-16 22:28:56,369:INFO:Defining folds
2025-11-16 22:28:56,370:INFO:Declaring metric variables
2025-11-16 22:28:56,385:INFO:Importing untrained model
2025-11-16 22:28:56,400:INFO:Decision Tree Classifier Imported successfully
2025-11-16 22:28:56,423:INFO:Starting cross validation
2025-11-16 22:28:56,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:28:56,946:INFO:Calculating mean and std
2025-11-16 22:28:56,947:INFO:Creating metrics dataframe
2025-11-16 22:28:56,951:INFO:Uploading results into container
2025-11-16 22:28:56,952:INFO:Uploading model into container now
2025-11-16 22:28:56,952:INFO:_master_model_container: 4
2025-11-16 22:28:56,952:INFO:_display_container: 2
2025-11-16 22:28:56,955:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-16 22:28:56,957:INFO:create_model() successfully completed......................................
2025-11-16 22:28:57,231:INFO:SubProcess create_model() end ==================================
2025-11-16 22:28:57,231:INFO:Creating metrics dataframe
2025-11-16 22:28:57,261:INFO:Initializing SVM - Linear Kernel
2025-11-16 22:28:57,261:INFO:Total runtime is 0.22603631416956585 minutes
2025-11-16 22:28:57,275:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:57,278:INFO:Initializing create_model()
2025-11-16 22:28:57,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:57,278:INFO:Checking exceptions
2025-11-16 22:28:57,278:INFO:Importing libraries
2025-11-16 22:28:57,278:INFO:Copying training dataset
2025-11-16 22:28:57,302:INFO:Defining folds
2025-11-16 22:28:57,302:INFO:Declaring metric variables
2025-11-16 22:28:57,318:INFO:Importing untrained model
2025-11-16 22:28:57,335:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 22:28:57,367:INFO:Starting cross validation
2025-11-16 22:28:57,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:28:57,878:INFO:Calculating mean and std
2025-11-16 22:28:57,878:INFO:Creating metrics dataframe
2025-11-16 22:28:57,888:INFO:Uploading results into container
2025-11-16 22:28:57,888:INFO:Uploading model into container now
2025-11-16 22:28:57,891:INFO:_master_model_container: 5
2025-11-16 22:28:57,891:INFO:_display_container: 2
2025-11-16 22:28:57,893:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-16 22:28:57,893:INFO:create_model() successfully completed......................................
2025-11-16 22:28:58,195:INFO:SubProcess create_model() end ==================================
2025-11-16 22:28:58,195:INFO:Creating metrics dataframe
2025-11-16 22:28:58,234:INFO:Initializing Ridge Classifier
2025-11-16 22:28:58,234:INFO:Total runtime is 0.24223906993865968 minutes
2025-11-16 22:28:58,247:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:58,247:INFO:Initializing create_model()
2025-11-16 22:28:58,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:58,253:INFO:Checking exceptions
2025-11-16 22:28:58,253:INFO:Importing libraries
2025-11-16 22:28:58,253:INFO:Copying training dataset
2025-11-16 22:28:58,278:INFO:Defining folds
2025-11-16 22:28:58,278:INFO:Declaring metric variables
2025-11-16 22:28:58,298:INFO:Importing untrained model
2025-11-16 22:28:58,319:INFO:Ridge Classifier Imported successfully
2025-11-16 22:28:58,387:INFO:Starting cross validation
2025-11-16 22:28:58,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:28:58,817:INFO:Calculating mean and std
2025-11-16 22:28:58,818:INFO:Creating metrics dataframe
2025-11-16 22:28:58,821:INFO:Uploading results into container
2025-11-16 22:28:58,822:INFO:Uploading model into container now
2025-11-16 22:28:58,822:INFO:_master_model_container: 6
2025-11-16 22:28:58,822:INFO:_display_container: 2
2025-11-16 22:28:58,824:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-16 22:28:58,825:INFO:create_model() successfully completed......................................
2025-11-16 22:28:59,093:INFO:SubProcess create_model() end ==================================
2025-11-16 22:28:59,093:INFO:Creating metrics dataframe
2025-11-16 22:28:59,111:INFO:Initializing Random Forest Classifier
2025-11-16 22:28:59,111:INFO:Total runtime is 0.25687140226364136 minutes
2025-11-16 22:28:59,118:INFO:SubProcess create_model() called ==================================
2025-11-16 22:28:59,118:INFO:Initializing create_model()
2025-11-16 22:28:59,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:28:59,118:INFO:Checking exceptions
2025-11-16 22:28:59,118:INFO:Importing libraries
2025-11-16 22:28:59,118:INFO:Copying training dataset
2025-11-16 22:28:59,126:INFO:Defining folds
2025-11-16 22:28:59,126:INFO:Declaring metric variables
2025-11-16 22:28:59,135:INFO:Importing untrained model
2025-11-16 22:28:59,145:INFO:Random Forest Classifier Imported successfully
2025-11-16 22:28:59,157:INFO:Starting cross validation
2025-11-16 22:28:59,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:00,330:INFO:Calculating mean and std
2025-11-16 22:29:00,330:INFO:Creating metrics dataframe
2025-11-16 22:29:00,334:INFO:Uploading results into container
2025-11-16 22:29:00,334:INFO:Uploading model into container now
2025-11-16 22:29:00,334:INFO:_master_model_container: 7
2025-11-16 22:29:00,334:INFO:_display_container: 2
2025-11-16 22:29:00,336:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-16 22:29:00,336:INFO:create_model() successfully completed......................................
2025-11-16 22:29:00,531:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:00,541:INFO:Creating metrics dataframe
2025-11-16 22:29:00,561:INFO:Initializing Quadratic Discriminant Analysis
2025-11-16 22:29:00,561:INFO:Total runtime is 0.28102622032165525 minutes
2025-11-16 22:29:00,570:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:00,570:INFO:Initializing create_model()
2025-11-16 22:29:00,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:00,570:INFO:Checking exceptions
2025-11-16 22:29:00,570:INFO:Importing libraries
2025-11-16 22:29:00,570:INFO:Copying training dataset
2025-11-16 22:29:00,576:INFO:Defining folds
2025-11-16 22:29:00,576:INFO:Declaring metric variables
2025-11-16 22:29:00,587:INFO:Importing untrained model
2025-11-16 22:29:00,596:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 22:29:00,629:INFO:Starting cross validation
2025-11-16 22:29:00,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:00,950:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:00,950:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:00,950:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:00,953:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:00,950:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:01,179:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:01,179:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 22:29:01,241:INFO:Calculating mean and std
2025-11-16 22:29:01,242:INFO:Creating metrics dataframe
2025-11-16 22:29:01,242:INFO:Uploading results into container
2025-11-16 22:29:01,242:INFO:Uploading model into container now
2025-11-16 22:29:01,242:INFO:_master_model_container: 8
2025-11-16 22:29:01,242:INFO:_display_container: 2
2025-11-16 22:29:01,250:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-16 22:29:01,250:INFO:create_model() successfully completed......................................
2025-11-16 22:29:01,560:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:01,560:INFO:Creating metrics dataframe
2025-11-16 22:29:01,579:INFO:Initializing Ada Boost Classifier
2025-11-16 22:29:01,580:INFO:Total runtime is 0.2980094393094381 minutes
2025-11-16 22:29:01,586:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:01,586:INFO:Initializing create_model()
2025-11-16 22:29:01,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:01,586:INFO:Checking exceptions
2025-11-16 22:29:01,586:INFO:Importing libraries
2025-11-16 22:29:01,586:INFO:Copying training dataset
2025-11-16 22:29:01,596:INFO:Defining folds
2025-11-16 22:29:01,597:INFO:Declaring metric variables
2025-11-16 22:29:01,603:INFO:Importing untrained model
2025-11-16 22:29:01,609:INFO:Ada Boost Classifier Imported successfully
2025-11-16 22:29:01,620:INFO:Starting cross validation
2025-11-16 22:29:01,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:01,813:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:01,813:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:01,813:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:01,813:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:01,813:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:01,813:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:02,231:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:02,231:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:29:02,480:INFO:Calculating mean and std
2025-11-16 22:29:02,481:INFO:Creating metrics dataframe
2025-11-16 22:29:02,491:INFO:Uploading results into container
2025-11-16 22:29:02,493:INFO:Uploading model into container now
2025-11-16 22:29:02,493:INFO:_master_model_container: 9
2025-11-16 22:29:02,493:INFO:_display_container: 2
2025-11-16 22:29:02,493:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 22:29:02,493:INFO:create_model() successfully completed......................................
2025-11-16 22:29:02,741:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:02,741:INFO:Creating metrics dataframe
2025-11-16 22:29:02,768:INFO:Initializing Gradient Boosting Classifier
2025-11-16 22:29:02,770:INFO:Total runtime is 0.31784175634384154 minutes
2025-11-16 22:29:02,776:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:02,778:INFO:Initializing create_model()
2025-11-16 22:29:02,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:02,778:INFO:Checking exceptions
2025-11-16 22:29:02,778:INFO:Importing libraries
2025-11-16 22:29:02,780:INFO:Copying training dataset
2025-11-16 22:29:02,784:INFO:Defining folds
2025-11-16 22:29:02,784:INFO:Declaring metric variables
2025-11-16 22:29:02,798:INFO:Importing untrained model
2025-11-16 22:29:02,807:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 22:29:02,824:INFO:Starting cross validation
2025-11-16 22:29:02,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:04,234:INFO:Calculating mean and std
2025-11-16 22:29:04,235:INFO:Creating metrics dataframe
2025-11-16 22:29:04,240:INFO:Uploading results into container
2025-11-16 22:29:04,240:INFO:Uploading model into container now
2025-11-16 22:29:04,240:INFO:_master_model_container: 10
2025-11-16 22:29:04,242:INFO:_display_container: 2
2025-11-16 22:29:04,242:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-16 22:29:04,242:INFO:create_model() successfully completed......................................
2025-11-16 22:29:04,458:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:04,458:INFO:Creating metrics dataframe
2025-11-16 22:29:04,482:INFO:Initializing Linear Discriminant Analysis
2025-11-16 22:29:04,482:INFO:Total runtime is 0.3463793317476908 minutes
2025-11-16 22:29:04,497:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:04,497:INFO:Initializing create_model()
2025-11-16 22:29:04,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:04,499:INFO:Checking exceptions
2025-11-16 22:29:04,499:INFO:Importing libraries
2025-11-16 22:29:04,499:INFO:Copying training dataset
2025-11-16 22:29:04,514:INFO:Defining folds
2025-11-16 22:29:04,514:INFO:Declaring metric variables
2025-11-16 22:29:04,522:INFO:Importing untrained model
2025-11-16 22:29:04,534:INFO:Linear Discriminant Analysis Imported successfully
2025-11-16 22:29:04,556:INFO:Starting cross validation
2025-11-16 22:29:04,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:05,020:INFO:Calculating mean and std
2025-11-16 22:29:05,020:INFO:Creating metrics dataframe
2025-11-16 22:29:05,020:INFO:Uploading results into container
2025-11-16 22:29:05,020:INFO:Uploading model into container now
2025-11-16 22:29:05,020:INFO:_master_model_container: 11
2025-11-16 22:29:05,020:INFO:_display_container: 2
2025-11-16 22:29:05,020:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-16 22:29:05,020:INFO:create_model() successfully completed......................................
2025-11-16 22:29:05,239:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:05,256:INFO:Creating metrics dataframe
2025-11-16 22:29:05,280:INFO:Initializing Extra Trees Classifier
2025-11-16 22:29:05,280:INFO:Total runtime is 0.35967372258504227 minutes
2025-11-16 22:29:05,282:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:05,282:INFO:Initializing create_model()
2025-11-16 22:29:05,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:05,289:INFO:Checking exceptions
2025-11-16 22:29:05,290:INFO:Importing libraries
2025-11-16 22:29:05,290:INFO:Copying training dataset
2025-11-16 22:29:05,297:INFO:Defining folds
2025-11-16 22:29:05,297:INFO:Declaring metric variables
2025-11-16 22:29:05,306:INFO:Importing untrained model
2025-11-16 22:29:05,314:INFO:Extra Trees Classifier Imported successfully
2025-11-16 22:29:05,403:INFO:Starting cross validation
2025-11-16 22:29:05,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:06,436:INFO:Calculating mean and std
2025-11-16 22:29:06,438:INFO:Creating metrics dataframe
2025-11-16 22:29:06,442:INFO:Uploading results into container
2025-11-16 22:29:06,443:INFO:Uploading model into container now
2025-11-16 22:29:06,445:INFO:_master_model_container: 12
2025-11-16 22:29:06,445:INFO:_display_container: 2
2025-11-16 22:29:06,445:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-16 22:29:06,445:INFO:create_model() successfully completed......................................
2025-11-16 22:29:06,774:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:06,774:INFO:Creating metrics dataframe
2025-11-16 22:29:06,806:INFO:Initializing Light Gradient Boosting Machine
2025-11-16 22:29:06,806:INFO:Total runtime is 0.3851054628690083 minutes
2025-11-16 22:29:06,811:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:06,811:INFO:Initializing create_model()
2025-11-16 22:29:06,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:06,811:INFO:Checking exceptions
2025-11-16 22:29:06,811:INFO:Importing libraries
2025-11-16 22:29:06,811:INFO:Copying training dataset
2025-11-16 22:29:06,822:INFO:Defining folds
2025-11-16 22:29:06,822:INFO:Declaring metric variables
2025-11-16 22:29:06,831:INFO:Importing untrained model
2025-11-16 22:29:06,841:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-16 22:29:06,859:INFO:Starting cross validation
2025-11-16 22:29:06,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:08,261:INFO:Calculating mean and std
2025-11-16 22:29:08,263:INFO:Creating metrics dataframe
2025-11-16 22:29:08,265:INFO:Uploading results into container
2025-11-16 22:29:08,267:INFO:Uploading model into container now
2025-11-16 22:29:08,267:INFO:_master_model_container: 13
2025-11-16 22:29:08,267:INFO:_display_container: 2
2025-11-16 22:29:08,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-16 22:29:08,269:INFO:create_model() successfully completed......................................
2025-11-16 22:29:08,434:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:08,434:INFO:Creating metrics dataframe
2025-11-16 22:29:08,474:INFO:Initializing Dummy Classifier
2025-11-16 22:29:08,474:INFO:Total runtime is 0.41291175285975135 minutes
2025-11-16 22:29:08,474:INFO:SubProcess create_model() called ==================================
2025-11-16 22:29:08,474:INFO:Initializing create_model()
2025-11-16 22:29:08,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F5E4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:08,474:INFO:Checking exceptions
2025-11-16 22:29:08,474:INFO:Importing libraries
2025-11-16 22:29:08,474:INFO:Copying training dataset
2025-11-16 22:29:08,490:INFO:Defining folds
2025-11-16 22:29:08,490:INFO:Declaring metric variables
2025-11-16 22:29:08,507:INFO:Importing untrained model
2025-11-16 22:29:08,525:INFO:Dummy Classifier Imported successfully
2025-11-16 22:29:08,547:INFO:Starting cross validation
2025-11-16 22:29:08,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:29:08,882:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:08,882:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:08,882:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:08,882:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:08,882:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:08,882:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:09,081:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:09,081:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 22:29:09,112:INFO:Calculating mean and std
2025-11-16 22:29:09,112:INFO:Creating metrics dataframe
2025-11-16 22:29:09,124:INFO:Uploading results into container
2025-11-16 22:29:09,124:INFO:Uploading model into container now
2025-11-16 22:29:09,124:INFO:_master_model_container: 14
2025-11-16 22:29:09,124:INFO:_display_container: 2
2025-11-16 22:29:09,131:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-16 22:29:09,132:INFO:create_model() successfully completed......................................
2025-11-16 22:29:09,439:INFO:SubProcess create_model() end ==================================
2025-11-16 22:29:09,439:INFO:Creating metrics dataframe
2025-11-16 22:29:09,471:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-16 22:29:09,504:INFO:Initializing create_model()
2025-11-16 22:29:09,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:29:09,508:INFO:Checking exceptions
2025-11-16 22:29:09,514:INFO:Importing libraries
2025-11-16 22:29:09,514:INFO:Copying training dataset
2025-11-16 22:29:09,534:INFO:Defining folds
2025-11-16 22:29:09,534:INFO:Declaring metric variables
2025-11-16 22:29:09,536:INFO:Importing untrained model
2025-11-16 22:29:09,537:INFO:Declaring custom model
2025-11-16 22:29:09,538:INFO:Ada Boost Classifier Imported successfully
2025-11-16 22:29:09,543:INFO:Cross validation set to False
2025-11-16 22:29:09,543:INFO:Fitting Model
2025-11-16 22:29:09,726:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-16 22:29:10,157:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 22:29:10,157:INFO:create_model() successfully completed......................................
2025-11-16 22:29:10,511:INFO:_master_model_container: 14
2025-11-16 22:29:10,511:INFO:_display_container: 2
2025-11-16 22:29:10,511:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 22:29:10,511:INFO:compare_models() successfully completed......................................
2025-11-16 22:30:30,290:INFO:Initializing tune_model()
2025-11-16 22:30:30,290:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-16 22:30:30,290:INFO:Checking exceptions
2025-11-16 22:30:30,361:INFO:Copying training dataset
2025-11-16 22:30:30,374:INFO:Checking base model
2025-11-16 22:30:30,375:INFO:Base model : Ada Boost Classifier
2025-11-16 22:30:30,395:INFO:Declaring metric variables
2025-11-16 22:30:30,410:INFO:Defining Hyperparameters
2025-11-16 22:30:30,742:INFO:Tuning with n_jobs=-1
2025-11-16 22:30:30,743:INFO:Initializing RandomizedSearchCV
2025-11-16 22:30:44,872:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-16 22:30:44,876:INFO:Hyperparameter search completed
2025-11-16 22:30:44,876:INFO:SubProcess create_model() called ==================================
2025-11-16 22:30:44,877:INFO:Initializing create_model()
2025-11-16 22:30:44,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D55F40C7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-16 22:30:44,877:INFO:Checking exceptions
2025-11-16 22:30:44,877:INFO:Importing libraries
2025-11-16 22:30:44,877:INFO:Copying training dataset
2025-11-16 22:30:44,893:INFO:Defining folds
2025-11-16 22:30:44,893:INFO:Declaring metric variables
2025-11-16 22:30:44,898:INFO:Importing untrained model
2025-11-16 22:30:44,902:INFO:Declaring custom model
2025-11-16 22:30:44,912:INFO:Ada Boost Classifier Imported successfully
2025-11-16 22:30:44,925:INFO:Starting cross validation
2025-11-16 22:30:44,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:30:47,601:INFO:Calculating mean and std
2025-11-16 22:30:47,603:INFO:Creating metrics dataframe
2025-11-16 22:30:47,611:INFO:Finalizing model
2025-11-16 22:30:48,607:INFO:Uploading results into container
2025-11-16 22:30:48,607:INFO:Uploading model into container now
2025-11-16 22:30:48,607:INFO:_master_model_container: 15
2025-11-16 22:30:48,609:INFO:_display_container: 3
2025-11-16 22:30:48,609:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-16 22:30:48,609:INFO:create_model() successfully completed......................................
2025-11-16 22:30:48,789:INFO:SubProcess create_model() end ==================================
2025-11-16 22:30:48,789:INFO:choose_better activated
2025-11-16 22:30:48,792:INFO:SubProcess create_model() called ==================================
2025-11-16 22:30:48,798:INFO:Initializing create_model()
2025-11-16 22:30:48,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D55AB1E090>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 22:30:48,799:INFO:Checking exceptions
2025-11-16 22:30:48,802:INFO:Importing libraries
2025-11-16 22:30:48,802:INFO:Copying training dataset
2025-11-16 22:30:48,812:INFO:Defining folds
2025-11-16 22:30:48,812:INFO:Declaring metric variables
2025-11-16 22:30:48,812:INFO:Importing untrained model
2025-11-16 22:30:48,812:INFO:Declaring custom model
2025-11-16 22:30:48,813:INFO:Ada Boost Classifier Imported successfully
2025-11-16 22:30:48,813:INFO:Starting cross validation
2025-11-16 22:30:48,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 22:30:49,032:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,037:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,044:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,044:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,058:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,072:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,078:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,078:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,472:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,477:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 22:30:49,813:INFO:Calculating mean and std
2025-11-16 22:30:49,813:INFO:Creating metrics dataframe
2025-11-16 22:30:49,817:INFO:Finalizing model
2025-11-16 22:30:49,909:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-16 22:30:50,134:INFO:Uploading results into container
2025-11-16 22:30:50,134:INFO:Uploading model into container now
2025-11-16 22:30:50,134:INFO:_master_model_container: 16
2025-11-16 22:30:50,134:INFO:_display_container: 4
2025-11-16 22:30:50,134:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 22:30:50,134:INFO:create_model() successfully completed......................................
2025-11-16 22:30:50,327:INFO:SubProcess create_model() end ==================================
2025-11-16 22:30:50,327:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-16 22:30:50,327:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.9991
2025-11-16 22:30:50,327:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-16 22:30:50,327:INFO:choose_better completed
2025-11-16 22:30:50,350:INFO:_master_model_container: 16
2025-11-16 22:30:50,350:INFO:_display_container: 3
2025-11-16 22:30:50,352:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-16 22:30:50,352:INFO:tune_model() successfully completed......................................
2025-11-16 23:57:32,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 23:57:32,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 23:57:32,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 23:57:32,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 23:57:39,986:INFO:PyCaret ClassificationExperiment
2025-11-16 23:57:39,986:INFO:Logging name: clf-default-name
2025-11-16 23:57:39,986:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-16 23:57:39,986:INFO:version 3.3.2
2025-11-16 23:57:39,986:INFO:Initializing setup()
2025-11-16 23:57:39,986:INFO:self.USI: d676
2025-11-16 23:57:39,986:INFO:self._variable_keys: {'data', '_ml_usecase', 'n_jobs_param', 'log_plots_param', 'X_test', 'y_train', 'exp_id', 'html_param', '_available_plots', 'fix_imbalance', 'seed', 'pipeline', 'exp_name_log', 'fold_shuffle_param', 'X', 'gpu_param', 'fold_groups_param', 'memory', 'X_train', 'y', 'idx', 'y_test', 'fold_generator', 'target_param', 'USI', 'gpu_n_jobs_param', 'logging_param', 'is_multiclass'}
2025-11-16 23:57:39,986:INFO:Checking environment
2025-11-16 23:57:39,986:INFO:python_version: 3.11.4
2025-11-16 23:57:39,986:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-16 23:57:39,986:INFO:machine: AMD64
2025-11-16 23:57:39,986:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-16 23:57:39,986:INFO:Memory: svmem(total=8403275776, available=1795608576, percent=78.6, used=6607667200, free=1795608576)
2025-11-16 23:57:39,986:INFO:Physical Core: 4
2025-11-16 23:57:39,986:INFO:Logical Core: 8
2025-11-16 23:57:39,986:INFO:Checking libraries
2025-11-16 23:57:39,986:INFO:System:
2025-11-16 23:57:39,986:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-16 23:57:39,986:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-16 23:57:39,986:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-16 23:57:39,986:INFO:PyCaret required dependencies:
2025-11-16 23:57:40,455:INFO:                 pip: 23.1.2
2025-11-16 23:57:40,455:INFO:          setuptools: 80.9.0
2025-11-16 23:57:40,455:INFO:             pycaret: 3.3.2
2025-11-16 23:57:40,455:INFO:             IPython: 9.6.0
2025-11-16 23:57:40,455:INFO:          ipywidgets: 8.1.7
2025-11-16 23:57:40,455:INFO:                tqdm: 4.67.1
2025-11-16 23:57:40,455:INFO:               numpy: 1.26.4
2025-11-16 23:57:40,455:INFO:              pandas: 2.1.4
2025-11-16 23:57:40,455:INFO:              jinja2: 3.1.6
2025-11-16 23:57:40,455:INFO:               scipy: 1.11.4
2025-11-16 23:57:40,455:INFO:              joblib: 1.3.2
2025-11-16 23:57:40,455:INFO:             sklearn: 1.4.2
2025-11-16 23:57:40,455:INFO:                pyod: 2.0.5
2025-11-16 23:57:40,455:INFO:            imblearn: 0.14.0
2025-11-16 23:57:40,455:INFO:   category_encoders: 2.7.0
2025-11-16 23:57:40,455:INFO:            lightgbm: 4.6.0
2025-11-16 23:57:40,455:INFO:               numba: 0.61.0
2025-11-16 23:57:40,455:INFO:            requests: 2.32.5
2025-11-16 23:57:40,455:INFO:          matplotlib: 3.7.5
2025-11-16 23:57:40,455:INFO:          scikitplot: 0.3.7
2025-11-16 23:57:40,455:INFO:         yellowbrick: 1.5
2025-11-16 23:57:40,455:INFO:              plotly: 5.24.1
2025-11-16 23:57:40,455:INFO:    plotly-resampler: Not installed
2025-11-16 23:57:40,455:INFO:             kaleido: 1.1.0
2025-11-16 23:57:40,455:INFO:           schemdraw: 0.15
2025-11-16 23:57:40,455:INFO:         statsmodels: 0.14.5
2025-11-16 23:57:40,455:INFO:              sktime: 0.26.0
2025-11-16 23:57:40,455:INFO:               tbats: 1.1.3
2025-11-16 23:57:40,455:INFO:            pmdarima: 2.0.4
2025-11-16 23:57:40,455:INFO:              psutil: 7.1.2
2025-11-16 23:57:40,455:INFO:          markupsafe: 3.0.3
2025-11-16 23:57:40,455:INFO:             pickle5: Not installed
2025-11-16 23:57:40,455:INFO:         cloudpickle: 3.1.1
2025-11-16 23:57:40,455:INFO:         deprecation: 2.1.0
2025-11-16 23:57:40,455:INFO:              xxhash: 3.6.0
2025-11-16 23:57:40,455:INFO:           wurlitzer: Not installed
2025-11-16 23:57:40,455:INFO:PyCaret optional dependencies:
2025-11-16 23:57:45,502:INFO:                shap: 0.44.1
2025-11-16 23:57:45,502:INFO:           interpret: 0.7.3
2025-11-16 23:57:45,502:INFO:                umap: 0.5.7
2025-11-16 23:57:45,502:INFO:     ydata_profiling: 4.17.0
2025-11-16 23:57:45,502:INFO:  explainerdashboard: 0.5.1
2025-11-16 23:57:45,502:INFO:             autoviz: Not installed
2025-11-16 23:57:45,502:INFO:           fairlearn: 0.7.0
2025-11-16 23:57:45,502:INFO:          deepchecks: Not installed
2025-11-16 23:57:45,502:INFO:             xgboost: Not installed
2025-11-16 23:57:45,502:INFO:            catboost: Not installed
2025-11-16 23:57:45,502:INFO:              kmodes: Not installed
2025-11-16 23:57:45,502:INFO:             mlxtend: Not installed
2025-11-16 23:57:45,502:INFO:       statsforecast: Not installed
2025-11-16 23:57:45,502:INFO:        tune_sklearn: Not installed
2025-11-16 23:57:45,502:INFO:                 ray: Not installed
2025-11-16 23:57:45,502:INFO:            hyperopt: Not installed
2025-11-16 23:57:45,502:INFO:              optuna: Not installed
2025-11-16 23:57:45,502:INFO:               skopt: Not installed
2025-11-16 23:57:45,502:INFO:              mlflow: 3.5.1
2025-11-16 23:57:45,502:INFO:              gradio: Not installed
2025-11-16 23:57:45,502:INFO:             fastapi: 0.121.0
2025-11-16 23:57:45,502:INFO:             uvicorn: 0.38.0
2025-11-16 23:57:45,502:INFO:              m2cgen: Not installed
2025-11-16 23:57:45,502:INFO:           evidently: Not installed
2025-11-16 23:57:45,502:INFO:               fugue: Not installed
2025-11-16 23:57:45,502:INFO:           streamlit: Not installed
2025-11-16 23:57:45,502:INFO:             prophet: Not installed
2025-11-16 23:57:45,502:INFO:None
2025-11-16 23:57:45,502:INFO:Set up data.
2025-11-16 23:57:45,537:INFO:Set up folding strategy.
2025-11-16 23:57:45,537:INFO:Set up train/test split.
2025-11-16 23:57:45,550:INFO:Set up index.
2025-11-16 23:57:45,550:INFO:Assigning column types.
2025-11-16 23:57:45,576:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-16 23:57:45,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 23:57:45,751:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 23:57:45,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:45,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 23:57:46,033:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 23:57:46,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,134:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-16 23:57:46,283:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 23:57:46,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 23:57:46,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,596:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-16 23:57:46,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:46,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:47,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:47,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:47,045:INFO:Preparing preprocessing pipeline...
2025-11-16 23:57:47,047:INFO:Set up simple imputation.
2025-11-16 23:57:47,051:INFO:Set up encoding of ordinal features.
2025-11-16 23:57:47,051:INFO:Set up encoding of categorical features.
2025-11-16 23:57:47,051:INFO:Set up imbalanced handling.
2025-11-16 23:57:47,051:INFO:Set up feature normalization.
2025-11-16 23:57:47,655:INFO:Finished creating preprocessing pipeline.
2025-11-16 23:57:47,733:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-16 23:57:47,733:INFO:Creating final display dataframe.
2025-11-16 23:57:48,515:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              d676
2025-11-16 23:57:48,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:48,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:48,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:48,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 23:57:48,859:INFO:setup() successfully completed in 9.17s...............
2025-11-16 23:57:48,879:INFO:Initializing compare_models()
2025-11-16 23:57:48,882:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-16 23:57:48,882:INFO:Checking exceptions
2025-11-16 23:57:48,886:INFO:Preparing display monitor
2025-11-16 23:57:48,928:INFO:Initializing Logistic Regression
2025-11-16 23:57:48,928:INFO:Total runtime is 0.0 minutes
2025-11-16 23:57:48,936:INFO:SubProcess create_model() called ==================================
2025-11-16 23:57:48,936:INFO:Initializing create_model()
2025-11-16 23:57:48,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:57:48,936:INFO:Checking exceptions
2025-11-16 23:57:48,936:INFO:Importing libraries
2025-11-16 23:57:48,936:INFO:Copying training dataset
2025-11-16 23:57:48,943:INFO:Defining folds
2025-11-16 23:57:48,943:INFO:Declaring metric variables
2025-11-16 23:57:48,950:INFO:Importing untrained model
2025-11-16 23:57:48,958:INFO:Logistic Regression Imported successfully
2025-11-16 23:57:48,969:INFO:Starting cross validation
2025-11-16 23:57:48,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:57:57,284:INFO:Calculating mean and std
2025-11-16 23:57:57,288:INFO:Creating metrics dataframe
2025-11-16 23:57:57,295:INFO:Uploading results into container
2025-11-16 23:57:57,299:INFO:Uploading model into container now
2025-11-16 23:57:57,299:INFO:_master_model_container: 1
2025-11-16 23:57:57,299:INFO:_display_container: 2
2025-11-16 23:57:57,301:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-16 23:57:57,301:INFO:create_model() successfully completed......................................
2025-11-16 23:57:57,486:INFO:SubProcess create_model() end ==================================
2025-11-16 23:57:57,486:INFO:Creating metrics dataframe
2025-11-16 23:57:57,500:INFO:Initializing K Neighbors Classifier
2025-11-16 23:57:57,500:INFO:Total runtime is 0.14286898374557494 minutes
2025-11-16 23:57:57,507:INFO:SubProcess create_model() called ==================================
2025-11-16 23:57:57,507:INFO:Initializing create_model()
2025-11-16 23:57:57,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:57:57,509:INFO:Checking exceptions
2025-11-16 23:57:57,509:INFO:Importing libraries
2025-11-16 23:57:57,509:INFO:Copying training dataset
2025-11-16 23:57:57,518:INFO:Defining folds
2025-11-16 23:57:57,518:INFO:Declaring metric variables
2025-11-16 23:57:57,533:INFO:Importing untrained model
2025-11-16 23:57:57,539:INFO:K Neighbors Classifier Imported successfully
2025-11-16 23:57:57,556:INFO:Starting cross validation
2025-11-16 23:57:57,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:57:58,114:INFO:Calculating mean and std
2025-11-16 23:57:58,116:INFO:Creating metrics dataframe
2025-11-16 23:57:58,120:INFO:Uploading results into container
2025-11-16 23:57:58,122:INFO:Uploading model into container now
2025-11-16 23:57:58,122:INFO:_master_model_container: 2
2025-11-16 23:57:58,122:INFO:_display_container: 2
2025-11-16 23:57:58,122:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 23:57:58,124:INFO:create_model() successfully completed......................................
2025-11-16 23:57:58,332:INFO:SubProcess create_model() end ==================================
2025-11-16 23:57:58,334:INFO:Creating metrics dataframe
2025-11-16 23:57:58,370:INFO:Initializing Naive Bayes
2025-11-16 23:57:58,371:INFO:Total runtime is 0.1573707063992818 minutes
2025-11-16 23:57:58,385:INFO:SubProcess create_model() called ==================================
2025-11-16 23:57:58,385:INFO:Initializing create_model()
2025-11-16 23:57:58,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:57:58,387:INFO:Checking exceptions
2025-11-16 23:57:58,387:INFO:Importing libraries
2025-11-16 23:57:58,387:INFO:Copying training dataset
2025-11-16 23:57:58,421:INFO:Defining folds
2025-11-16 23:57:58,422:INFO:Declaring metric variables
2025-11-16 23:57:58,450:INFO:Importing untrained model
2025-11-16 23:57:58,470:INFO:Naive Bayes Imported successfully
2025-11-16 23:57:58,499:INFO:Starting cross validation
2025-11-16 23:57:58,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:57:58,883:INFO:Calculating mean and std
2025-11-16 23:57:58,885:INFO:Creating metrics dataframe
2025-11-16 23:57:58,887:INFO:Uploading results into container
2025-11-16 23:57:58,889:INFO:Uploading model into container now
2025-11-16 23:57:58,889:INFO:_master_model_container: 3
2025-11-16 23:57:58,889:INFO:_display_container: 2
2025-11-16 23:57:58,889:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-16 23:57:58,889:INFO:create_model() successfully completed......................................
2025-11-16 23:57:59,117:INFO:SubProcess create_model() end ==================================
2025-11-16 23:57:59,117:INFO:Creating metrics dataframe
2025-11-16 23:57:59,140:INFO:Initializing Decision Tree Classifier
2025-11-16 23:57:59,140:INFO:Total runtime is 0.17019763787587483 minutes
2025-11-16 23:57:59,148:INFO:SubProcess create_model() called ==================================
2025-11-16 23:57:59,149:INFO:Initializing create_model()
2025-11-16 23:57:59,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:57:59,149:INFO:Checking exceptions
2025-11-16 23:57:59,149:INFO:Importing libraries
2025-11-16 23:57:59,149:INFO:Copying training dataset
2025-11-16 23:57:59,158:INFO:Defining folds
2025-11-16 23:57:59,158:INFO:Declaring metric variables
2025-11-16 23:57:59,172:INFO:Importing untrained model
2025-11-16 23:57:59,186:INFO:Decision Tree Classifier Imported successfully
2025-11-16 23:57:59,197:INFO:Starting cross validation
2025-11-16 23:57:59,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:57:59,615:INFO:Calculating mean and std
2025-11-16 23:57:59,615:INFO:Creating metrics dataframe
2025-11-16 23:57:59,615:INFO:Uploading results into container
2025-11-16 23:57:59,620:INFO:Uploading model into container now
2025-11-16 23:57:59,620:INFO:_master_model_container: 4
2025-11-16 23:57:59,620:INFO:_display_container: 2
2025-11-16 23:57:59,620:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-16 23:57:59,620:INFO:create_model() successfully completed......................................
2025-11-16 23:57:59,775:INFO:SubProcess create_model() end ==================================
2025-11-16 23:57:59,775:INFO:Creating metrics dataframe
2025-11-16 23:57:59,791:INFO:Initializing SVM - Linear Kernel
2025-11-16 23:57:59,791:INFO:Total runtime is 0.18105847040812173 minutes
2025-11-16 23:57:59,797:INFO:SubProcess create_model() called ==================================
2025-11-16 23:57:59,797:INFO:Initializing create_model()
2025-11-16 23:57:59,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:57:59,797:INFO:Checking exceptions
2025-11-16 23:57:59,797:INFO:Importing libraries
2025-11-16 23:57:59,797:INFO:Copying training dataset
2025-11-16 23:57:59,811:INFO:Defining folds
2025-11-16 23:57:59,811:INFO:Declaring metric variables
2025-11-16 23:57:59,814:INFO:Importing untrained model
2025-11-16 23:57:59,831:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 23:57:59,847:INFO:Starting cross validation
2025-11-16 23:57:59,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:00,283:INFO:Calculating mean and std
2025-11-16 23:58:00,285:INFO:Creating metrics dataframe
2025-11-16 23:58:00,295:INFO:Uploading results into container
2025-11-16 23:58:00,297:INFO:Uploading model into container now
2025-11-16 23:58:00,299:INFO:_master_model_container: 5
2025-11-16 23:58:00,299:INFO:_display_container: 2
2025-11-16 23:58:00,299:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-16 23:58:00,299:INFO:create_model() successfully completed......................................
2025-11-16 23:58:00,508:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:00,508:INFO:Creating metrics dataframe
2025-11-16 23:58:00,535:INFO:Initializing Ridge Classifier
2025-11-16 23:58:00,535:INFO:Total runtime is 0.19345595439275104 minutes
2025-11-16 23:58:00,542:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:00,542:INFO:Initializing create_model()
2025-11-16 23:58:00,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:00,542:INFO:Checking exceptions
2025-11-16 23:58:00,542:INFO:Importing libraries
2025-11-16 23:58:00,542:INFO:Copying training dataset
2025-11-16 23:58:00,550:INFO:Defining folds
2025-11-16 23:58:00,550:INFO:Declaring metric variables
2025-11-16 23:58:00,556:INFO:Importing untrained model
2025-11-16 23:58:00,563:INFO:Ridge Classifier Imported successfully
2025-11-16 23:58:00,571:INFO:Starting cross validation
2025-11-16 23:58:00,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:00,936:INFO:Calculating mean and std
2025-11-16 23:58:00,938:INFO:Creating metrics dataframe
2025-11-16 23:58:00,942:INFO:Uploading results into container
2025-11-16 23:58:00,942:INFO:Uploading model into container now
2025-11-16 23:58:00,949:INFO:_master_model_container: 6
2025-11-16 23:58:00,949:INFO:_display_container: 2
2025-11-16 23:58:00,951:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-16 23:58:00,952:INFO:create_model() successfully completed......................................
2025-11-16 23:58:01,146:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:01,146:INFO:Creating metrics dataframe
2025-11-16 23:58:01,165:INFO:Initializing Random Forest Classifier
2025-11-16 23:58:01,165:INFO:Total runtime is 0.20394883155822752 minutes
2025-11-16 23:58:01,171:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:01,171:INFO:Initializing create_model()
2025-11-16 23:58:01,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:01,173:INFO:Checking exceptions
2025-11-16 23:58:01,173:INFO:Importing libraries
2025-11-16 23:58:01,173:INFO:Copying training dataset
2025-11-16 23:58:01,175:INFO:Defining folds
2025-11-16 23:58:01,175:INFO:Declaring metric variables
2025-11-16 23:58:01,190:INFO:Importing untrained model
2025-11-16 23:58:01,200:INFO:Random Forest Classifier Imported successfully
2025-11-16 23:58:01,214:INFO:Starting cross validation
2025-11-16 23:58:01,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:02,427:INFO:Calculating mean and std
2025-11-16 23:58:02,427:INFO:Creating metrics dataframe
2025-11-16 23:58:02,431:INFO:Uploading results into container
2025-11-16 23:58:02,431:INFO:Uploading model into container now
2025-11-16 23:58:02,431:INFO:_master_model_container: 7
2025-11-16 23:58:02,431:INFO:_display_container: 2
2025-11-16 23:58:02,431:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-16 23:58:02,431:INFO:create_model() successfully completed......................................
2025-11-16 23:58:02,653:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:02,654:INFO:Creating metrics dataframe
2025-11-16 23:58:02,676:INFO:Initializing Quadratic Discriminant Analysis
2025-11-16 23:58:02,679:INFO:Total runtime is 0.2291947523752848 minutes
2025-11-16 23:58:02,686:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:02,689:INFO:Initializing create_model()
2025-11-16 23:58:02,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:02,689:INFO:Checking exceptions
2025-11-16 23:58:02,690:INFO:Importing libraries
2025-11-16 23:58:02,690:INFO:Copying training dataset
2025-11-16 23:58:02,702:INFO:Defining folds
2025-11-16 23:58:02,702:INFO:Declaring metric variables
2025-11-16 23:58:02,714:INFO:Importing untrained model
2025-11-16 23:58:02,723:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 23:58:02,741:INFO:Starting cross validation
2025-11-16 23:58:02,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:02,988:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:02,994:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:02,994:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:03,000:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:03,018:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:03,135:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:03,147:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-16 23:58:03,197:INFO:Calculating mean and std
2025-11-16 23:58:03,199:INFO:Creating metrics dataframe
2025-11-16 23:58:03,202:INFO:Uploading results into container
2025-11-16 23:58:03,202:INFO:Uploading model into container now
2025-11-16 23:58:03,204:INFO:_master_model_container: 8
2025-11-16 23:58:03,204:INFO:_display_container: 2
2025-11-16 23:58:03,204:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-16 23:58:03,204:INFO:create_model() successfully completed......................................
2025-11-16 23:58:03,399:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:03,399:INFO:Creating metrics dataframe
2025-11-16 23:58:03,416:INFO:Initializing Ada Boost Classifier
2025-11-16 23:58:03,416:INFO:Total runtime is 0.24147525231043496 minutes
2025-11-16 23:58:03,423:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:03,424:INFO:Initializing create_model()
2025-11-16 23:58:03,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:03,424:INFO:Checking exceptions
2025-11-16 23:58:03,424:INFO:Importing libraries
2025-11-16 23:58:03,424:INFO:Copying training dataset
2025-11-16 23:58:03,432:INFO:Defining folds
2025-11-16 23:58:03,432:INFO:Declaring metric variables
2025-11-16 23:58:03,442:INFO:Importing untrained model
2025-11-16 23:58:03,449:INFO:Ada Boost Classifier Imported successfully
2025-11-16 23:58:03,460:INFO:Starting cross validation
2025-11-16 23:58:03,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:03,669:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,671:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,675:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,679:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,681:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,683:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,692:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:03,716:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:04,081:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:04,084:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:04,336:INFO:Calculating mean and std
2025-11-16 23:58:04,340:INFO:Creating metrics dataframe
2025-11-16 23:58:04,344:INFO:Uploading results into container
2025-11-16 23:58:04,344:INFO:Uploading model into container now
2025-11-16 23:58:04,344:INFO:_master_model_container: 9
2025-11-16 23:58:04,344:INFO:_display_container: 2
2025-11-16 23:58:04,344:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 23:58:04,344:INFO:create_model() successfully completed......................................
2025-11-16 23:58:04,515:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:04,515:INFO:Creating metrics dataframe
2025-11-16 23:58:04,523:INFO:Initializing Gradient Boosting Classifier
2025-11-16 23:58:04,523:INFO:Total runtime is 0.2599173744519551 minutes
2025-11-16 23:58:04,542:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:04,542:INFO:Initializing create_model()
2025-11-16 23:58:04,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:04,544:INFO:Checking exceptions
2025-11-16 23:58:04,544:INFO:Importing libraries
2025-11-16 23:58:04,544:INFO:Copying training dataset
2025-11-16 23:58:04,553:INFO:Defining folds
2025-11-16 23:58:04,553:INFO:Declaring metric variables
2025-11-16 23:58:04,562:INFO:Importing untrained model
2025-11-16 23:58:04,572:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 23:58:04,587:INFO:Starting cross validation
2025-11-16 23:58:04,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:05,850:INFO:Calculating mean and std
2025-11-16 23:58:05,853:INFO:Creating metrics dataframe
2025-11-16 23:58:05,856:INFO:Uploading results into container
2025-11-16 23:58:05,860:INFO:Uploading model into container now
2025-11-16 23:58:05,860:INFO:_master_model_container: 10
2025-11-16 23:58:05,862:INFO:_display_container: 2
2025-11-16 23:58:05,864:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-16 23:58:05,865:INFO:create_model() successfully completed......................................
2025-11-16 23:58:06,039:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:06,039:INFO:Creating metrics dataframe
2025-11-16 23:58:06,071:INFO:Initializing Linear Discriminant Analysis
2025-11-16 23:58:06,071:INFO:Total runtime is 0.285723869005839 minutes
2025-11-16 23:58:06,081:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:06,081:INFO:Initializing create_model()
2025-11-16 23:58:06,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:06,081:INFO:Checking exceptions
2025-11-16 23:58:06,081:INFO:Importing libraries
2025-11-16 23:58:06,081:INFO:Copying training dataset
2025-11-16 23:58:06,089:INFO:Defining folds
2025-11-16 23:58:06,089:INFO:Declaring metric variables
2025-11-16 23:58:06,109:INFO:Importing untrained model
2025-11-16 23:58:06,118:INFO:Linear Discriminant Analysis Imported successfully
2025-11-16 23:58:06,141:INFO:Starting cross validation
2025-11-16 23:58:06,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:06,597:INFO:Calculating mean and std
2025-11-16 23:58:06,599:INFO:Creating metrics dataframe
2025-11-16 23:58:06,602:INFO:Uploading results into container
2025-11-16 23:58:06,604:INFO:Uploading model into container now
2025-11-16 23:58:06,605:INFO:_master_model_container: 11
2025-11-16 23:58:06,605:INFO:_display_container: 2
2025-11-16 23:58:06,607:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-16 23:58:06,607:INFO:create_model() successfully completed......................................
2025-11-16 23:58:06,852:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:06,852:INFO:Creating metrics dataframe
2025-11-16 23:58:06,872:INFO:Initializing Extra Trees Classifier
2025-11-16 23:58:06,872:INFO:Total runtime is 0.29906361897786454 minutes
2025-11-16 23:58:06,878:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:06,878:INFO:Initializing create_model()
2025-11-16 23:58:06,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:06,878:INFO:Checking exceptions
2025-11-16 23:58:06,878:INFO:Importing libraries
2025-11-16 23:58:06,878:INFO:Copying training dataset
2025-11-16 23:58:06,888:INFO:Defining folds
2025-11-16 23:58:06,888:INFO:Declaring metric variables
2025-11-16 23:58:06,893:INFO:Importing untrained model
2025-11-16 23:58:06,893:INFO:Extra Trees Classifier Imported successfully
2025-11-16 23:58:06,915:INFO:Starting cross validation
2025-11-16 23:58:06,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:07,944:INFO:Calculating mean and std
2025-11-16 23:58:07,945:INFO:Creating metrics dataframe
2025-11-16 23:58:07,949:INFO:Uploading results into container
2025-11-16 23:58:07,949:INFO:Uploading model into container now
2025-11-16 23:58:07,949:INFO:_master_model_container: 12
2025-11-16 23:58:07,949:INFO:_display_container: 2
2025-11-16 23:58:07,951:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-16 23:58:07,952:INFO:create_model() successfully completed......................................
2025-11-16 23:58:08,171:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:08,178:INFO:Creating metrics dataframe
2025-11-16 23:58:08,202:INFO:Initializing Light Gradient Boosting Machine
2025-11-16 23:58:08,202:INFO:Total runtime is 0.32124118407567337 minutes
2025-11-16 23:58:08,204:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:08,211:INFO:Initializing create_model()
2025-11-16 23:58:08,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:08,211:INFO:Checking exceptions
2025-11-16 23:58:08,211:INFO:Importing libraries
2025-11-16 23:58:08,211:INFO:Copying training dataset
2025-11-16 23:58:08,223:INFO:Defining folds
2025-11-16 23:58:08,225:INFO:Declaring metric variables
2025-11-16 23:58:08,230:INFO:Importing untrained model
2025-11-16 23:58:08,245:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-16 23:58:08,267:INFO:Starting cross validation
2025-11-16 23:58:08,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:09,671:INFO:Calculating mean and std
2025-11-16 23:58:09,673:INFO:Creating metrics dataframe
2025-11-16 23:58:09,676:INFO:Uploading results into container
2025-11-16 23:58:09,676:INFO:Uploading model into container now
2025-11-16 23:58:09,676:INFO:_master_model_container: 13
2025-11-16 23:58:09,676:INFO:_display_container: 2
2025-11-16 23:58:09,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-16 23:58:09,678:INFO:create_model() successfully completed......................................
2025-11-16 23:58:09,820:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:09,820:INFO:Creating metrics dataframe
2025-11-16 23:58:09,838:INFO:Initializing Dummy Classifier
2025-11-16 23:58:09,838:INFO:Total runtime is 0.34849821329116815 minutes
2025-11-16 23:58:09,843:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:09,843:INFO:Initializing create_model()
2025-11-16 23:58:09,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD18A2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:09,843:INFO:Checking exceptions
2025-11-16 23:58:09,843:INFO:Importing libraries
2025-11-16 23:58:09,843:INFO:Copying training dataset
2025-11-16 23:58:09,856:INFO:Defining folds
2025-11-16 23:58:09,856:INFO:Declaring metric variables
2025-11-16 23:58:09,857:INFO:Importing untrained model
2025-11-16 23:58:09,866:INFO:Dummy Classifier Imported successfully
2025-11-16 23:58:09,875:INFO:Starting cross validation
2025-11-16 23:58:09,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:10,187:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,193:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,193:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,195:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,206:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,209:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,209:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,213:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,327:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,338:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-16 23:58:10,358:INFO:Calculating mean and std
2025-11-16 23:58:10,358:INFO:Creating metrics dataframe
2025-11-16 23:58:10,365:INFO:Uploading results into container
2025-11-16 23:58:10,365:INFO:Uploading model into container now
2025-11-16 23:58:10,366:INFO:_master_model_container: 14
2025-11-16 23:58:10,366:INFO:_display_container: 2
2025-11-16 23:58:10,366:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-16 23:58:10,366:INFO:create_model() successfully completed......................................
2025-11-16 23:58:10,622:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:10,627:INFO:Creating metrics dataframe
2025-11-16 23:58:10,669:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-16 23:58:10,706:INFO:Initializing create_model()
2025-11-16 23:58:10,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:10,709:INFO:Checking exceptions
2025-11-16 23:58:10,715:INFO:Importing libraries
2025-11-16 23:58:10,715:INFO:Copying training dataset
2025-11-16 23:58:10,730:INFO:Defining folds
2025-11-16 23:58:10,730:INFO:Declaring metric variables
2025-11-16 23:58:10,730:INFO:Importing untrained model
2025-11-16 23:58:10,730:INFO:Declaring custom model
2025-11-16 23:58:10,730:INFO:Ada Boost Classifier Imported successfully
2025-11-16 23:58:10,739:INFO:Cross validation set to False
2025-11-16 23:58:10,739:INFO:Fitting Model
2025-11-16 23:58:10,840:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-16 23:58:11,087:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 23:58:11,087:INFO:create_model() successfully completed......................................
2025-11-16 23:58:11,388:INFO:_master_model_container: 14
2025-11-16 23:58:11,388:INFO:_display_container: 2
2025-11-16 23:58:11,390:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 23:58:11,390:INFO:compare_models() successfully completed......................................
2025-11-16 23:58:11,460:INFO:Initializing tune_model()
2025-11-16 23:58:11,462:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-16 23:58:11,462:INFO:Checking exceptions
2025-11-16 23:58:11,500:INFO:Copying training dataset
2025-11-16 23:58:11,511:INFO:Checking base model
2025-11-16 23:58:11,511:INFO:Base model : Ada Boost Classifier
2025-11-16 23:58:11,518:INFO:Declaring metric variables
2025-11-16 23:58:11,530:INFO:Defining Hyperparameters
2025-11-16 23:58:11,775:INFO:Tuning with n_jobs=-1
2025-11-16 23:58:11,777:INFO:Initializing RandomizedSearchCV
2025-11-16 23:58:24,320:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-16 23:58:24,320:INFO:Hyperparameter search completed
2025-11-16 23:58:24,320:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:24,325:INFO:Initializing create_model()
2025-11-16 23:58:24,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCE19890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-16 23:58:24,325:INFO:Checking exceptions
2025-11-16 23:58:24,325:INFO:Importing libraries
2025-11-16 23:58:24,325:INFO:Copying training dataset
2025-11-16 23:58:24,337:INFO:Defining folds
2025-11-16 23:58:24,338:INFO:Declaring metric variables
2025-11-16 23:58:24,345:INFO:Importing untrained model
2025-11-16 23:58:24,347:INFO:Declaring custom model
2025-11-16 23:58:24,347:INFO:Ada Boost Classifier Imported successfully
2025-11-16 23:58:24,369:INFO:Starting cross validation
2025-11-16 23:58:24,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:26,529:INFO:Calculating mean and std
2025-11-16 23:58:26,529:INFO:Creating metrics dataframe
2025-11-16 23:58:26,529:INFO:Finalizing model
2025-11-16 23:58:27,310:INFO:Uploading results into container
2025-11-16 23:58:27,310:INFO:Uploading model into container now
2025-11-16 23:58:27,314:INFO:_master_model_container: 15
2025-11-16 23:58:27,314:INFO:_display_container: 3
2025-11-16 23:58:27,314:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-16 23:58:27,314:INFO:create_model() successfully completed......................................
2025-11-16 23:58:27,521:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:27,521:INFO:choose_better activated
2025-11-16 23:58:27,529:INFO:SubProcess create_model() called ==================================
2025-11-16 23:58:27,529:INFO:Initializing create_model()
2025-11-16 23:58:27,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8C8702750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 23:58:27,531:INFO:Checking exceptions
2025-11-16 23:58:27,531:INFO:Importing libraries
2025-11-16 23:58:27,531:INFO:Copying training dataset
2025-11-16 23:58:27,543:INFO:Defining folds
2025-11-16 23:58:27,543:INFO:Declaring metric variables
2025-11-16 23:58:27,543:INFO:Importing untrained model
2025-11-16 23:58:27,543:INFO:Declaring custom model
2025-11-16 23:58:27,543:INFO:Ada Boost Classifier Imported successfully
2025-11-16 23:58:27,543:INFO:Starting cross validation
2025-11-16 23:58:27,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 23:58:27,701:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,713:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,715:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,715:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,717:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,721:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,723:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:27,723:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:28,113:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:28,113:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 23:58:28,351:INFO:Calculating mean and std
2025-11-16 23:58:28,351:INFO:Creating metrics dataframe
2025-11-16 23:58:28,355:INFO:Finalizing model
2025-11-16 23:58:28,492:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-16 23:58:28,697:INFO:Uploading results into container
2025-11-16 23:58:28,697:INFO:Uploading model into container now
2025-11-16 23:58:28,704:INFO:_master_model_container: 16
2025-11-16 23:58:28,704:INFO:_display_container: 4
2025-11-16 23:58:28,704:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 23:58:28,704:INFO:create_model() successfully completed......................................
2025-11-16 23:58:28,893:INFO:SubProcess create_model() end ==================================
2025-11-16 23:58:28,893:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-16 23:58:28,893:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.9991
2025-11-16 23:58:28,893:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-16 23:58:28,893:INFO:choose_better completed
2025-11-16 23:58:28,914:INFO:_master_model_container: 16
2025-11-16 23:58:28,914:INFO:_display_container: 3
2025-11-16 23:58:28,923:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-16 23:58:28,923:INFO:tune_model() successfully completed......................................
2025-11-17 00:02:05,625:INFO:PyCaret ClassificationExperiment
2025-11-17 00:02:05,625:INFO:Logging name: clf-default-name
2025-11-17 00:02:05,627:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-17 00:02:05,627:INFO:version 3.3.2
2025-11-17 00:02:05,627:INFO:Initializing setup()
2025-11-17 00:02:05,627:INFO:self.USI: 9af8
2025-11-17 00:02:05,627:INFO:self._variable_keys: {'data', '_ml_usecase', 'n_jobs_param', 'log_plots_param', 'X_test', 'y_train', 'exp_id', 'html_param', '_available_plots', 'fix_imbalance', 'seed', 'pipeline', 'exp_name_log', 'fold_shuffle_param', 'X', 'gpu_param', 'fold_groups_param', 'memory', 'X_train', 'y', 'idx', 'y_test', 'fold_generator', 'target_param', 'USI', 'gpu_n_jobs_param', 'logging_param', 'is_multiclass'}
2025-11-17 00:02:05,627:INFO:Checking environment
2025-11-17 00:02:05,627:INFO:python_version: 3.11.4
2025-11-17 00:02:05,627:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-17 00:02:05,627:INFO:machine: AMD64
2025-11-17 00:02:05,627:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-17 00:02:05,627:INFO:Memory: svmem(total=8403275776, available=1674858496, percent=80.1, used=6728417280, free=1674858496)
2025-11-17 00:02:05,627:INFO:Physical Core: 4
2025-11-17 00:02:05,630:INFO:Logical Core: 8
2025-11-17 00:02:05,630:INFO:Checking libraries
2025-11-17 00:02:05,630:INFO:System:
2025-11-17 00:02:05,630:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-17 00:02:05,630:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-17 00:02:05,630:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-17 00:02:05,630:INFO:PyCaret required dependencies:
2025-11-17 00:02:05,630:INFO:                 pip: 23.1.2
2025-11-17 00:02:05,630:INFO:          setuptools: 80.9.0
2025-11-17 00:02:05,630:INFO:             pycaret: 3.3.2
2025-11-17 00:02:05,631:INFO:             IPython: 9.6.0
2025-11-17 00:02:05,631:INFO:          ipywidgets: 8.1.7
2025-11-17 00:02:05,631:INFO:                tqdm: 4.67.1
2025-11-17 00:02:05,631:INFO:               numpy: 1.26.4
2025-11-17 00:02:05,631:INFO:              pandas: 2.1.4
2025-11-17 00:02:05,631:INFO:              jinja2: 3.1.6
2025-11-17 00:02:05,631:INFO:               scipy: 1.11.4
2025-11-17 00:02:05,631:INFO:              joblib: 1.3.2
2025-11-17 00:02:05,631:INFO:             sklearn: 1.4.2
2025-11-17 00:02:05,631:INFO:                pyod: 2.0.5
2025-11-17 00:02:05,631:INFO:            imblearn: 0.14.0
2025-11-17 00:02:05,631:INFO:   category_encoders: 2.7.0
2025-11-17 00:02:05,631:INFO:            lightgbm: 4.6.0
2025-11-17 00:02:05,631:INFO:               numba: 0.61.0
2025-11-17 00:02:05,633:INFO:            requests: 2.32.5
2025-11-17 00:02:05,633:INFO:          matplotlib: 3.7.5
2025-11-17 00:02:05,633:INFO:          scikitplot: 0.3.7
2025-11-17 00:02:05,634:INFO:         yellowbrick: 1.5
2025-11-17 00:02:05,634:INFO:              plotly: 5.24.1
2025-11-17 00:02:05,634:INFO:    plotly-resampler: Not installed
2025-11-17 00:02:05,634:INFO:             kaleido: 1.1.0
2025-11-17 00:02:05,634:INFO:           schemdraw: 0.15
2025-11-17 00:02:05,634:INFO:         statsmodels: 0.14.5
2025-11-17 00:02:05,634:INFO:              sktime: 0.26.0
2025-11-17 00:02:05,634:INFO:               tbats: 1.1.3
2025-11-17 00:02:05,634:INFO:            pmdarima: 2.0.4
2025-11-17 00:02:05,634:INFO:              psutil: 7.1.2
2025-11-17 00:02:05,634:INFO:          markupsafe: 3.0.3
2025-11-17 00:02:05,635:INFO:             pickle5: Not installed
2025-11-17 00:02:05,635:INFO:         cloudpickle: 3.1.1
2025-11-17 00:02:05,635:INFO:         deprecation: 2.1.0
2025-11-17 00:02:05,635:INFO:              xxhash: 3.6.0
2025-11-17 00:02:05,635:INFO:           wurlitzer: Not installed
2025-11-17 00:02:05,635:INFO:PyCaret optional dependencies:
2025-11-17 00:02:05,635:INFO:                shap: 0.44.1
2025-11-17 00:02:05,635:INFO:           interpret: 0.7.3
2025-11-17 00:02:05,635:INFO:                umap: 0.5.7
2025-11-17 00:02:05,635:INFO:     ydata_profiling: 4.17.0
2025-11-17 00:02:05,635:INFO:  explainerdashboard: 0.5.1
2025-11-17 00:02:05,635:INFO:             autoviz: Not installed
2025-11-17 00:02:05,635:INFO:           fairlearn: 0.7.0
2025-11-17 00:02:05,635:INFO:          deepchecks: Not installed
2025-11-17 00:02:05,637:INFO:             xgboost: Not installed
2025-11-17 00:02:05,637:INFO:            catboost: Not installed
2025-11-17 00:02:05,637:INFO:              kmodes: Not installed
2025-11-17 00:02:05,637:INFO:             mlxtend: Not installed
2025-11-17 00:02:05,637:INFO:       statsforecast: Not installed
2025-11-17 00:02:05,637:INFO:        tune_sklearn: Not installed
2025-11-17 00:02:05,637:INFO:                 ray: Not installed
2025-11-17 00:02:05,637:INFO:            hyperopt: Not installed
2025-11-17 00:02:05,637:INFO:              optuna: Not installed
2025-11-17 00:02:05,637:INFO:               skopt: Not installed
2025-11-17 00:02:05,637:INFO:              mlflow: 3.5.1
2025-11-17 00:02:05,637:INFO:              gradio: Not installed
2025-11-17 00:02:05,637:INFO:             fastapi: 0.121.0
2025-11-17 00:02:05,637:INFO:             uvicorn: 0.38.0
2025-11-17 00:02:05,637:INFO:              m2cgen: Not installed
2025-11-17 00:02:05,637:INFO:           evidently: Not installed
2025-11-17 00:02:05,639:INFO:               fugue: Not installed
2025-11-17 00:02:05,639:INFO:           streamlit: Not installed
2025-11-17 00:02:05,639:INFO:             prophet: Not installed
2025-11-17 00:02:05,639:INFO:None
2025-11-17 00:02:05,639:INFO:Set up data.
2025-11-17 00:02:05,649:INFO:Set up folding strategy.
2025-11-17 00:02:05,649:INFO:Set up train/test split.
2025-11-17 00:02:05,663:INFO:Set up index.
2025-11-17 00:02:05,663:INFO:Assigning column types.
2025-11-17 00:02:05,667:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-17 00:02:05,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:02:05,776:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:02:05,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:05,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:02:06,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:02:06,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,129:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-17 00:02:06,380:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:02:06,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,750:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:02:06,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,831:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-17 00:02:06,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:06,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:07,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:07,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:07,143:INFO:Preparing preprocessing pipeline...
2025-11-17 00:02:07,145:INFO:Set up simple imputation.
2025-11-17 00:02:07,145:INFO:Set up encoding of ordinal features.
2025-11-17 00:02:07,145:INFO:Set up encoding of categorical features.
2025-11-17 00:02:07,145:INFO:Set up imbalanced handling.
2025-11-17 00:02:07,145:INFO:Set up feature normalization.
2025-11-17 00:02:07,370:INFO:Finished creating preprocessing pipeline.
2025-11-17 00:02:07,478:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-17 00:02:07,478:INFO:Creating final display dataframe.
2025-11-17 00:02:07,727:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              9af8
2025-11-17 00:02:07,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:07,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:08,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:08,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:02:08,193:INFO:setup() successfully completed in 2.74s...............
2025-11-17 00:02:08,271:INFO:Initializing compare_models()
2025-11-17 00:02:08,279:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-17 00:02:08,279:INFO:Checking exceptions
2025-11-17 00:02:08,316:INFO:Preparing display monitor
2025-11-17 00:02:08,448:INFO:Initializing Logistic Regression
2025-11-17 00:02:08,451:INFO:Total runtime is 5.183617273966471e-05 minutes
2025-11-17 00:02:08,464:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:08,464:INFO:Initializing create_model()
2025-11-17 00:02:08,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:08,466:INFO:Checking exceptions
2025-11-17 00:02:08,466:INFO:Importing libraries
2025-11-17 00:02:08,466:INFO:Copying training dataset
2025-11-17 00:02:08,478:INFO:Defining folds
2025-11-17 00:02:08,480:INFO:Declaring metric variables
2025-11-17 00:02:08,490:INFO:Importing untrained model
2025-11-17 00:02:08,494:INFO:Logistic Regression Imported successfully
2025-11-17 00:02:08,525:INFO:Starting cross validation
2025-11-17 00:02:08,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:09,159:INFO:Calculating mean and std
2025-11-17 00:02:09,161:INFO:Creating metrics dataframe
2025-11-17 00:02:09,161:INFO:Uploading results into container
2025-11-17 00:02:09,161:INFO:Uploading model into container now
2025-11-17 00:02:09,161:INFO:_master_model_container: 1
2025-11-17 00:02:09,161:INFO:_display_container: 2
2025-11-17 00:02:09,161:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-17 00:02:09,161:INFO:create_model() successfully completed......................................
2025-11-17 00:02:09,426:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:09,426:INFO:Creating metrics dataframe
2025-11-17 00:02:09,439:INFO:Initializing K Neighbors Classifier
2025-11-17 00:02:09,439:INFO:Total runtime is 0.016526520252227783 minutes
2025-11-17 00:02:09,447:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:09,447:INFO:Initializing create_model()
2025-11-17 00:02:09,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:09,447:INFO:Checking exceptions
2025-11-17 00:02:09,447:INFO:Importing libraries
2025-11-17 00:02:09,447:INFO:Copying training dataset
2025-11-17 00:02:09,468:INFO:Defining folds
2025-11-17 00:02:09,468:INFO:Declaring metric variables
2025-11-17 00:02:09,477:INFO:Importing untrained model
2025-11-17 00:02:09,482:INFO:K Neighbors Classifier Imported successfully
2025-11-17 00:02:09,518:INFO:Starting cross validation
2025-11-17 00:02:09,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:10,427:INFO:Calculating mean and std
2025-11-17 00:02:10,432:INFO:Creating metrics dataframe
2025-11-17 00:02:10,443:INFO:Uploading results into container
2025-11-17 00:02:10,443:INFO:Uploading model into container now
2025-11-17 00:02:10,443:INFO:_master_model_container: 2
2025-11-17 00:02:10,452:INFO:_display_container: 2
2025-11-17 00:02:10,452:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-17 00:02:10,452:INFO:create_model() successfully completed......................................
2025-11-17 00:02:10,853:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:10,853:INFO:Creating metrics dataframe
2025-11-17 00:02:10,902:INFO:Initializing Naive Bayes
2025-11-17 00:02:10,902:INFO:Total runtime is 0.04091551701227824 minutes
2025-11-17 00:02:10,936:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:10,936:INFO:Initializing create_model()
2025-11-17 00:02:10,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:10,942:INFO:Checking exceptions
2025-11-17 00:02:10,946:INFO:Importing libraries
2025-11-17 00:02:10,948:INFO:Copying training dataset
2025-11-17 00:02:10,982:INFO:Defining folds
2025-11-17 00:02:10,982:INFO:Declaring metric variables
2025-11-17 00:02:11,020:INFO:Importing untrained model
2025-11-17 00:02:11,054:INFO:Naive Bayes Imported successfully
2025-11-17 00:02:11,102:INFO:Starting cross validation
2025-11-17 00:02:11,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:11,863:INFO:Calculating mean and std
2025-11-17 00:02:11,866:INFO:Creating metrics dataframe
2025-11-17 00:02:11,879:INFO:Uploading results into container
2025-11-17 00:02:11,879:INFO:Uploading model into container now
2025-11-17 00:02:11,879:INFO:_master_model_container: 3
2025-11-17 00:02:11,879:INFO:_display_container: 2
2025-11-17 00:02:11,879:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-17 00:02:11,889:INFO:create_model() successfully completed......................................
2025-11-17 00:02:12,280:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:12,280:INFO:Creating metrics dataframe
2025-11-17 00:02:12,336:INFO:Initializing Decision Tree Classifier
2025-11-17 00:02:12,336:INFO:Total runtime is 0.06481211582819621 minutes
2025-11-17 00:02:12,360:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:12,363:INFO:Initializing create_model()
2025-11-17 00:02:12,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:12,363:INFO:Checking exceptions
2025-11-17 00:02:12,363:INFO:Importing libraries
2025-11-17 00:02:12,366:INFO:Copying training dataset
2025-11-17 00:02:12,393:INFO:Defining folds
2025-11-17 00:02:12,393:INFO:Declaring metric variables
2025-11-17 00:02:12,428:INFO:Importing untrained model
2025-11-17 00:02:12,450:INFO:Decision Tree Classifier Imported successfully
2025-11-17 00:02:12,494:INFO:Starting cross validation
2025-11-17 00:02:12,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:13,305:INFO:Calculating mean and std
2025-11-17 00:02:13,309:INFO:Creating metrics dataframe
2025-11-17 00:02:13,325:INFO:Uploading results into container
2025-11-17 00:02:13,325:INFO:Uploading model into container now
2025-11-17 00:02:13,325:INFO:_master_model_container: 4
2025-11-17 00:02:13,325:INFO:_display_container: 2
2025-11-17 00:02:13,325:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-17 00:02:13,325:INFO:create_model() successfully completed......................................
2025-11-17 00:02:13,723:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:13,724:INFO:Creating metrics dataframe
2025-11-17 00:02:13,757:INFO:Initializing SVM - Linear Kernel
2025-11-17 00:02:13,757:INFO:Total runtime is 0.08848880529403687 minutes
2025-11-17 00:02:13,783:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:13,790:INFO:Initializing create_model()
2025-11-17 00:02:13,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:13,790:INFO:Checking exceptions
2025-11-17 00:02:13,790:INFO:Importing libraries
2025-11-17 00:02:13,790:INFO:Copying training dataset
2025-11-17 00:02:13,815:INFO:Defining folds
2025-11-17 00:02:13,815:INFO:Declaring metric variables
2025-11-17 00:02:13,841:INFO:Importing untrained model
2025-11-17 00:02:13,862:INFO:SVM - Linear Kernel Imported successfully
2025-11-17 00:02:13,906:INFO:Starting cross validation
2025-11-17 00:02:13,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:14,810:INFO:Calculating mean and std
2025-11-17 00:02:14,815:INFO:Creating metrics dataframe
2025-11-17 00:02:14,831:INFO:Uploading results into container
2025-11-17 00:02:14,833:INFO:Uploading model into container now
2025-11-17 00:02:14,833:INFO:_master_model_container: 5
2025-11-17 00:02:14,833:INFO:_display_container: 2
2025-11-17 00:02:14,838:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-17 00:02:14,838:INFO:create_model() successfully completed......................................
2025-11-17 00:02:15,143:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:15,147:INFO:Creating metrics dataframe
2025-11-17 00:02:15,172:INFO:Initializing Ridge Classifier
2025-11-17 00:02:15,172:INFO:Total runtime is 0.11207987864812216 minutes
2025-11-17 00:02:15,188:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:15,193:INFO:Initializing create_model()
2025-11-17 00:02:15,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:15,193:INFO:Checking exceptions
2025-11-17 00:02:15,193:INFO:Importing libraries
2025-11-17 00:02:15,195:INFO:Copying training dataset
2025-11-17 00:02:15,213:INFO:Defining folds
2025-11-17 00:02:15,213:INFO:Declaring metric variables
2025-11-17 00:02:15,223:INFO:Importing untrained model
2025-11-17 00:02:15,239:INFO:Ridge Classifier Imported successfully
2025-11-17 00:02:15,274:INFO:Starting cross validation
2025-11-17 00:02:15,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:15,908:INFO:Calculating mean and std
2025-11-17 00:02:15,908:INFO:Creating metrics dataframe
2025-11-17 00:02:15,920:INFO:Uploading results into container
2025-11-17 00:02:15,924:INFO:Uploading model into container now
2025-11-17 00:02:15,924:INFO:_master_model_container: 6
2025-11-17 00:02:15,924:INFO:_display_container: 2
2025-11-17 00:02:15,924:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-17 00:02:15,924:INFO:create_model() successfully completed......................................
2025-11-17 00:02:16,290:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:16,290:INFO:Creating metrics dataframe
2025-11-17 00:02:16,338:INFO:Initializing Random Forest Classifier
2025-11-17 00:02:16,346:INFO:Total runtime is 0.13164360920588175 minutes
2025-11-17 00:02:16,361:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:16,361:INFO:Initializing create_model()
2025-11-17 00:02:16,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:16,369:INFO:Checking exceptions
2025-11-17 00:02:16,369:INFO:Importing libraries
2025-11-17 00:02:16,369:INFO:Copying training dataset
2025-11-17 00:02:16,394:INFO:Defining folds
2025-11-17 00:02:16,394:INFO:Declaring metric variables
2025-11-17 00:02:16,416:INFO:Importing untrained model
2025-11-17 00:02:16,438:INFO:Random Forest Classifier Imported successfully
2025-11-17 00:02:16,479:INFO:Starting cross validation
2025-11-17 00:02:16,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:19,285:INFO:Calculating mean and std
2025-11-17 00:02:19,290:INFO:Creating metrics dataframe
2025-11-17 00:02:19,297:INFO:Uploading results into container
2025-11-17 00:02:19,304:INFO:Uploading model into container now
2025-11-17 00:02:19,304:INFO:_master_model_container: 7
2025-11-17 00:02:19,304:INFO:_display_container: 2
2025-11-17 00:02:19,310:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-17 00:02:19,310:INFO:create_model() successfully completed......................................
2025-11-17 00:02:19,586:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:19,586:INFO:Creating metrics dataframe
2025-11-17 00:02:19,610:INFO:Initializing Quadratic Discriminant Analysis
2025-11-17 00:02:19,610:INFO:Total runtime is 0.18604334195454914 minutes
2025-11-17 00:02:19,620:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:19,620:INFO:Initializing create_model()
2025-11-17 00:02:19,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:19,622:INFO:Checking exceptions
2025-11-17 00:02:19,622:INFO:Importing libraries
2025-11-17 00:02:19,622:INFO:Copying training dataset
2025-11-17 00:02:19,626:INFO:Defining folds
2025-11-17 00:02:19,626:INFO:Declaring metric variables
2025-11-17 00:02:19,643:INFO:Importing untrained model
2025-11-17 00:02:19,683:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-17 00:02:19,719:INFO:Starting cross validation
2025-11-17 00:02:19,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:19,935:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:19,939:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:19,947:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:19,976:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,005:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,013:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,019:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,029:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,259:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,390:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:02:20,492:INFO:Calculating mean and std
2025-11-17 00:02:20,493:INFO:Creating metrics dataframe
2025-11-17 00:02:20,493:INFO:Uploading results into container
2025-11-17 00:02:20,493:INFO:Uploading model into container now
2025-11-17 00:02:20,501:INFO:_master_model_container: 8
2025-11-17 00:02:20,501:INFO:_display_container: 2
2025-11-17 00:02:20,503:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-17 00:02:20,503:INFO:create_model() successfully completed......................................
2025-11-17 00:02:20,787:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:20,787:INFO:Creating metrics dataframe
2025-11-17 00:02:20,837:INFO:Initializing Ada Boost Classifier
2025-11-17 00:02:20,837:INFO:Total runtime is 0.20649888118108112 minutes
2025-11-17 00:02:20,863:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:20,863:INFO:Initializing create_model()
2025-11-17 00:02:20,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:20,865:INFO:Checking exceptions
2025-11-17 00:02:20,865:INFO:Importing libraries
2025-11-17 00:02:20,865:INFO:Copying training dataset
2025-11-17 00:02:20,897:INFO:Defining folds
2025-11-17 00:02:20,897:INFO:Declaring metric variables
2025-11-17 00:02:20,919:INFO:Importing untrained model
2025-11-17 00:02:20,944:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:02:20,989:INFO:Starting cross validation
2025-11-17 00:02:21,002:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:21,371:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,378:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,384:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,394:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,407:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,439:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,441:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:21,447:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:22,024:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:22,041:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:22,433:INFO:Calculating mean and std
2025-11-17 00:02:22,433:INFO:Creating metrics dataframe
2025-11-17 00:02:22,443:INFO:Uploading results into container
2025-11-17 00:02:22,444:INFO:Uploading model into container now
2025-11-17 00:02:22,445:INFO:_master_model_container: 9
2025-11-17 00:02:22,446:INFO:_display_container: 2
2025-11-17 00:02:22,446:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:02:22,446:INFO:create_model() successfully completed......................................
2025-11-17 00:02:22,617:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:22,617:INFO:Creating metrics dataframe
2025-11-17 00:02:22,637:INFO:Initializing Gradient Boosting Classifier
2025-11-17 00:02:22,637:INFO:Total runtime is 0.23649128278096515 minutes
2025-11-17 00:02:22,645:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:22,645:INFO:Initializing create_model()
2025-11-17 00:02:22,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:22,645:INFO:Checking exceptions
2025-11-17 00:02:22,645:INFO:Importing libraries
2025-11-17 00:02:22,645:INFO:Copying training dataset
2025-11-17 00:02:22,653:INFO:Defining folds
2025-11-17 00:02:22,653:INFO:Declaring metric variables
2025-11-17 00:02:22,674:INFO:Importing untrained model
2025-11-17 00:02:22,688:INFO:Gradient Boosting Classifier Imported successfully
2025-11-17 00:02:22,711:INFO:Starting cross validation
2025-11-17 00:02:22,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:24,953:INFO:Calculating mean and std
2025-11-17 00:02:24,957:INFO:Creating metrics dataframe
2025-11-17 00:02:24,970:INFO:Uploading results into container
2025-11-17 00:02:24,974:INFO:Uploading model into container now
2025-11-17 00:02:24,974:INFO:_master_model_container: 10
2025-11-17 00:02:24,974:INFO:_display_container: 2
2025-11-17 00:02:24,974:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-17 00:02:24,974:INFO:create_model() successfully completed......................................
2025-11-17 00:02:25,319:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:25,319:INFO:Creating metrics dataframe
2025-11-17 00:02:25,335:INFO:Initializing Linear Discriminant Analysis
2025-11-17 00:02:25,335:INFO:Total runtime is 0.28145951827367144 minutes
2025-11-17 00:02:25,335:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:25,342:INFO:Initializing create_model()
2025-11-17 00:02:25,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:25,342:INFO:Checking exceptions
2025-11-17 00:02:25,342:INFO:Importing libraries
2025-11-17 00:02:25,342:INFO:Copying training dataset
2025-11-17 00:02:25,351:INFO:Defining folds
2025-11-17 00:02:25,351:INFO:Declaring metric variables
2025-11-17 00:02:25,351:INFO:Importing untrained model
2025-11-17 00:02:25,368:INFO:Linear Discriminant Analysis Imported successfully
2025-11-17 00:02:25,383:INFO:Starting cross validation
2025-11-17 00:02:25,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:25,921:INFO:Calculating mean and std
2025-11-17 00:02:25,921:INFO:Creating metrics dataframe
2025-11-17 00:02:25,931:INFO:Uploading results into container
2025-11-17 00:02:25,933:INFO:Uploading model into container now
2025-11-17 00:02:25,936:INFO:_master_model_container: 11
2025-11-17 00:02:25,938:INFO:_display_container: 2
2025-11-17 00:02:25,940:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-17 00:02:25,940:INFO:create_model() successfully completed......................................
2025-11-17 00:02:26,190:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:26,190:INFO:Creating metrics dataframe
2025-11-17 00:02:26,210:INFO:Initializing Extra Trees Classifier
2025-11-17 00:02:26,210:INFO:Total runtime is 0.2960468252499898 minutes
2025-11-17 00:02:26,216:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:26,216:INFO:Initializing create_model()
2025-11-17 00:02:26,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:26,216:INFO:Checking exceptions
2025-11-17 00:02:26,216:INFO:Importing libraries
2025-11-17 00:02:26,216:INFO:Copying training dataset
2025-11-17 00:02:26,224:INFO:Defining folds
2025-11-17 00:02:26,224:INFO:Declaring metric variables
2025-11-17 00:02:26,240:INFO:Importing untrained model
2025-11-17 00:02:26,248:INFO:Extra Trees Classifier Imported successfully
2025-11-17 00:02:26,260:INFO:Starting cross validation
2025-11-17 00:02:26,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:27,916:INFO:Calculating mean and std
2025-11-17 00:02:27,919:INFO:Creating metrics dataframe
2025-11-17 00:02:27,922:INFO:Uploading results into container
2025-11-17 00:02:27,922:INFO:Uploading model into container now
2025-11-17 00:02:27,922:INFO:_master_model_container: 12
2025-11-17 00:02:27,922:INFO:_display_container: 2
2025-11-17 00:02:27,929:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-17 00:02:27,930:INFO:create_model() successfully completed......................................
2025-11-17 00:02:28,121:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:28,121:INFO:Creating metrics dataframe
2025-11-17 00:02:28,144:INFO:Initializing Light Gradient Boosting Machine
2025-11-17 00:02:28,144:INFO:Total runtime is 0.32826785246531165 minutes
2025-11-17 00:02:28,156:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:28,158:INFO:Initializing create_model()
2025-11-17 00:02:28,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:28,158:INFO:Checking exceptions
2025-11-17 00:02:28,158:INFO:Importing libraries
2025-11-17 00:02:28,158:INFO:Copying training dataset
2025-11-17 00:02:28,179:INFO:Defining folds
2025-11-17 00:02:28,180:INFO:Declaring metric variables
2025-11-17 00:02:28,191:INFO:Importing untrained model
2025-11-17 00:02:28,208:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 00:02:28,228:INFO:Starting cross validation
2025-11-17 00:02:28,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:30,328:INFO:Calculating mean and std
2025-11-17 00:02:30,332:INFO:Creating metrics dataframe
2025-11-17 00:02:30,341:INFO:Uploading results into container
2025-11-17 00:02:30,341:INFO:Uploading model into container now
2025-11-17 00:02:30,343:INFO:_master_model_container: 13
2025-11-17 00:02:30,343:INFO:_display_container: 2
2025-11-17 00:02:30,345:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 00:02:30,345:INFO:create_model() successfully completed......................................
2025-11-17 00:02:30,551:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:30,551:INFO:Creating metrics dataframe
2025-11-17 00:02:30,576:INFO:Initializing Dummy Classifier
2025-11-17 00:02:30,576:INFO:Total runtime is 0.3688119490941365 minutes
2025-11-17 00:02:30,585:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:30,588:INFO:Initializing create_model()
2025-11-17 00:02:30,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD55EB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:30,588:INFO:Checking exceptions
2025-11-17 00:02:30,588:INFO:Importing libraries
2025-11-17 00:02:30,588:INFO:Copying training dataset
2025-11-17 00:02:30,602:INFO:Defining folds
2025-11-17 00:02:30,602:INFO:Declaring metric variables
2025-11-17 00:02:30,614:INFO:Importing untrained model
2025-11-17 00:02:30,628:INFO:Dummy Classifier Imported successfully
2025-11-17 00:02:30,648:INFO:Starting cross validation
2025-11-17 00:02:30,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:30,997:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,038:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,047:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,055:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,060:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,097:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,098:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,100:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,206:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,238:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:02:31,250:INFO:Calculating mean and std
2025-11-17 00:02:31,252:INFO:Creating metrics dataframe
2025-11-17 00:02:31,260:INFO:Uploading results into container
2025-11-17 00:02:31,264:INFO:Uploading model into container now
2025-11-17 00:02:31,264:INFO:_master_model_container: 14
2025-11-17 00:02:31,266:INFO:_display_container: 2
2025-11-17 00:02:31,266:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-17 00:02:31,266:INFO:create_model() successfully completed......................................
2025-11-17 00:02:31,456:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:31,456:INFO:Creating metrics dataframe
2025-11-17 00:02:31,485:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-17 00:02:31,511:INFO:Initializing create_model()
2025-11-17 00:02:31,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:31,513:INFO:Checking exceptions
2025-11-17 00:02:31,515:INFO:Importing libraries
2025-11-17 00:02:31,517:INFO:Copying training dataset
2025-11-17 00:02:31,534:INFO:Defining folds
2025-11-17 00:02:31,534:INFO:Declaring metric variables
2025-11-17 00:02:31,534:INFO:Importing untrained model
2025-11-17 00:02:31,534:INFO:Declaring custom model
2025-11-17 00:02:31,539:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:02:31,542:INFO:Cross validation set to False
2025-11-17 00:02:31,543:INFO:Fitting Model
2025-11-17 00:02:31,681:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:02:31,929:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:02:31,929:INFO:create_model() successfully completed......................................
2025-11-17 00:02:32,217:INFO:_master_model_container: 14
2025-11-17 00:02:32,217:INFO:_display_container: 2
2025-11-17 00:02:32,219:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:02:32,219:INFO:compare_models() successfully completed......................................
2025-11-17 00:02:32,292:INFO:Initializing tune_model()
2025-11-17 00:02:32,292:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 00:02:32,292:INFO:Checking exceptions
2025-11-17 00:02:32,385:INFO:Copying training dataset
2025-11-17 00:02:32,402:INFO:Checking base model
2025-11-17 00:02:32,404:INFO:Base model : Ada Boost Classifier
2025-11-17 00:02:32,416:INFO:Declaring metric variables
2025-11-17 00:02:32,433:INFO:Defining Hyperparameters
2025-11-17 00:02:32,737:INFO:Tuning with n_jobs=-1
2025-11-17 00:02:32,739:INFO:Initializing RandomizedSearchCV
2025-11-17 00:02:52,745:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-17 00:02:52,749:INFO:Hyperparameter search completed
2025-11-17 00:02:52,750:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:52,753:INFO:Initializing create_model()
2025-11-17 00:02:52,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-17 00:02:52,754:INFO:Checking exceptions
2025-11-17 00:02:52,754:INFO:Importing libraries
2025-11-17 00:02:52,754:INFO:Copying training dataset
2025-11-17 00:02:52,770:INFO:Defining folds
2025-11-17 00:02:52,770:INFO:Declaring metric variables
2025-11-17 00:02:52,781:INFO:Importing untrained model
2025-11-17 00:02:52,781:INFO:Declaring custom model
2025-11-17 00:02:52,790:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:02:52,809:INFO:Starting cross validation
2025-11-17 00:02:52,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:56,571:INFO:Calculating mean and std
2025-11-17 00:02:56,576:INFO:Creating metrics dataframe
2025-11-17 00:02:56,600:INFO:Finalizing model
2025-11-17 00:02:58,247:INFO:Uploading results into container
2025-11-17 00:02:58,249:INFO:Uploading model into container now
2025-11-17 00:02:58,251:INFO:_master_model_container: 15
2025-11-17 00:02:58,251:INFO:_display_container: 3
2025-11-17 00:02:58,251:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:02:58,251:INFO:create_model() successfully completed......................................
2025-11-17 00:02:58,600:INFO:SubProcess create_model() end ==================================
2025-11-17 00:02:58,600:INFO:choose_better activated
2025-11-17 00:02:58,606:INFO:SubProcess create_model() called ==================================
2025-11-17 00:02:58,607:INFO:Initializing create_model()
2025-11-17 00:02:58,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD3D06D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:02:58,608:INFO:Checking exceptions
2025-11-17 00:02:58,612:INFO:Importing libraries
2025-11-17 00:02:58,612:INFO:Copying training dataset
2025-11-17 00:02:58,620:INFO:Defining folds
2025-11-17 00:02:58,620:INFO:Declaring metric variables
2025-11-17 00:02:58,620:INFO:Importing untrained model
2025-11-17 00:02:58,620:INFO:Declaring custom model
2025-11-17 00:02:58,622:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:02:58,622:INFO:Starting cross validation
2025-11-17 00:02:58,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:02:58,874:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,883:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,896:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,904:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,906:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,908:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,915:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:58,926:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:59,530:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:02:59,539:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:03:00,108:INFO:Calculating mean and std
2025-11-17 00:03:00,108:INFO:Creating metrics dataframe
2025-11-17 00:03:00,113:INFO:Finalizing model
2025-11-17 00:03:00,229:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:03:00,497:INFO:Uploading results into container
2025-11-17 00:03:00,512:INFO:Uploading model into container now
2025-11-17 00:03:00,513:INFO:_master_model_container: 16
2025-11-17 00:03:00,513:INFO:_display_container: 4
2025-11-17 00:03:00,513:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:03:00,513:INFO:create_model() successfully completed......................................
2025-11-17 00:03:00,730:INFO:SubProcess create_model() end ==================================
2025-11-17 00:03:00,730:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-17 00:03:00,730:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.9991
2025-11-17 00:03:00,730:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-17 00:03:00,730:INFO:choose_better completed
2025-11-17 00:03:00,762:INFO:_master_model_container: 16
2025-11-17 00:03:00,762:INFO:_display_container: 3
2025-11-17 00:03:00,762:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:03:00,762:INFO:tune_model() successfully completed......................................
2025-11-17 00:15:46,310:INFO:PyCaret ClassificationExperiment
2025-11-17 00:15:46,310:INFO:Logging name: clf-default-name
2025-11-17 00:15:46,310:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-17 00:15:46,310:INFO:version 3.3.2
2025-11-17 00:15:46,310:INFO:Initializing setup()
2025-11-17 00:15:46,310:INFO:self.USI: e2e6
2025-11-17 00:15:46,310:INFO:self._variable_keys: {'data', '_ml_usecase', 'n_jobs_param', 'log_plots_param', 'X_test', 'y_train', 'exp_id', 'html_param', '_available_plots', 'fix_imbalance', 'seed', 'pipeline', 'exp_name_log', 'fold_shuffle_param', 'X', 'gpu_param', 'fold_groups_param', 'memory', 'X_train', 'y', 'idx', 'y_test', 'fold_generator', 'target_param', 'USI', 'gpu_n_jobs_param', 'logging_param', 'is_multiclass'}
2025-11-17 00:15:46,310:INFO:Checking environment
2025-11-17 00:15:46,310:INFO:python_version: 3.11.4
2025-11-17 00:15:46,310:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-17 00:15:46,310:INFO:machine: AMD64
2025-11-17 00:15:46,310:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-17 00:15:46,310:INFO:Memory: svmem(total=8403275776, available=1832349696, percent=78.2, used=6570926080, free=1832349696)
2025-11-17 00:15:46,310:INFO:Physical Core: 4
2025-11-17 00:15:46,310:INFO:Logical Core: 8
2025-11-17 00:15:46,310:INFO:Checking libraries
2025-11-17 00:15:46,310:INFO:System:
2025-11-17 00:15:46,310:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-17 00:15:46,310:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-17 00:15:46,310:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-17 00:15:46,310:INFO:PyCaret required dependencies:
2025-11-17 00:15:46,310:INFO:                 pip: 23.1.2
2025-11-17 00:15:46,310:INFO:          setuptools: 80.9.0
2025-11-17 00:15:46,310:INFO:             pycaret: 3.3.2
2025-11-17 00:15:46,310:INFO:             IPython: 9.6.0
2025-11-17 00:15:46,310:INFO:          ipywidgets: 8.1.7
2025-11-17 00:15:46,310:INFO:                tqdm: 4.67.1
2025-11-17 00:15:46,310:INFO:               numpy: 1.26.4
2025-11-17 00:15:46,310:INFO:              pandas: 2.1.4
2025-11-17 00:15:46,310:INFO:              jinja2: 3.1.6
2025-11-17 00:15:46,310:INFO:               scipy: 1.11.4
2025-11-17 00:15:46,310:INFO:              joblib: 1.3.2
2025-11-17 00:15:46,310:INFO:             sklearn: 1.4.2
2025-11-17 00:15:46,310:INFO:                pyod: 2.0.5
2025-11-17 00:15:46,310:INFO:            imblearn: 0.14.0
2025-11-17 00:15:46,310:INFO:   category_encoders: 2.7.0
2025-11-17 00:15:46,310:INFO:            lightgbm: 4.6.0
2025-11-17 00:15:46,310:INFO:               numba: 0.61.0
2025-11-17 00:15:46,310:INFO:            requests: 2.32.5
2025-11-17 00:15:46,310:INFO:          matplotlib: 3.7.5
2025-11-17 00:15:46,310:INFO:          scikitplot: 0.3.7
2025-11-17 00:15:46,310:INFO:         yellowbrick: 1.5
2025-11-17 00:15:46,310:INFO:              plotly: 5.24.1
2025-11-17 00:15:46,310:INFO:    plotly-resampler: Not installed
2025-11-17 00:15:46,310:INFO:             kaleido: 1.1.0
2025-11-17 00:15:46,310:INFO:           schemdraw: 0.15
2025-11-17 00:15:46,310:INFO:         statsmodels: 0.14.5
2025-11-17 00:15:46,310:INFO:              sktime: 0.26.0
2025-11-17 00:15:46,310:INFO:               tbats: 1.1.3
2025-11-17 00:15:46,310:INFO:            pmdarima: 2.0.4
2025-11-17 00:15:46,310:INFO:              psutil: 7.1.2
2025-11-17 00:15:46,310:INFO:          markupsafe: 3.0.3
2025-11-17 00:15:46,310:INFO:             pickle5: Not installed
2025-11-17 00:15:46,310:INFO:         cloudpickle: 3.1.1
2025-11-17 00:15:46,310:INFO:         deprecation: 2.1.0
2025-11-17 00:15:46,310:INFO:              xxhash: 3.6.0
2025-11-17 00:15:46,310:INFO:           wurlitzer: Not installed
2025-11-17 00:15:46,310:INFO:PyCaret optional dependencies:
2025-11-17 00:15:46,310:INFO:                shap: 0.44.1
2025-11-17 00:15:46,310:INFO:           interpret: 0.7.3
2025-11-17 00:15:46,310:INFO:                umap: 0.5.7
2025-11-17 00:15:46,310:INFO:     ydata_profiling: 4.17.0
2025-11-17 00:15:46,310:INFO:  explainerdashboard: 0.5.1
2025-11-17 00:15:46,310:INFO:             autoviz: Not installed
2025-11-17 00:15:46,320:INFO:           fairlearn: 0.7.0
2025-11-17 00:15:46,320:INFO:          deepchecks: Not installed
2025-11-17 00:15:46,320:INFO:             xgboost: Not installed
2025-11-17 00:15:46,320:INFO:            catboost: Not installed
2025-11-17 00:15:46,320:INFO:              kmodes: Not installed
2025-11-17 00:15:46,320:INFO:             mlxtend: Not installed
2025-11-17 00:15:46,320:INFO:       statsforecast: Not installed
2025-11-17 00:15:46,320:INFO:        tune_sklearn: Not installed
2025-11-17 00:15:46,321:INFO:                 ray: Not installed
2025-11-17 00:15:46,321:INFO:            hyperopt: Not installed
2025-11-17 00:15:46,321:INFO:              optuna: Not installed
2025-11-17 00:15:46,321:INFO:               skopt: Not installed
2025-11-17 00:15:46,321:INFO:              mlflow: 3.5.1
2025-11-17 00:15:46,322:INFO:              gradio: Not installed
2025-11-17 00:15:46,322:INFO:             fastapi: 0.121.0
2025-11-17 00:15:46,322:INFO:             uvicorn: 0.38.0
2025-11-17 00:15:46,322:INFO:              m2cgen: Not installed
2025-11-17 00:15:46,322:INFO:           evidently: Not installed
2025-11-17 00:15:46,322:INFO:               fugue: Not installed
2025-11-17 00:15:46,322:INFO:           streamlit: Not installed
2025-11-17 00:15:46,322:INFO:             prophet: Not installed
2025-11-17 00:15:46,322:INFO:None
2025-11-17 00:15:46,322:INFO:Set up data.
2025-11-17 00:15:46,322:INFO:Set up folding strategy.
2025-11-17 00:15:46,322:INFO:Set up train/test split.
2025-11-17 00:15:46,339:INFO:Set up index.
2025-11-17 00:15:46,339:INFO:Assigning column types.
2025-11-17 00:15:46,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-17 00:15:46,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:15:46,441:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:15:46,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:15:46,560:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:15:46,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,638:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-17 00:15:46,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:15:46,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:15:46,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:46,978:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-17 00:15:47,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:47,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:47,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:47,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:47,269:INFO:Preparing preprocessing pipeline...
2025-11-17 00:15:47,271:INFO:Set up simple imputation.
2025-11-17 00:15:47,275:INFO:Set up encoding of ordinal features.
2025-11-17 00:15:47,277:INFO:Set up encoding of categorical features.
2025-11-17 00:15:47,277:INFO:Set up imbalanced handling.
2025-11-17 00:15:47,277:INFO:Set up feature normalization.
2025-11-17 00:15:47,586:INFO:Finished creating preprocessing pipeline.
2025-11-17 00:15:47,638:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-17 00:15:47,638:INFO:Creating final display dataframe.
2025-11-17 00:15:48,309:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              e2e6
2025-11-17 00:15:48,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:48,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:48,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:48,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:15:48,893:INFO:setup() successfully completed in 2.74s...............
2025-11-17 00:15:49,089:INFO:Initializing compare_models()
2025-11-17 00:15:49,089:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-17 00:15:49,091:INFO:Checking exceptions
2025-11-17 00:15:49,099:INFO:Preparing display monitor
2025-11-17 00:15:49,158:INFO:Initializing Logistic Regression
2025-11-17 00:15:49,158:INFO:Total runtime is 0.0 minutes
2025-11-17 00:15:49,167:INFO:SubProcess create_model() called ==================================
2025-11-17 00:15:49,167:INFO:Initializing create_model()
2025-11-17 00:15:49,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:15:49,169:INFO:Checking exceptions
2025-11-17 00:15:49,169:INFO:Importing libraries
2025-11-17 00:15:49,169:INFO:Copying training dataset
2025-11-17 00:15:49,181:INFO:Defining folds
2025-11-17 00:15:49,181:INFO:Declaring metric variables
2025-11-17 00:15:49,193:INFO:Importing untrained model
2025-11-17 00:15:49,199:INFO:Logistic Regression Imported successfully
2025-11-17 00:15:49,218:INFO:Starting cross validation
2025-11-17 00:15:49,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:15:59,462:INFO:Calculating mean and std
2025-11-17 00:15:59,464:INFO:Creating metrics dataframe
2025-11-17 00:15:59,468:INFO:Uploading results into container
2025-11-17 00:15:59,470:INFO:Uploading model into container now
2025-11-17 00:15:59,470:INFO:_master_model_container: 1
2025-11-17 00:15:59,471:INFO:_display_container: 2
2025-11-17 00:15:59,472:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-17 00:15:59,472:INFO:create_model() successfully completed......................................
2025-11-17 00:15:59,673:INFO:SubProcess create_model() end ==================================
2025-11-17 00:15:59,673:INFO:Creating metrics dataframe
2025-11-17 00:15:59,685:INFO:Initializing K Neighbors Classifier
2025-11-17 00:15:59,688:INFO:Total runtime is 0.17550238370895385 minutes
2025-11-17 00:15:59,692:INFO:SubProcess create_model() called ==================================
2025-11-17 00:15:59,694:INFO:Initializing create_model()
2025-11-17 00:15:59,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:15:59,694:INFO:Checking exceptions
2025-11-17 00:15:59,694:INFO:Importing libraries
2025-11-17 00:15:59,694:INFO:Copying training dataset
2025-11-17 00:15:59,701:INFO:Defining folds
2025-11-17 00:15:59,701:INFO:Declaring metric variables
2025-11-17 00:15:59,712:INFO:Importing untrained model
2025-11-17 00:15:59,716:INFO:K Neighbors Classifier Imported successfully
2025-11-17 00:15:59,741:INFO:Starting cross validation
2025-11-17 00:15:59,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:00,336:INFO:Calculating mean and std
2025-11-17 00:16:00,338:INFO:Creating metrics dataframe
2025-11-17 00:16:00,346:INFO:Uploading results into container
2025-11-17 00:16:00,349:INFO:Uploading model into container now
2025-11-17 00:16:00,349:INFO:_master_model_container: 2
2025-11-17 00:16:00,349:INFO:_display_container: 2
2025-11-17 00:16:00,349:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-17 00:16:00,349:INFO:create_model() successfully completed......................................
2025-11-17 00:16:00,668:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:00,668:INFO:Creating metrics dataframe
2025-11-17 00:16:00,705:INFO:Initializing Naive Bayes
2025-11-17 00:16:00,705:INFO:Total runtime is 0.1924550414085388 minutes
2025-11-17 00:16:00,714:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:00,714:INFO:Initializing create_model()
2025-11-17 00:16:00,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:00,714:INFO:Checking exceptions
2025-11-17 00:16:00,714:INFO:Importing libraries
2025-11-17 00:16:00,714:INFO:Copying training dataset
2025-11-17 00:16:00,751:INFO:Defining folds
2025-11-17 00:16:00,751:INFO:Declaring metric variables
2025-11-17 00:16:00,770:INFO:Importing untrained model
2025-11-17 00:16:00,783:INFO:Naive Bayes Imported successfully
2025-11-17 00:16:00,816:INFO:Starting cross validation
2025-11-17 00:16:00,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:01,321:INFO:Calculating mean and std
2025-11-17 00:16:01,321:INFO:Creating metrics dataframe
2025-11-17 00:16:01,327:INFO:Uploading results into container
2025-11-17 00:16:01,327:INFO:Uploading model into container now
2025-11-17 00:16:01,327:INFO:_master_model_container: 3
2025-11-17 00:16:01,327:INFO:_display_container: 2
2025-11-17 00:16:01,327:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-17 00:16:01,327:INFO:create_model() successfully completed......................................
2025-11-17 00:16:01,613:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:01,613:INFO:Creating metrics dataframe
2025-11-17 00:16:01,655:INFO:Initializing Decision Tree Classifier
2025-11-17 00:16:01,655:INFO:Total runtime is 0.20828147729237872 minutes
2025-11-17 00:16:01,671:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:01,671:INFO:Initializing create_model()
2025-11-17 00:16:01,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:01,671:INFO:Checking exceptions
2025-11-17 00:16:01,671:INFO:Importing libraries
2025-11-17 00:16:01,671:INFO:Copying training dataset
2025-11-17 00:16:01,738:INFO:Defining folds
2025-11-17 00:16:01,738:INFO:Declaring metric variables
2025-11-17 00:16:01,766:INFO:Importing untrained model
2025-11-17 00:16:01,788:INFO:Decision Tree Classifier Imported successfully
2025-11-17 00:16:01,829:INFO:Starting cross validation
2025-11-17 00:16:01,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:02,419:INFO:Calculating mean and std
2025-11-17 00:16:02,419:INFO:Creating metrics dataframe
2025-11-17 00:16:02,429:INFO:Uploading results into container
2025-11-17 00:16:02,429:INFO:Uploading model into container now
2025-11-17 00:16:02,434:INFO:_master_model_container: 4
2025-11-17 00:16:02,435:INFO:_display_container: 2
2025-11-17 00:16:02,437:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-17 00:16:02,437:INFO:create_model() successfully completed......................................
2025-11-17 00:16:02,718:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:02,718:INFO:Creating metrics dataframe
2025-11-17 00:16:02,754:INFO:Initializing SVM - Linear Kernel
2025-11-17 00:16:02,754:INFO:Total runtime is 0.2266097585360209 minutes
2025-11-17 00:16:02,769:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:02,769:INFO:Initializing create_model()
2025-11-17 00:16:02,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:02,769:INFO:Checking exceptions
2025-11-17 00:16:02,769:INFO:Importing libraries
2025-11-17 00:16:02,769:INFO:Copying training dataset
2025-11-17 00:16:02,795:INFO:Defining folds
2025-11-17 00:16:02,795:INFO:Declaring metric variables
2025-11-17 00:16:02,814:INFO:Importing untrained model
2025-11-17 00:16:02,833:INFO:SVM - Linear Kernel Imported successfully
2025-11-17 00:16:02,854:INFO:Starting cross validation
2025-11-17 00:16:02,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:03,389:INFO:Calculating mean and std
2025-11-17 00:16:03,390:INFO:Creating metrics dataframe
2025-11-17 00:16:03,395:INFO:Uploading results into container
2025-11-17 00:16:03,396:INFO:Uploading model into container now
2025-11-17 00:16:03,397:INFO:_master_model_container: 5
2025-11-17 00:16:03,398:INFO:_display_container: 2
2025-11-17 00:16:03,398:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-17 00:16:03,398:INFO:create_model() successfully completed......................................
2025-11-17 00:16:03,575:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:03,575:INFO:Creating metrics dataframe
2025-11-17 00:16:03,620:INFO:Initializing Ridge Classifier
2025-11-17 00:16:03,620:INFO:Total runtime is 0.24103769858678178 minutes
2025-11-17 00:16:03,629:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:03,629:INFO:Initializing create_model()
2025-11-17 00:16:03,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:03,629:INFO:Checking exceptions
2025-11-17 00:16:03,629:INFO:Importing libraries
2025-11-17 00:16:03,629:INFO:Copying training dataset
2025-11-17 00:16:03,669:INFO:Defining folds
2025-11-17 00:16:03,672:INFO:Declaring metric variables
2025-11-17 00:16:03,685:INFO:Importing untrained model
2025-11-17 00:16:03,709:INFO:Ridge Classifier Imported successfully
2025-11-17 00:16:03,740:INFO:Starting cross validation
2025-11-17 00:16:03,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:04,296:INFO:Calculating mean and std
2025-11-17 00:16:04,296:INFO:Creating metrics dataframe
2025-11-17 00:16:04,296:INFO:Uploading results into container
2025-11-17 00:16:04,309:INFO:Uploading model into container now
2025-11-17 00:16:04,309:INFO:_master_model_container: 6
2025-11-17 00:16:04,313:INFO:_display_container: 2
2025-11-17 00:16:04,313:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-17 00:16:04,315:INFO:create_model() successfully completed......................................
2025-11-17 00:16:04,667:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:04,670:INFO:Creating metrics dataframe
2025-11-17 00:16:04,712:INFO:Initializing Random Forest Classifier
2025-11-17 00:16:04,712:INFO:Total runtime is 0.25924216508865355 minutes
2025-11-17 00:16:04,729:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:04,729:INFO:Initializing create_model()
2025-11-17 00:16:04,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:04,729:INFO:Checking exceptions
2025-11-17 00:16:04,729:INFO:Importing libraries
2025-11-17 00:16:04,734:INFO:Copying training dataset
2025-11-17 00:16:04,752:INFO:Defining folds
2025-11-17 00:16:04,752:INFO:Declaring metric variables
2025-11-17 00:16:04,777:INFO:Importing untrained model
2025-11-17 00:16:04,802:INFO:Random Forest Classifier Imported successfully
2025-11-17 00:16:04,836:INFO:Starting cross validation
2025-11-17 00:16:04,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:06,285:INFO:Calculating mean and std
2025-11-17 00:16:06,285:INFO:Creating metrics dataframe
2025-11-17 00:16:06,285:INFO:Uploading results into container
2025-11-17 00:16:06,285:INFO:Uploading model into container now
2025-11-17 00:16:06,285:INFO:_master_model_container: 7
2025-11-17 00:16:06,285:INFO:_display_container: 2
2025-11-17 00:16:06,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-17 00:16:06,285:INFO:create_model() successfully completed......................................
2025-11-17 00:16:06,594:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:06,594:INFO:Creating metrics dataframe
2025-11-17 00:16:06,629:INFO:Initializing Quadratic Discriminant Analysis
2025-11-17 00:16:06,629:INFO:Total runtime is 0.29118343194325763 minutes
2025-11-17 00:16:06,637:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:06,643:INFO:Initializing create_model()
2025-11-17 00:16:06,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:06,644:INFO:Checking exceptions
2025-11-17 00:16:06,644:INFO:Importing libraries
2025-11-17 00:16:06,644:INFO:Copying training dataset
2025-11-17 00:16:06,666:INFO:Defining folds
2025-11-17 00:16:06,666:INFO:Declaring metric variables
2025-11-17 00:16:06,684:INFO:Importing untrained model
2025-11-17 00:16:06,696:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-17 00:16:06,728:INFO:Starting cross validation
2025-11-17 00:16:06,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:07,005:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,007:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,011:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,013:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,023:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,027:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,029:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,044:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,161:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,173:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:16:07,223:INFO:Calculating mean and std
2025-11-17 00:16:07,223:INFO:Creating metrics dataframe
2025-11-17 00:16:07,231:INFO:Uploading results into container
2025-11-17 00:16:07,231:INFO:Uploading model into container now
2025-11-17 00:16:07,231:INFO:_master_model_container: 8
2025-11-17 00:16:07,231:INFO:_display_container: 2
2025-11-17 00:16:07,231:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-17 00:16:07,231:INFO:create_model() successfully completed......................................
2025-11-17 00:16:07,508:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:07,508:INFO:Creating metrics dataframe
2025-11-17 00:16:07,560:INFO:Initializing Ada Boost Classifier
2025-11-17 00:16:07,562:INFO:Total runtime is 0.30673717657725014 minutes
2025-11-17 00:16:07,577:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:07,578:INFO:Initializing create_model()
2025-11-17 00:16:07,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:07,578:INFO:Checking exceptions
2025-11-17 00:16:07,578:INFO:Importing libraries
2025-11-17 00:16:07,578:INFO:Copying training dataset
2025-11-17 00:16:07,601:INFO:Defining folds
2025-11-17 00:16:07,601:INFO:Declaring metric variables
2025-11-17 00:16:07,619:INFO:Importing untrained model
2025-11-17 00:16:07,645:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:16:07,682:INFO:Starting cross validation
2025-11-17 00:16:07,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:07,990:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:07,993:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,001:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,003:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,010:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,024:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,029:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,397:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,411:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:08,799:INFO:Calculating mean and std
2025-11-17 00:16:08,802:INFO:Creating metrics dataframe
2025-11-17 00:16:08,810:INFO:Uploading results into container
2025-11-17 00:16:08,810:INFO:Uploading model into container now
2025-11-17 00:16:08,810:INFO:_master_model_container: 9
2025-11-17 00:16:08,816:INFO:_display_container: 2
2025-11-17 00:16:08,816:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:16:08,816:INFO:create_model() successfully completed......................................
2025-11-17 00:16:09,003:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:09,003:INFO:Creating metrics dataframe
2025-11-17 00:16:09,026:INFO:Initializing Gradient Boosting Classifier
2025-11-17 00:16:09,026:INFO:Total runtime is 0.3311373194058736 minutes
2025-11-17 00:16:09,032:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:09,040:INFO:Initializing create_model()
2025-11-17 00:16:09,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:09,042:INFO:Checking exceptions
2025-11-17 00:16:09,042:INFO:Importing libraries
2025-11-17 00:16:09,042:INFO:Copying training dataset
2025-11-17 00:16:09,056:INFO:Defining folds
2025-11-17 00:16:09,059:INFO:Declaring metric variables
2025-11-17 00:16:09,072:INFO:Importing untrained model
2025-11-17 00:16:09,081:INFO:Gradient Boosting Classifier Imported successfully
2025-11-17 00:16:09,116:INFO:Starting cross validation
2025-11-17 00:16:09,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:10,370:INFO:Calculating mean and std
2025-11-17 00:16:10,370:INFO:Creating metrics dataframe
2025-11-17 00:16:10,375:INFO:Uploading results into container
2025-11-17 00:16:10,375:INFO:Uploading model into container now
2025-11-17 00:16:10,377:INFO:_master_model_container: 10
2025-11-17 00:16:10,377:INFO:_display_container: 2
2025-11-17 00:16:10,377:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-17 00:16:10,377:INFO:create_model() successfully completed......................................
2025-11-17 00:16:10,542:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:10,549:INFO:Creating metrics dataframe
2025-11-17 00:16:10,583:INFO:Initializing Linear Discriminant Analysis
2025-11-17 00:16:10,583:INFO:Total runtime is 0.3570887287457784 minutes
2025-11-17 00:16:10,601:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:10,603:INFO:Initializing create_model()
2025-11-17 00:16:10,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:10,603:INFO:Checking exceptions
2025-11-17 00:16:10,603:INFO:Importing libraries
2025-11-17 00:16:10,605:INFO:Copying training dataset
2025-11-17 00:16:10,626:INFO:Defining folds
2025-11-17 00:16:10,626:INFO:Declaring metric variables
2025-11-17 00:16:10,646:INFO:Importing untrained model
2025-11-17 00:16:10,667:INFO:Linear Discriminant Analysis Imported successfully
2025-11-17 00:16:10,702:INFO:Starting cross validation
2025-11-17 00:16:10,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:11,200:INFO:Calculating mean and std
2025-11-17 00:16:11,202:INFO:Creating metrics dataframe
2025-11-17 00:16:11,202:INFO:Uploading results into container
2025-11-17 00:16:11,202:INFO:Uploading model into container now
2025-11-17 00:16:11,209:INFO:_master_model_container: 11
2025-11-17 00:16:11,209:INFO:_display_container: 2
2025-11-17 00:16:11,209:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-17 00:16:11,212:INFO:create_model() successfully completed......................................
2025-11-17 00:16:11,472:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:11,472:INFO:Creating metrics dataframe
2025-11-17 00:16:11,498:INFO:Initializing Extra Trees Classifier
2025-11-17 00:16:11,498:INFO:Total runtime is 0.3723398566246033 minutes
2025-11-17 00:16:11,504:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:11,504:INFO:Initializing create_model()
2025-11-17 00:16:11,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:11,507:INFO:Checking exceptions
2025-11-17 00:16:11,508:INFO:Importing libraries
2025-11-17 00:16:11,508:INFO:Copying training dataset
2025-11-17 00:16:11,511:INFO:Defining folds
2025-11-17 00:16:11,511:INFO:Declaring metric variables
2025-11-17 00:16:11,523:INFO:Importing untrained model
2025-11-17 00:16:11,528:INFO:Extra Trees Classifier Imported successfully
2025-11-17 00:16:11,548:INFO:Starting cross validation
2025-11-17 00:16:11,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:12,639:INFO:Calculating mean and std
2025-11-17 00:16:12,639:INFO:Creating metrics dataframe
2025-11-17 00:16:12,639:INFO:Uploading results into container
2025-11-17 00:16:12,639:INFO:Uploading model into container now
2025-11-17 00:16:12,639:INFO:_master_model_container: 12
2025-11-17 00:16:12,639:INFO:_display_container: 2
2025-11-17 00:16:12,639:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-17 00:16:12,639:INFO:create_model() successfully completed......................................
2025-11-17 00:16:12,929:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:12,929:INFO:Creating metrics dataframe
2025-11-17 00:16:12,943:INFO:Initializing Light Gradient Boosting Machine
2025-11-17 00:16:12,943:INFO:Total runtime is 0.39641613960266114 minutes
2025-11-17 00:16:12,963:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:12,963:INFO:Initializing create_model()
2025-11-17 00:16:12,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:12,964:INFO:Checking exceptions
2025-11-17 00:16:12,964:INFO:Importing libraries
2025-11-17 00:16:12,964:INFO:Copying training dataset
2025-11-17 00:16:12,985:INFO:Defining folds
2025-11-17 00:16:12,985:INFO:Declaring metric variables
2025-11-17 00:16:12,998:INFO:Importing untrained model
2025-11-17 00:16:13,013:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 00:16:13,079:INFO:Starting cross validation
2025-11-17 00:16:13,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:14,384:INFO:Calculating mean and std
2025-11-17 00:16:14,386:INFO:Creating metrics dataframe
2025-11-17 00:16:14,388:INFO:Uploading results into container
2025-11-17 00:16:14,388:INFO:Uploading model into container now
2025-11-17 00:16:14,390:INFO:_master_model_container: 13
2025-11-17 00:16:14,390:INFO:_display_container: 2
2025-11-17 00:16:14,392:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 00:16:14,392:INFO:create_model() successfully completed......................................
2025-11-17 00:16:14,540:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:14,540:INFO:Creating metrics dataframe
2025-11-17 00:16:14,572:INFO:Initializing Dummy Classifier
2025-11-17 00:16:14,573:INFO:Total runtime is 0.42359281380971275 minutes
2025-11-17 00:16:14,587:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:14,588:INFO:Initializing create_model()
2025-11-17 00:16:14,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF90A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:14,589:INFO:Checking exceptions
2025-11-17 00:16:14,589:INFO:Importing libraries
2025-11-17 00:16:14,590:INFO:Copying training dataset
2025-11-17 00:16:14,606:INFO:Defining folds
2025-11-17 00:16:14,612:INFO:Declaring metric variables
2025-11-17 00:16:14,624:INFO:Importing untrained model
2025-11-17 00:16:14,647:INFO:Dummy Classifier Imported successfully
2025-11-17 00:16:14,680:INFO:Starting cross validation
2025-11-17 00:16:14,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:15,027:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,034:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,034:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,034:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,038:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,041:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,047:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,054:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,157:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,180:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:16:15,198:INFO:Calculating mean and std
2025-11-17 00:16:15,198:INFO:Creating metrics dataframe
2025-11-17 00:16:15,209:INFO:Uploading results into container
2025-11-17 00:16:15,211:INFO:Uploading model into container now
2025-11-17 00:16:15,213:INFO:_master_model_container: 14
2025-11-17 00:16:15,213:INFO:_display_container: 2
2025-11-17 00:16:15,215:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-17 00:16:15,215:INFO:create_model() successfully completed......................................
2025-11-17 00:16:15,456:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:15,456:INFO:Creating metrics dataframe
2025-11-17 00:16:15,485:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-17 00:16:15,505:INFO:Initializing create_model()
2025-11-17 00:16:15,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:15,507:INFO:Checking exceptions
2025-11-17 00:16:15,509:INFO:Importing libraries
2025-11-17 00:16:15,509:INFO:Copying training dataset
2025-11-17 00:16:15,513:INFO:Defining folds
2025-11-17 00:16:15,513:INFO:Declaring metric variables
2025-11-17 00:16:15,513:INFO:Importing untrained model
2025-11-17 00:16:15,513:INFO:Declaring custom model
2025-11-17 00:16:15,513:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:16:15,523:INFO:Cross validation set to False
2025-11-17 00:16:15,523:INFO:Fitting Model
2025-11-17 00:16:15,632:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:16:15,947:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:16:15,947:INFO:create_model() successfully completed......................................
2025-11-17 00:16:16,299:INFO:_master_model_container: 14
2025-11-17 00:16:16,299:INFO:_display_container: 2
2025-11-17 00:16:16,299:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:16:16,299:INFO:compare_models() successfully completed......................................
2025-11-17 00:16:16,459:INFO:Initializing tune_model()
2025-11-17 00:16:16,459:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 00:16:16,459:INFO:Checking exceptions
2025-11-17 00:16:16,509:INFO:Copying training dataset
2025-11-17 00:16:16,519:INFO:Checking base model
2025-11-17 00:16:16,519:INFO:Base model : Ada Boost Classifier
2025-11-17 00:16:16,531:INFO:Declaring metric variables
2025-11-17 00:16:16,542:INFO:Defining Hyperparameters
2025-11-17 00:16:16,779:INFO:Tuning with n_jobs=-1
2025-11-17 00:16:16,779:INFO:Initializing RandomizedSearchCV
2025-11-17 00:16:29,243:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-17 00:16:29,243:INFO:Hyperparameter search completed
2025-11-17 00:16:29,243:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:29,247:INFO:Initializing create_model()
2025-11-17 00:16:29,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF92C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-17 00:16:29,247:INFO:Checking exceptions
2025-11-17 00:16:29,247:INFO:Importing libraries
2025-11-17 00:16:29,247:INFO:Copying training dataset
2025-11-17 00:16:29,255:INFO:Defining folds
2025-11-17 00:16:29,255:INFO:Declaring metric variables
2025-11-17 00:16:29,260:INFO:Importing untrained model
2025-11-17 00:16:29,260:INFO:Declaring custom model
2025-11-17 00:16:29,266:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:16:29,277:INFO:Starting cross validation
2025-11-17 00:16:29,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:31,894:INFO:Calculating mean and std
2025-11-17 00:16:31,897:INFO:Creating metrics dataframe
2025-11-17 00:16:31,905:INFO:Finalizing model
2025-11-17 00:16:32,849:INFO:Uploading results into container
2025-11-17 00:16:32,849:INFO:Uploading model into container now
2025-11-17 00:16:32,851:INFO:_master_model_container: 15
2025-11-17 00:16:32,851:INFO:_display_container: 3
2025-11-17 00:16:32,851:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:16:32,851:INFO:create_model() successfully completed......................................
2025-11-17 00:16:33,038:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:33,038:INFO:choose_better activated
2025-11-17 00:16:33,045:INFO:SubProcess create_model() called ==================================
2025-11-17 00:16:33,047:INFO:Initializing create_model()
2025-11-17 00:16:33,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:16:33,048:INFO:Checking exceptions
2025-11-17 00:16:33,051:INFO:Importing libraries
2025-11-17 00:16:33,051:INFO:Copying training dataset
2025-11-17 00:16:33,059:INFO:Defining folds
2025-11-17 00:16:33,059:INFO:Declaring metric variables
2025-11-17 00:16:33,061:INFO:Importing untrained model
2025-11-17 00:16:33,061:INFO:Declaring custom model
2025-11-17 00:16:33,062:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:16:33,062:INFO:Starting cross validation
2025-11-17 00:16:33,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:16:33,266:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,268:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,277:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,281:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,291:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,299:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,307:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,317:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,754:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:33,761:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:16:34,023:INFO:Calculating mean and std
2025-11-17 00:16:34,023:INFO:Creating metrics dataframe
2025-11-17 00:16:34,029:INFO:Finalizing model
2025-11-17 00:16:34,203:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:16:34,666:INFO:Uploading results into container
2025-11-17 00:16:34,668:INFO:Uploading model into container now
2025-11-17 00:16:34,668:INFO:_master_model_container: 16
2025-11-17 00:16:34,668:INFO:_display_container: 4
2025-11-17 00:16:34,668:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:16:34,668:INFO:create_model() successfully completed......................................
2025-11-17 00:16:34,835:INFO:SubProcess create_model() end ==================================
2025-11-17 00:16:34,844:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-17 00:16:34,844:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.999
2025-11-17 00:16:34,844:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-17 00:16:34,844:INFO:choose_better completed
2025-11-17 00:16:34,867:INFO:_master_model_container: 16
2025-11-17 00:16:34,868:INFO:_display_container: 3
2025-11-17 00:16:34,869:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:16:34,869:INFO:tune_model() successfully completed......................................
2025-11-17 00:16:50,049:INFO:Initializing tune_model()
2025-11-17 00:16:50,049:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 00:16:50,052:INFO:Checking exceptions
2025-11-17 00:16:50,123:INFO:Copying training dataset
2025-11-17 00:16:50,137:INFO:Checking base model
2025-11-17 00:16:50,137:INFO:Base model : Ada Boost Classifier
2025-11-17 00:16:50,151:INFO:Declaring metric variables
2025-11-17 00:16:50,165:INFO:Defining Hyperparameters
2025-11-17 00:16:50,433:INFO:Tuning with n_jobs=-1
2025-11-17 00:16:50,433:INFO:Initializing RandomizedSearchCV
2025-11-17 00:17:03,201:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-17 00:17:03,201:INFO:Hyperparameter search completed
2025-11-17 00:17:03,201:INFO:SubProcess create_model() called ==================================
2025-11-17 00:17:03,201:INFO:Initializing create_model()
2025-11-17 00:17:03,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CCF92C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-17 00:17:03,201:INFO:Checking exceptions
2025-11-17 00:17:03,201:INFO:Importing libraries
2025-11-17 00:17:03,201:INFO:Copying training dataset
2025-11-17 00:17:03,215:INFO:Defining folds
2025-11-17 00:17:03,215:INFO:Declaring metric variables
2025-11-17 00:17:03,215:INFO:Importing untrained model
2025-11-17 00:17:03,215:INFO:Declaring custom model
2025-11-17 00:17:03,230:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:17:03,244:INFO:Starting cross validation
2025-11-17 00:17:03,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:17:05,409:INFO:Calculating mean and std
2025-11-17 00:17:05,412:INFO:Creating metrics dataframe
2025-11-17 00:17:05,416:INFO:Finalizing model
2025-11-17 00:17:06,397:INFO:Uploading results into container
2025-11-17 00:17:06,400:INFO:Uploading model into container now
2025-11-17 00:17:06,400:INFO:_master_model_container: 17
2025-11-17 00:17:06,400:INFO:_display_container: 4
2025-11-17 00:17:06,400:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:17:06,400:INFO:create_model() successfully completed......................................
2025-11-17 00:17:06,580:INFO:SubProcess create_model() end ==================================
2025-11-17 00:17:06,580:INFO:choose_better activated
2025-11-17 00:17:06,591:INFO:SubProcess create_model() called ==================================
2025-11-17 00:17:06,592:INFO:Initializing create_model()
2025-11-17 00:17:06,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CD9DF610>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:17:06,593:INFO:Checking exceptions
2025-11-17 00:17:06,597:INFO:Importing libraries
2025-11-17 00:17:06,597:INFO:Copying training dataset
2025-11-17 00:17:06,599:INFO:Defining folds
2025-11-17 00:17:06,599:INFO:Declaring metric variables
2025-11-17 00:17:06,599:INFO:Importing untrained model
2025-11-17 00:17:06,599:INFO:Declaring custom model
2025-11-17 00:17:06,599:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:17:06,607:INFO:Starting cross validation
2025-11-17 00:17:06,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:17:06,867:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,871:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,871:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,879:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,883:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,890:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,893:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:06,896:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:07,276:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:07,281:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:17:07,501:INFO:Calculating mean and std
2025-11-17 00:17:07,501:INFO:Creating metrics dataframe
2025-11-17 00:17:07,505:INFO:Finalizing model
2025-11-17 00:17:07,618:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:17:07,728:INFO:Uploading results into container
2025-11-17 00:17:07,728:INFO:Uploading model into container now
2025-11-17 00:17:07,728:INFO:_master_model_container: 18
2025-11-17 00:17:07,728:INFO:_display_container: 5
2025-11-17 00:17:07,741:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:17:07,741:INFO:create_model() successfully completed......................................
2025-11-17 00:17:07,876:INFO:SubProcess create_model() end ==================================
2025-11-17 00:17:07,876:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-17 00:17:07,876:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.999
2025-11-17 00:17:07,876:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-17 00:17:07,876:INFO:choose_better completed
2025-11-17 00:17:07,905:INFO:_master_model_container: 18
2025-11-17 00:17:07,905:INFO:_display_container: 4
2025-11-17 00:17:07,906:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:17:07,906:INFO:tune_model() successfully completed......................................
2025-11-17 00:18:35,818:INFO:PyCaret ClassificationExperiment
2025-11-17 00:18:35,824:INFO:Logging name: clf-default-name
2025-11-17 00:18:35,824:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-17 00:18:35,824:INFO:version 3.3.2
2025-11-17 00:18:35,824:INFO:Initializing setup()
2025-11-17 00:18:35,824:INFO:self.USI: a01d
2025-11-17 00:18:35,824:INFO:self._variable_keys: {'data', '_ml_usecase', 'n_jobs_param', 'log_plots_param', 'X_test', 'y_train', 'exp_id', 'html_param', '_available_plots', 'fix_imbalance', 'seed', 'pipeline', 'exp_name_log', 'fold_shuffle_param', 'X', 'gpu_param', 'fold_groups_param', 'memory', 'X_train', 'y', 'idx', 'y_test', 'fold_generator', 'target_param', 'USI', 'gpu_n_jobs_param', 'logging_param', 'is_multiclass'}
2025-11-17 00:18:35,824:INFO:Checking environment
2025-11-17 00:18:35,826:INFO:python_version: 3.11.4
2025-11-17 00:18:35,826:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-17 00:18:35,826:INFO:machine: AMD64
2025-11-17 00:18:35,826:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-17 00:18:35,826:INFO:Memory: svmem(total=8403275776, available=1430515712, percent=83.0, used=6972760064, free=1430515712)
2025-11-17 00:18:35,827:INFO:Physical Core: 4
2025-11-17 00:18:35,827:INFO:Logical Core: 8
2025-11-17 00:18:35,827:INFO:Checking libraries
2025-11-17 00:18:35,828:INFO:System:
2025-11-17 00:18:35,828:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-17 00:18:35,830:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-17 00:18:35,830:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-17 00:18:35,830:INFO:PyCaret required dependencies:
2025-11-17 00:18:35,830:INFO:                 pip: 23.1.2
2025-11-17 00:18:35,830:INFO:          setuptools: 80.9.0
2025-11-17 00:18:35,830:INFO:             pycaret: 3.3.2
2025-11-17 00:18:35,830:INFO:             IPython: 9.6.0
2025-11-17 00:18:35,830:INFO:          ipywidgets: 8.1.7
2025-11-17 00:18:35,832:INFO:                tqdm: 4.67.1
2025-11-17 00:18:35,832:INFO:               numpy: 1.26.4
2025-11-17 00:18:35,832:INFO:              pandas: 2.1.4
2025-11-17 00:18:35,832:INFO:              jinja2: 3.1.6
2025-11-17 00:18:35,832:INFO:               scipy: 1.11.4
2025-11-17 00:18:35,832:INFO:              joblib: 1.3.2
2025-11-17 00:18:35,835:INFO:             sklearn: 1.4.2
2025-11-17 00:18:35,835:INFO:                pyod: 2.0.5
2025-11-17 00:18:35,835:INFO:            imblearn: 0.14.0
2025-11-17 00:18:35,835:INFO:   category_encoders: 2.7.0
2025-11-17 00:18:35,835:INFO:            lightgbm: 4.6.0
2025-11-17 00:18:35,835:INFO:               numba: 0.61.0
2025-11-17 00:18:35,835:INFO:            requests: 2.32.5
2025-11-17 00:18:35,835:INFO:          matplotlib: 3.7.5
2025-11-17 00:18:35,835:INFO:          scikitplot: 0.3.7
2025-11-17 00:18:35,835:INFO:         yellowbrick: 1.5
2025-11-17 00:18:35,835:INFO:              plotly: 5.24.1
2025-11-17 00:18:35,835:INFO:    plotly-resampler: Not installed
2025-11-17 00:18:35,835:INFO:             kaleido: 1.1.0
2025-11-17 00:18:35,835:INFO:           schemdraw: 0.15
2025-11-17 00:18:35,835:INFO:         statsmodels: 0.14.5
2025-11-17 00:18:35,835:INFO:              sktime: 0.26.0
2025-11-17 00:18:35,835:INFO:               tbats: 1.1.3
2025-11-17 00:18:35,835:INFO:            pmdarima: 2.0.4
2025-11-17 00:18:35,835:INFO:              psutil: 7.1.2
2025-11-17 00:18:35,835:INFO:          markupsafe: 3.0.3
2025-11-17 00:18:35,835:INFO:             pickle5: Not installed
2025-11-17 00:18:35,835:INFO:         cloudpickle: 3.1.1
2025-11-17 00:18:35,835:INFO:         deprecation: 2.1.0
2025-11-17 00:18:35,835:INFO:              xxhash: 3.6.0
2025-11-17 00:18:35,835:INFO:           wurlitzer: Not installed
2025-11-17 00:18:35,835:INFO:PyCaret optional dependencies:
2025-11-17 00:18:35,835:INFO:                shap: 0.44.1
2025-11-17 00:18:35,844:INFO:           interpret: 0.7.3
2025-11-17 00:18:35,844:INFO:                umap: 0.5.7
2025-11-17 00:18:35,844:INFO:     ydata_profiling: 4.17.0
2025-11-17 00:18:35,844:INFO:  explainerdashboard: 0.5.1
2025-11-17 00:18:35,846:INFO:             autoviz: Not installed
2025-11-17 00:18:35,846:INFO:           fairlearn: 0.7.0
2025-11-17 00:18:35,846:INFO:          deepchecks: Not installed
2025-11-17 00:18:35,846:INFO:             xgboost: Not installed
2025-11-17 00:18:35,849:INFO:            catboost: Not installed
2025-11-17 00:18:35,849:INFO:              kmodes: Not installed
2025-11-17 00:18:35,849:INFO:             mlxtend: Not installed
2025-11-17 00:18:35,849:INFO:       statsforecast: Not installed
2025-11-17 00:18:35,849:INFO:        tune_sklearn: Not installed
2025-11-17 00:18:35,849:INFO:                 ray: Not installed
2025-11-17 00:18:35,851:INFO:            hyperopt: Not installed
2025-11-17 00:18:35,851:INFO:              optuna: Not installed
2025-11-17 00:18:35,851:INFO:               skopt: Not installed
2025-11-17 00:18:35,851:INFO:              mlflow: 3.5.1
2025-11-17 00:18:35,851:INFO:              gradio: Not installed
2025-11-17 00:18:35,851:INFO:             fastapi: 0.121.0
2025-11-17 00:18:35,853:INFO:             uvicorn: 0.38.0
2025-11-17 00:18:35,853:INFO:              m2cgen: Not installed
2025-11-17 00:18:35,853:INFO:           evidently: Not installed
2025-11-17 00:18:35,853:INFO:               fugue: Not installed
2025-11-17 00:18:35,853:INFO:           streamlit: Not installed
2025-11-17 00:18:35,853:INFO:             prophet: Not installed
2025-11-17 00:18:35,853:INFO:None
2025-11-17 00:18:35,853:INFO:Set up data.
2025-11-17 00:18:35,869:INFO:Set up folding strategy.
2025-11-17 00:18:35,869:INFO:Set up train/test split.
2025-11-17 00:18:35,881:INFO:Set up index.
2025-11-17 00:18:35,881:INFO:Assigning column types.
2025-11-17 00:18:35,888:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-17 00:18:36,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:18:36,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:18:36,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:18:36,368:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:18:36,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,434:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-17 00:18:36,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:18:36,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:18:36,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,751:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-17 00:18:36,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:36,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:37,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:37,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:37,126:INFO:Preparing preprocessing pipeline...
2025-11-17 00:18:37,131:INFO:Set up simple imputation.
2025-11-17 00:18:37,134:INFO:Set up encoding of ordinal features.
2025-11-17 00:18:37,140:INFO:Set up encoding of categorical features.
2025-11-17 00:18:37,140:INFO:Set up imbalanced handling.
2025-11-17 00:18:37,140:INFO:Set up feature normalization.
2025-11-17 00:18:37,402:INFO:Finished creating preprocessing pipeline.
2025-11-17 00:18:37,485:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-17 00:18:37,485:INFO:Creating final display dataframe.
2025-11-17 00:18:37,633:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              a01d
2025-11-17 00:18:37,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:37,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:38,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:38,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:18:38,130:INFO:setup() successfully completed in 2.53s...............
2025-11-17 00:18:38,334:INFO:Initializing compare_models()
2025-11-17 00:18:38,334:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-17 00:18:38,336:INFO:Checking exceptions
2025-11-17 00:18:38,345:INFO:Preparing display monitor
2025-11-17 00:18:38,409:INFO:Initializing Logistic Regression
2025-11-17 00:18:38,411:INFO:Total runtime is 3.753503163655599e-05 minutes
2025-11-17 00:18:38,419:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:38,419:INFO:Initializing create_model()
2025-11-17 00:18:38,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:38,419:INFO:Checking exceptions
2025-11-17 00:18:38,419:INFO:Importing libraries
2025-11-17 00:18:38,419:INFO:Copying training dataset
2025-11-17 00:18:38,434:INFO:Defining folds
2025-11-17 00:18:38,434:INFO:Declaring metric variables
2025-11-17 00:18:38,446:INFO:Importing untrained model
2025-11-17 00:18:38,453:INFO:Logistic Regression Imported successfully
2025-11-17 00:18:38,492:INFO:Starting cross validation
2025-11-17 00:18:38,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:38,987:INFO:Calculating mean and std
2025-11-17 00:18:38,987:INFO:Creating metrics dataframe
2025-11-17 00:18:38,987:INFO:Uploading results into container
2025-11-17 00:18:38,992:INFO:Uploading model into container now
2025-11-17 00:18:38,992:INFO:_master_model_container: 1
2025-11-17 00:18:38,992:INFO:_display_container: 2
2025-11-17 00:18:38,993:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-17 00:18:38,993:INFO:create_model() successfully completed......................................
2025-11-17 00:18:39,201:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:39,201:INFO:Creating metrics dataframe
2025-11-17 00:18:39,239:INFO:Initializing K Neighbors Classifier
2025-11-17 00:18:39,239:INFO:Total runtime is 0.013831591606140137 minutes
2025-11-17 00:18:39,259:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:39,262:INFO:Initializing create_model()
2025-11-17 00:18:39,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:39,263:INFO:Checking exceptions
2025-11-17 00:18:39,263:INFO:Importing libraries
2025-11-17 00:18:39,263:INFO:Copying training dataset
2025-11-17 00:18:39,284:INFO:Defining folds
2025-11-17 00:18:39,287:INFO:Declaring metric variables
2025-11-17 00:18:39,306:INFO:Importing untrained model
2025-11-17 00:18:39,322:INFO:K Neighbors Classifier Imported successfully
2025-11-17 00:18:39,332:INFO:Starting cross validation
2025-11-17 00:18:39,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:40,030:INFO:Calculating mean and std
2025-11-17 00:18:40,030:INFO:Creating metrics dataframe
2025-11-17 00:18:40,034:INFO:Uploading results into container
2025-11-17 00:18:40,034:INFO:Uploading model into container now
2025-11-17 00:18:40,035:INFO:_master_model_container: 2
2025-11-17 00:18:40,035:INFO:_display_container: 2
2025-11-17 00:18:40,035:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-17 00:18:40,035:INFO:create_model() successfully completed......................................
2025-11-17 00:18:40,248:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:40,248:INFO:Creating metrics dataframe
2025-11-17 00:18:40,266:INFO:Initializing Naive Bayes
2025-11-17 00:18:40,268:INFO:Total runtime is 0.030984238783518477 minutes
2025-11-17 00:18:40,278:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:40,281:INFO:Initializing create_model()
2025-11-17 00:18:40,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:40,281:INFO:Checking exceptions
2025-11-17 00:18:40,281:INFO:Importing libraries
2025-11-17 00:18:40,281:INFO:Copying training dataset
2025-11-17 00:18:40,299:INFO:Defining folds
2025-11-17 00:18:40,299:INFO:Declaring metric variables
2025-11-17 00:18:40,309:INFO:Importing untrained model
2025-11-17 00:18:40,323:INFO:Naive Bayes Imported successfully
2025-11-17 00:18:40,347:INFO:Starting cross validation
2025-11-17 00:18:40,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:40,943:INFO:Calculating mean and std
2025-11-17 00:18:40,947:INFO:Creating metrics dataframe
2025-11-17 00:18:40,950:INFO:Uploading results into container
2025-11-17 00:18:40,951:INFO:Uploading model into container now
2025-11-17 00:18:40,951:INFO:_master_model_container: 3
2025-11-17 00:18:40,951:INFO:_display_container: 2
2025-11-17 00:18:40,954:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-17 00:18:40,954:INFO:create_model() successfully completed......................................
2025-11-17 00:18:41,216:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:41,216:INFO:Creating metrics dataframe
2025-11-17 00:18:41,256:INFO:Initializing Decision Tree Classifier
2025-11-17 00:18:41,258:INFO:Total runtime is 0.04747998317082723 minutes
2025-11-17 00:18:41,272:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:41,275:INFO:Initializing create_model()
2025-11-17 00:18:41,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:41,276:INFO:Checking exceptions
2025-11-17 00:18:41,276:INFO:Importing libraries
2025-11-17 00:18:41,276:INFO:Copying training dataset
2025-11-17 00:18:41,296:INFO:Defining folds
2025-11-17 00:18:41,304:INFO:Declaring metric variables
2025-11-17 00:18:41,320:INFO:Importing untrained model
2025-11-17 00:18:41,334:INFO:Decision Tree Classifier Imported successfully
2025-11-17 00:18:41,359:INFO:Starting cross validation
2025-11-17 00:18:41,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:41,891:INFO:Calculating mean and std
2025-11-17 00:18:41,896:INFO:Creating metrics dataframe
2025-11-17 00:18:41,904:INFO:Uploading results into container
2025-11-17 00:18:41,904:INFO:Uploading model into container now
2025-11-17 00:18:41,907:INFO:_master_model_container: 4
2025-11-17 00:18:41,907:INFO:_display_container: 2
2025-11-17 00:18:41,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-17 00:18:41,909:INFO:create_model() successfully completed......................................
2025-11-17 00:18:42,231:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:42,231:INFO:Creating metrics dataframe
2025-11-17 00:18:42,247:INFO:Initializing SVM - Linear Kernel
2025-11-17 00:18:42,247:INFO:Total runtime is 0.06396642923355103 minutes
2025-11-17 00:18:42,261:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:42,261:INFO:Initializing create_model()
2025-11-17 00:18:42,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:42,263:INFO:Checking exceptions
2025-11-17 00:18:42,263:INFO:Importing libraries
2025-11-17 00:18:42,263:INFO:Copying training dataset
2025-11-17 00:18:42,267:INFO:Defining folds
2025-11-17 00:18:42,267:INFO:Declaring metric variables
2025-11-17 00:18:42,277:INFO:Importing untrained model
2025-11-17 00:18:42,284:INFO:SVM - Linear Kernel Imported successfully
2025-11-17 00:18:42,295:INFO:Starting cross validation
2025-11-17 00:18:42,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:42,662:INFO:Calculating mean and std
2025-11-17 00:18:42,662:INFO:Creating metrics dataframe
2025-11-17 00:18:42,669:INFO:Uploading results into container
2025-11-17 00:18:42,670:INFO:Uploading model into container now
2025-11-17 00:18:42,672:INFO:_master_model_container: 5
2025-11-17 00:18:42,672:INFO:_display_container: 2
2025-11-17 00:18:42,673:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-17 00:18:42,673:INFO:create_model() successfully completed......................................
2025-11-17 00:18:42,892:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:42,892:INFO:Creating metrics dataframe
2025-11-17 00:18:42,910:INFO:Initializing Ridge Classifier
2025-11-17 00:18:42,910:INFO:Total runtime is 0.07501860857009889 minutes
2025-11-17 00:18:42,913:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:42,913:INFO:Initializing create_model()
2025-11-17 00:18:42,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:42,920:INFO:Checking exceptions
2025-11-17 00:18:42,920:INFO:Importing libraries
2025-11-17 00:18:42,920:INFO:Copying training dataset
2025-11-17 00:18:42,964:INFO:Defining folds
2025-11-17 00:18:42,964:INFO:Declaring metric variables
2025-11-17 00:18:42,972:INFO:Importing untrained model
2025-11-17 00:18:42,980:INFO:Ridge Classifier Imported successfully
2025-11-17 00:18:43,001:INFO:Starting cross validation
2025-11-17 00:18:43,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:43,442:INFO:Calculating mean and std
2025-11-17 00:18:43,444:INFO:Creating metrics dataframe
2025-11-17 00:18:43,447:INFO:Uploading results into container
2025-11-17 00:18:43,448:INFO:Uploading model into container now
2025-11-17 00:18:43,448:INFO:_master_model_container: 6
2025-11-17 00:18:43,450:INFO:_display_container: 2
2025-11-17 00:18:43,450:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-17 00:18:43,450:INFO:create_model() successfully completed......................................
2025-11-17 00:18:43,730:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:43,736:INFO:Creating metrics dataframe
2025-11-17 00:18:43,779:INFO:Initializing Random Forest Classifier
2025-11-17 00:18:43,780:INFO:Total runtime is 0.0895038406054179 minutes
2025-11-17 00:18:43,795:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:43,795:INFO:Initializing create_model()
2025-11-17 00:18:43,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:43,798:INFO:Checking exceptions
2025-11-17 00:18:43,798:INFO:Importing libraries
2025-11-17 00:18:43,798:INFO:Copying training dataset
2025-11-17 00:18:43,810:INFO:Defining folds
2025-11-17 00:18:43,810:INFO:Declaring metric variables
2025-11-17 00:18:43,834:INFO:Importing untrained model
2025-11-17 00:18:43,846:INFO:Random Forest Classifier Imported successfully
2025-11-17 00:18:43,877:INFO:Starting cross validation
2025-11-17 00:18:43,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:45,132:INFO:Calculating mean and std
2025-11-17 00:18:45,134:INFO:Creating metrics dataframe
2025-11-17 00:18:45,141:INFO:Uploading results into container
2025-11-17 00:18:45,144:INFO:Uploading model into container now
2025-11-17 00:18:45,147:INFO:_master_model_container: 7
2025-11-17 00:18:45,147:INFO:_display_container: 2
2025-11-17 00:18:45,149:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-17 00:18:45,150:INFO:create_model() successfully completed......................................
2025-11-17 00:18:45,443:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:45,443:INFO:Creating metrics dataframe
2025-11-17 00:18:45,480:INFO:Initializing Quadratic Discriminant Analysis
2025-11-17 00:18:45,481:INFO:Total runtime is 0.11787821451822918 minutes
2025-11-17 00:18:45,494:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:45,494:INFO:Initializing create_model()
2025-11-17 00:18:45,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:45,496:INFO:Checking exceptions
2025-11-17 00:18:45,496:INFO:Importing libraries
2025-11-17 00:18:45,496:INFO:Copying training dataset
2025-11-17 00:18:45,507:INFO:Defining folds
2025-11-17 00:18:45,517:INFO:Declaring metric variables
2025-11-17 00:18:45,531:INFO:Importing untrained model
2025-11-17 00:18:45,542:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-17 00:18:45,573:INFO:Starting cross validation
2025-11-17 00:18:45,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:45,850:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,852:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,857:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,859:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,862:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,862:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,866:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,872:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:45,998:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:46,008:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:18:46,070:INFO:Calculating mean and std
2025-11-17 00:18:46,070:INFO:Creating metrics dataframe
2025-11-17 00:18:46,080:INFO:Uploading results into container
2025-11-17 00:18:46,081:INFO:Uploading model into container now
2025-11-17 00:18:46,081:INFO:_master_model_container: 8
2025-11-17 00:18:46,081:INFO:_display_container: 2
2025-11-17 00:18:46,081:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-17 00:18:46,081:INFO:create_model() successfully completed......................................
2025-11-17 00:18:46,374:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:46,374:INFO:Creating metrics dataframe
2025-11-17 00:18:46,405:INFO:Initializing Ada Boost Classifier
2025-11-17 00:18:46,405:INFO:Total runtime is 0.13327701489130656 minutes
2025-11-17 00:18:46,415:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:46,415:INFO:Initializing create_model()
2025-11-17 00:18:46,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:46,415:INFO:Checking exceptions
2025-11-17 00:18:46,415:INFO:Importing libraries
2025-11-17 00:18:46,415:INFO:Copying training dataset
2025-11-17 00:18:46,428:INFO:Defining folds
2025-11-17 00:18:46,428:INFO:Declaring metric variables
2025-11-17 00:18:46,441:INFO:Importing untrained model
2025-11-17 00:18:46,449:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:18:46,470:INFO:Starting cross validation
2025-11-17 00:18:46,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:46,713:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,718:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,723:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,723:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,725:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,729:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,731:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:46,735:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:47,110:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:47,110:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:18:47,345:INFO:Calculating mean and std
2025-11-17 00:18:47,347:INFO:Creating metrics dataframe
2025-11-17 00:18:47,351:INFO:Uploading results into container
2025-11-17 00:18:47,353:INFO:Uploading model into container now
2025-11-17 00:18:47,355:INFO:_master_model_container: 9
2025-11-17 00:18:47,355:INFO:_display_container: 2
2025-11-17 00:18:47,355:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:18:47,355:INFO:create_model() successfully completed......................................
2025-11-17 00:18:47,557:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:47,557:INFO:Creating metrics dataframe
2025-11-17 00:18:47,584:INFO:Initializing Gradient Boosting Classifier
2025-11-17 00:18:47,584:INFO:Total runtime is 0.15292745033899943 minutes
2025-11-17 00:18:47,595:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:47,596:INFO:Initializing create_model()
2025-11-17 00:18:47,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:47,596:INFO:Checking exceptions
2025-11-17 00:18:47,596:INFO:Importing libraries
2025-11-17 00:18:47,596:INFO:Copying training dataset
2025-11-17 00:18:47,607:INFO:Defining folds
2025-11-17 00:18:47,607:INFO:Declaring metric variables
2025-11-17 00:18:47,619:INFO:Importing untrained model
2025-11-17 00:18:47,629:INFO:Gradient Boosting Classifier Imported successfully
2025-11-17 00:18:47,647:INFO:Starting cross validation
2025-11-17 00:18:47,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:49,315:INFO:Calculating mean and std
2025-11-17 00:18:49,318:INFO:Creating metrics dataframe
2025-11-17 00:18:49,329:INFO:Uploading results into container
2025-11-17 00:18:49,329:INFO:Uploading model into container now
2025-11-17 00:18:49,332:INFO:_master_model_container: 10
2025-11-17 00:18:49,332:INFO:_display_container: 2
2025-11-17 00:18:49,332:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-17 00:18:49,333:INFO:create_model() successfully completed......................................
2025-11-17 00:18:49,571:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:49,571:INFO:Creating metrics dataframe
2025-11-17 00:18:49,604:INFO:Initializing Linear Discriminant Analysis
2025-11-17 00:18:49,604:INFO:Total runtime is 0.18658355077107747 minutes
2025-11-17 00:18:49,620:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:49,620:INFO:Initializing create_model()
2025-11-17 00:18:49,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:49,620:INFO:Checking exceptions
2025-11-17 00:18:49,620:INFO:Importing libraries
2025-11-17 00:18:49,620:INFO:Copying training dataset
2025-11-17 00:18:49,636:INFO:Defining folds
2025-11-17 00:18:49,636:INFO:Declaring metric variables
2025-11-17 00:18:49,667:INFO:Importing untrained model
2025-11-17 00:18:49,678:INFO:Linear Discriminant Analysis Imported successfully
2025-11-17 00:18:49,707:INFO:Starting cross validation
2025-11-17 00:18:49,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:50,184:INFO:Calculating mean and std
2025-11-17 00:18:50,184:INFO:Creating metrics dataframe
2025-11-17 00:18:50,195:INFO:Uploading results into container
2025-11-17 00:18:50,195:INFO:Uploading model into container now
2025-11-17 00:18:50,198:INFO:_master_model_container: 11
2025-11-17 00:18:50,198:INFO:_display_container: 2
2025-11-17 00:18:50,198:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-17 00:18:50,198:INFO:create_model() successfully completed......................................
2025-11-17 00:18:50,471:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:50,471:INFO:Creating metrics dataframe
2025-11-17 00:18:50,506:INFO:Initializing Extra Trees Classifier
2025-11-17 00:18:50,506:INFO:Total runtime is 0.20162672599156697 minutes
2025-11-17 00:18:50,520:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:50,520:INFO:Initializing create_model()
2025-11-17 00:18:50,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:50,520:INFO:Checking exceptions
2025-11-17 00:18:50,520:INFO:Importing libraries
2025-11-17 00:18:50,520:INFO:Copying training dataset
2025-11-17 00:18:50,537:INFO:Defining folds
2025-11-17 00:18:50,537:INFO:Declaring metric variables
2025-11-17 00:18:50,556:INFO:Importing untrained model
2025-11-17 00:18:50,569:INFO:Extra Trees Classifier Imported successfully
2025-11-17 00:18:50,595:INFO:Starting cross validation
2025-11-17 00:18:50,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:51,648:INFO:Calculating mean and std
2025-11-17 00:18:51,648:INFO:Creating metrics dataframe
2025-11-17 00:18:51,653:INFO:Uploading results into container
2025-11-17 00:18:51,653:INFO:Uploading model into container now
2025-11-17 00:18:51,653:INFO:_master_model_container: 12
2025-11-17 00:18:51,655:INFO:_display_container: 2
2025-11-17 00:18:51,656:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-17 00:18:51,656:INFO:create_model() successfully completed......................................
2025-11-17 00:18:51,907:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:51,907:INFO:Creating metrics dataframe
2025-11-17 00:18:51,947:INFO:Initializing Light Gradient Boosting Machine
2025-11-17 00:18:51,947:INFO:Total runtime is 0.2256424824396769 minutes
2025-11-17 00:18:51,954:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:51,963:INFO:Initializing create_model()
2025-11-17 00:18:51,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:51,965:INFO:Checking exceptions
2025-11-17 00:18:51,965:INFO:Importing libraries
2025-11-17 00:18:51,965:INFO:Copying training dataset
2025-11-17 00:18:51,983:INFO:Defining folds
2025-11-17 00:18:51,985:INFO:Declaring metric variables
2025-11-17 00:18:52,000:INFO:Importing untrained model
2025-11-17 00:18:52,006:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 00:18:52,041:INFO:Starting cross validation
2025-11-17 00:18:52,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:53,397:INFO:Calculating mean and std
2025-11-17 00:18:53,399:INFO:Creating metrics dataframe
2025-11-17 00:18:53,403:INFO:Uploading results into container
2025-11-17 00:18:53,405:INFO:Uploading model into container now
2025-11-17 00:18:53,405:INFO:_master_model_container: 13
2025-11-17 00:18:53,405:INFO:_display_container: 2
2025-11-17 00:18:53,407:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 00:18:53,407:INFO:create_model() successfully completed......................................
2025-11-17 00:18:53,552:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:53,552:INFO:Creating metrics dataframe
2025-11-17 00:18:53,586:INFO:Initializing Dummy Classifier
2025-11-17 00:18:53,586:INFO:Total runtime is 0.2529499610265096 minutes
2025-11-17 00:18:53,598:INFO:SubProcess create_model() called ==================================
2025-11-17 00:18:53,600:INFO:Initializing create_model()
2025-11-17 00:18:53,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD17F490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:53,602:INFO:Checking exceptions
2025-11-17 00:18:53,602:INFO:Importing libraries
2025-11-17 00:18:53,602:INFO:Copying training dataset
2025-11-17 00:18:53,618:INFO:Defining folds
2025-11-17 00:18:53,618:INFO:Declaring metric variables
2025-11-17 00:18:53,630:INFO:Importing untrained model
2025-11-17 00:18:53,637:INFO:Dummy Classifier Imported successfully
2025-11-17 00:18:53,668:INFO:Starting cross validation
2025-11-17 00:18:53,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:18:53,977:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:53,981:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:53,985:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:53,985:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:53,991:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:53,995:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:54,003:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:54,105:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:54,105:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:18:54,126:INFO:Calculating mean and std
2025-11-17 00:18:54,126:INFO:Creating metrics dataframe
2025-11-17 00:18:54,131:INFO:Uploading results into container
2025-11-17 00:18:54,131:INFO:Uploading model into container now
2025-11-17 00:18:54,131:INFO:_master_model_container: 14
2025-11-17 00:18:54,134:INFO:_display_container: 2
2025-11-17 00:18:54,134:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-17 00:18:54,134:INFO:create_model() successfully completed......................................
2025-11-17 00:18:54,371:INFO:SubProcess create_model() end ==================================
2025-11-17 00:18:54,371:INFO:Creating metrics dataframe
2025-11-17 00:18:54,403:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-17 00:18:54,425:INFO:Initializing create_model()
2025-11-17 00:18:54,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:18:54,425:INFO:Checking exceptions
2025-11-17 00:18:54,430:INFO:Importing libraries
2025-11-17 00:18:54,430:INFO:Copying training dataset
2025-11-17 00:18:54,438:INFO:Defining folds
2025-11-17 00:18:54,438:INFO:Declaring metric variables
2025-11-17 00:18:54,438:INFO:Importing untrained model
2025-11-17 00:18:54,438:INFO:Declaring custom model
2025-11-17 00:18:54,438:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:18:54,446:INFO:Cross validation set to False
2025-11-17 00:18:54,446:INFO:Fitting Model
2025-11-17 00:18:54,571:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:18:54,743:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:18:54,743:INFO:create_model() successfully completed......................................
2025-11-17 00:18:55,002:INFO:_master_model_container: 14
2025-11-17 00:18:55,002:INFO:_display_container: 2
2025-11-17 00:18:55,002:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:18:55,002:INFO:compare_models() successfully completed......................................
2025-11-17 00:18:55,037:INFO:Initializing tune_model()
2025-11-17 00:18:55,037:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 00:18:55,037:INFO:Checking exceptions
2025-11-17 00:18:55,068:INFO:Copying training dataset
2025-11-17 00:18:55,080:INFO:Checking base model
2025-11-17 00:18:55,080:INFO:Base model : Ada Boost Classifier
2025-11-17 00:18:55,085:INFO:Declaring metric variables
2025-11-17 00:18:55,094:INFO:Defining Hyperparameters
2025-11-17 00:18:55,263:INFO:Tuning with n_jobs=-1
2025-11-17 00:18:55,263:INFO:Initializing RandomizedSearchCV
2025-11-17 00:19:07,546:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-17 00:19:07,548:INFO:Hyperparameter search completed
2025-11-17 00:19:07,548:INFO:SubProcess create_model() called ==================================
2025-11-17 00:19:07,548:INFO:Initializing create_model()
2025-11-17 00:19:07,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B8CD9D49D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-17 00:19:07,548:INFO:Checking exceptions
2025-11-17 00:19:07,548:INFO:Importing libraries
2025-11-17 00:19:07,548:INFO:Copying training dataset
2025-11-17 00:19:07,557:INFO:Defining folds
2025-11-17 00:19:07,557:INFO:Declaring metric variables
2025-11-17 00:19:07,561:INFO:Importing untrained model
2025-11-17 00:19:07,561:INFO:Declaring custom model
2025-11-17 00:19:07,566:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:19:07,577:INFO:Starting cross validation
2025-11-17 00:19:07,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:19:09,608:INFO:Calculating mean and std
2025-11-17 00:19:09,611:INFO:Creating metrics dataframe
2025-11-17 00:19:09,622:INFO:Finalizing model
2025-11-17 00:19:10,265:INFO:Uploading results into container
2025-11-17 00:19:10,266:INFO:Uploading model into container now
2025-11-17 00:19:10,266:INFO:_master_model_container: 15
2025-11-17 00:19:10,267:INFO:_display_container: 3
2025-11-17 00:19:10,267:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:19:10,267:INFO:create_model() successfully completed......................................
2025-11-17 00:19:10,412:INFO:SubProcess create_model() end ==================================
2025-11-17 00:19:10,412:INFO:choose_better activated
2025-11-17 00:19:10,419:INFO:SubProcess create_model() called ==================================
2025-11-17 00:19:10,420:INFO:Initializing create_model()
2025-11-17 00:19:10,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B8CBA3A950>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:19:10,420:INFO:Checking exceptions
2025-11-17 00:19:10,424:INFO:Importing libraries
2025-11-17 00:19:10,424:INFO:Copying training dataset
2025-11-17 00:19:10,432:INFO:Defining folds
2025-11-17 00:19:10,432:INFO:Declaring metric variables
2025-11-17 00:19:10,432:INFO:Importing untrained model
2025-11-17 00:19:10,432:INFO:Declaring custom model
2025-11-17 00:19:10,432:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:19:10,432:INFO:Starting cross validation
2025-11-17 00:19:10,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:19:10,638:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,645:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,649:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,651:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,651:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,656:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,661:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:10,668:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:11,034:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:11,034:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:19:11,208:INFO:Calculating mean and std
2025-11-17 00:19:11,209:INFO:Creating metrics dataframe
2025-11-17 00:19:11,209:INFO:Finalizing model
2025-11-17 00:19:11,259:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:19:11,371:INFO:Uploading results into container
2025-11-17 00:19:11,374:INFO:Uploading model into container now
2025-11-17 00:19:11,374:INFO:_master_model_container: 16
2025-11-17 00:19:11,374:INFO:_display_container: 4
2025-11-17 00:19:11,374:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:19:11,374:INFO:create_model() successfully completed......................................
2025-11-17 00:19:11,575:INFO:SubProcess create_model() end ==================================
2025-11-17 00:19:11,575:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-17 00:19:11,575:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.9991
2025-11-17 00:19:11,575:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-17 00:19:11,575:INFO:choose_better completed
2025-11-17 00:19:11,598:INFO:_master_model_container: 16
2025-11-17 00:19:11,598:INFO:_display_container: 3
2025-11-17 00:19:11,598:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:19:11,598:INFO:tune_model() successfully completed......................................
2025-11-17 00:41:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-17 00:41:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-17 00:41:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-17 00:41:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-17 00:42:21,018:INFO:PyCaret ClassificationExperiment
2025-11-17 00:42:21,018:INFO:Logging name: clf-default-name
2025-11-17 00:42:21,018:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-17 00:42:21,018:INFO:version 3.3.2
2025-11-17 00:42:21,018:INFO:Initializing setup()
2025-11-17 00:42:21,018:INFO:self.USI: e6ae
2025-11-17 00:42:21,018:INFO:self._variable_keys: {'y', 'fold_shuffle_param', 'fold_generator', 'log_plots_param', 'X_test', 'gpu_param', 'pipeline', 'gpu_n_jobs_param', 'exp_id', 'y_train', 'fold_groups_param', 'logging_param', 'data', 'is_multiclass', 'html_param', 'y_test', 'target_param', 'seed', 'fix_imbalance', 'memory', '_ml_usecase', 'X', 'idx', '_available_plots', 'exp_name_log', 'X_train', 'n_jobs_param', 'USI'}
2025-11-17 00:42:21,018:INFO:Checking environment
2025-11-17 00:42:21,018:INFO:python_version: 3.11.4
2025-11-17 00:42:21,018:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-17 00:42:21,020:INFO:machine: AMD64
2025-11-17 00:42:21,020:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-17 00:42:21,020:INFO:Memory: svmem(total=8403275776, available=1301651456, percent=84.5, used=7101624320, free=1301651456)
2025-11-17 00:42:21,020:INFO:Physical Core: 4
2025-11-17 00:42:21,020:INFO:Logical Core: 8
2025-11-17 00:42:21,020:INFO:Checking libraries
2025-11-17 00:42:21,020:INFO:System:
2025-11-17 00:42:21,020:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-17 00:42:21,020:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-17 00:42:21,020:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-17 00:42:21,020:INFO:PyCaret required dependencies:
2025-11-17 00:42:21,355:INFO:                 pip: 23.1.2
2025-11-17 00:42:21,355:INFO:          setuptools: 80.9.0
2025-11-17 00:42:21,355:INFO:             pycaret: 3.3.2
2025-11-17 00:42:21,355:INFO:             IPython: 9.6.0
2025-11-17 00:42:21,355:INFO:          ipywidgets: 8.1.7
2025-11-17 00:42:21,355:INFO:                tqdm: 4.67.1
2025-11-17 00:42:21,355:INFO:               numpy: 1.26.4
2025-11-17 00:42:21,355:INFO:              pandas: 2.1.4
2025-11-17 00:42:21,355:INFO:              jinja2: 3.1.6
2025-11-17 00:42:21,355:INFO:               scipy: 1.11.4
2025-11-17 00:42:21,355:INFO:              joblib: 1.3.2
2025-11-17 00:42:21,355:INFO:             sklearn: 1.4.2
2025-11-17 00:42:21,355:INFO:                pyod: 2.0.5
2025-11-17 00:42:21,355:INFO:            imblearn: 0.14.0
2025-11-17 00:42:21,355:INFO:   category_encoders: 2.7.0
2025-11-17 00:42:21,355:INFO:            lightgbm: 4.6.0
2025-11-17 00:42:21,355:INFO:               numba: 0.61.0
2025-11-17 00:42:21,355:INFO:            requests: 2.32.5
2025-11-17 00:42:21,355:INFO:          matplotlib: 3.7.5
2025-11-17 00:42:21,355:INFO:          scikitplot: 0.3.7
2025-11-17 00:42:21,355:INFO:         yellowbrick: 1.5
2025-11-17 00:42:21,355:INFO:              plotly: 5.24.1
2025-11-17 00:42:21,355:INFO:    plotly-resampler: Not installed
2025-11-17 00:42:21,355:INFO:             kaleido: 1.1.0
2025-11-17 00:42:21,355:INFO:           schemdraw: 0.15
2025-11-17 00:42:21,355:INFO:         statsmodels: 0.14.5
2025-11-17 00:42:21,355:INFO:              sktime: 0.26.0
2025-11-17 00:42:21,355:INFO:               tbats: 1.1.3
2025-11-17 00:42:21,355:INFO:            pmdarima: 2.0.4
2025-11-17 00:42:21,355:INFO:              psutil: 7.1.2
2025-11-17 00:42:21,355:INFO:          markupsafe: 3.0.3
2025-11-17 00:42:21,355:INFO:             pickle5: Not installed
2025-11-17 00:42:21,355:INFO:         cloudpickle: 3.1.1
2025-11-17 00:42:21,355:INFO:         deprecation: 2.1.0
2025-11-17 00:42:21,355:INFO:              xxhash: 3.6.0
2025-11-17 00:42:21,355:INFO:           wurlitzer: Not installed
2025-11-17 00:42:21,355:INFO:PyCaret optional dependencies:
2025-11-17 00:42:26,266:INFO:                shap: 0.44.1
2025-11-17 00:42:26,266:INFO:           interpret: 0.7.3
2025-11-17 00:42:26,266:INFO:                umap: 0.5.7
2025-11-17 00:42:26,266:INFO:     ydata_profiling: 4.17.0
2025-11-17 00:42:26,266:INFO:  explainerdashboard: 0.5.1
2025-11-17 00:42:26,266:INFO:             autoviz: Not installed
2025-11-17 00:42:26,266:INFO:           fairlearn: 0.7.0
2025-11-17 00:42:26,266:INFO:          deepchecks: Not installed
2025-11-17 00:42:26,266:INFO:             xgboost: Not installed
2025-11-17 00:42:26,266:INFO:            catboost: Not installed
2025-11-17 00:42:26,266:INFO:              kmodes: Not installed
2025-11-17 00:42:26,266:INFO:             mlxtend: Not installed
2025-11-17 00:42:26,266:INFO:       statsforecast: Not installed
2025-11-17 00:42:26,266:INFO:        tune_sklearn: Not installed
2025-11-17 00:42:26,266:INFO:                 ray: Not installed
2025-11-17 00:42:26,266:INFO:            hyperopt: Not installed
2025-11-17 00:42:26,266:INFO:              optuna: Not installed
2025-11-17 00:42:26,266:INFO:               skopt: Not installed
2025-11-17 00:42:26,266:INFO:              mlflow: 3.5.1
2025-11-17 00:42:26,266:INFO:              gradio: Not installed
2025-11-17 00:42:26,266:INFO:             fastapi: 0.121.0
2025-11-17 00:42:26,266:INFO:             uvicorn: 0.38.0
2025-11-17 00:42:26,266:INFO:              m2cgen: Not installed
2025-11-17 00:42:26,266:INFO:           evidently: Not installed
2025-11-17 00:42:26,266:INFO:               fugue: Not installed
2025-11-17 00:42:26,266:INFO:           streamlit: Not installed
2025-11-17 00:42:26,266:INFO:             prophet: Not installed
2025-11-17 00:42:26,266:INFO:None
2025-11-17 00:42:26,266:INFO:Set up data.
2025-11-17 00:42:26,298:INFO:Set up folding strategy.
2025-11-17 00:42:26,298:INFO:Set up train/test split.
2025-11-17 00:42:26,332:INFO:Set up index.
2025-11-17 00:42:26,332:INFO:Assigning column types.
2025-11-17 00:42:26,332:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-17 00:42:26,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:42:26,541:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:42:26,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:26,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:26,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 00:42:26,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:42:26,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:26,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:26,945:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-17 00:42:27,100:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:42:27,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,353:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 00:42:27,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,449:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-17 00:42:27,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:27,934:INFO:Preparing preprocessing pipeline...
2025-11-17 00:42:27,934:INFO:Set up simple imputation.
2025-11-17 00:42:27,934:INFO:Set up encoding of ordinal features.
2025-11-17 00:42:27,949:INFO:Set up encoding of categorical features.
2025-11-17 00:42:27,949:INFO:Set up imbalanced handling.
2025-11-17 00:42:27,949:INFO:Set up feature normalization.
2025-11-17 00:42:28,280:INFO:Finished creating preprocessing pipeline.
2025-11-17 00:42:28,373:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-17 00:42:28,373:INFO:Creating final display dataframe.
2025-11-17 00:42:28,527:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              e6ae
2025-11-17 00:42:28,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:28,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:28,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:28,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 00:42:28,956:INFO:setup() successfully completed in 8.12s...............
2025-11-17 00:42:29,012:INFO:Initializing compare_models()
2025-11-17 00:42:29,012:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-17 00:42:29,012:INFO:Checking exceptions
2025-11-17 00:42:29,022:INFO:Preparing display monitor
2025-11-17 00:42:29,110:INFO:Initializing Logistic Regression
2025-11-17 00:42:29,110:INFO:Total runtime is 0.0 minutes
2025-11-17 00:42:29,121:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:29,122:INFO:Initializing create_model()
2025-11-17 00:42:29,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:29,122:INFO:Checking exceptions
2025-11-17 00:42:29,122:INFO:Importing libraries
2025-11-17 00:42:29,122:INFO:Copying training dataset
2025-11-17 00:42:29,134:INFO:Defining folds
2025-11-17 00:42:29,134:INFO:Declaring metric variables
2025-11-17 00:42:29,145:INFO:Importing untrained model
2025-11-17 00:42:29,159:INFO:Logistic Regression Imported successfully
2025-11-17 00:42:29,213:INFO:Starting cross validation
2025-11-17 00:42:29,221:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:38,158:INFO:Calculating mean and std
2025-11-17 00:42:38,168:INFO:Creating metrics dataframe
2025-11-17 00:42:38,180:INFO:Uploading results into container
2025-11-17 00:42:38,180:INFO:Uploading model into container now
2025-11-17 00:42:38,182:INFO:_master_model_container: 1
2025-11-17 00:42:38,182:INFO:_display_container: 2
2025-11-17 00:42:38,182:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-17 00:42:38,184:INFO:create_model() successfully completed......................................
2025-11-17 00:42:38,382:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:38,382:INFO:Creating metrics dataframe
2025-11-17 00:42:38,394:INFO:Initializing K Neighbors Classifier
2025-11-17 00:42:38,394:INFO:Total runtime is 0.15473610957463582 minutes
2025-11-17 00:42:38,401:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:38,401:INFO:Initializing create_model()
2025-11-17 00:42:38,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:38,405:INFO:Checking exceptions
2025-11-17 00:42:38,405:INFO:Importing libraries
2025-11-17 00:42:38,405:INFO:Copying training dataset
2025-11-17 00:42:38,416:INFO:Defining folds
2025-11-17 00:42:38,416:INFO:Declaring metric variables
2025-11-17 00:42:38,422:INFO:Importing untrained model
2025-11-17 00:42:38,430:INFO:K Neighbors Classifier Imported successfully
2025-11-17 00:42:38,446:INFO:Starting cross validation
2025-11-17 00:42:38,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:38,972:INFO:Calculating mean and std
2025-11-17 00:42:38,973:INFO:Creating metrics dataframe
2025-11-17 00:42:38,976:INFO:Uploading results into container
2025-11-17 00:42:38,976:INFO:Uploading model into container now
2025-11-17 00:42:38,977:INFO:_master_model_container: 2
2025-11-17 00:42:38,977:INFO:_display_container: 2
2025-11-17 00:42:38,977:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-17 00:42:38,977:INFO:create_model() successfully completed......................................
2025-11-17 00:42:39,225:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:39,226:INFO:Creating metrics dataframe
2025-11-17 00:42:39,251:INFO:Initializing Naive Bayes
2025-11-17 00:42:39,254:INFO:Total runtime is 0.16906628211339314 minutes
2025-11-17 00:42:39,267:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:39,267:INFO:Initializing create_model()
2025-11-17 00:42:39,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:39,267:INFO:Checking exceptions
2025-11-17 00:42:39,267:INFO:Importing libraries
2025-11-17 00:42:39,267:INFO:Copying training dataset
2025-11-17 00:42:39,289:INFO:Defining folds
2025-11-17 00:42:39,292:INFO:Declaring metric variables
2025-11-17 00:42:39,308:INFO:Importing untrained model
2025-11-17 00:42:39,322:INFO:Naive Bayes Imported successfully
2025-11-17 00:42:39,349:INFO:Starting cross validation
2025-11-17 00:42:39,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:39,844:INFO:Calculating mean and std
2025-11-17 00:42:39,844:INFO:Creating metrics dataframe
2025-11-17 00:42:39,850:INFO:Uploading results into container
2025-11-17 00:42:39,851:INFO:Uploading model into container now
2025-11-17 00:42:39,851:INFO:_master_model_container: 3
2025-11-17 00:42:39,851:INFO:_display_container: 2
2025-11-17 00:42:39,851:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-17 00:42:39,851:INFO:create_model() successfully completed......................................
2025-11-17 00:42:40,038:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:40,038:INFO:Creating metrics dataframe
2025-11-17 00:42:40,071:INFO:Initializing Decision Tree Classifier
2025-11-17 00:42:40,073:INFO:Total runtime is 0.18268400033315021 minutes
2025-11-17 00:42:40,081:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:40,081:INFO:Initializing create_model()
2025-11-17 00:42:40,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:40,081:INFO:Checking exceptions
2025-11-17 00:42:40,081:INFO:Importing libraries
2025-11-17 00:42:40,081:INFO:Copying training dataset
2025-11-17 00:42:40,100:INFO:Defining folds
2025-11-17 00:42:40,100:INFO:Declaring metric variables
2025-11-17 00:42:40,111:INFO:Importing untrained model
2025-11-17 00:42:40,121:INFO:Decision Tree Classifier Imported successfully
2025-11-17 00:42:40,138:INFO:Starting cross validation
2025-11-17 00:42:40,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:40,509:INFO:Calculating mean and std
2025-11-17 00:42:40,509:INFO:Creating metrics dataframe
2025-11-17 00:42:40,513:INFO:Uploading results into container
2025-11-17 00:42:40,513:INFO:Uploading model into container now
2025-11-17 00:42:40,514:INFO:_master_model_container: 4
2025-11-17 00:42:40,514:INFO:_display_container: 2
2025-11-17 00:42:40,514:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-17 00:42:40,514:INFO:create_model() successfully completed......................................
2025-11-17 00:42:40,659:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:40,659:INFO:Creating metrics dataframe
2025-11-17 00:42:40,678:INFO:Initializing SVM - Linear Kernel
2025-11-17 00:42:40,678:INFO:Total runtime is 0.19279809792836505 minutes
2025-11-17 00:42:40,684:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:40,686:INFO:Initializing create_model()
2025-11-17 00:42:40,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:40,686:INFO:Checking exceptions
2025-11-17 00:42:40,686:INFO:Importing libraries
2025-11-17 00:42:40,687:INFO:Copying training dataset
2025-11-17 00:42:40,691:INFO:Defining folds
2025-11-17 00:42:40,691:INFO:Declaring metric variables
2025-11-17 00:42:40,704:INFO:Importing untrained model
2025-11-17 00:42:40,709:INFO:SVM - Linear Kernel Imported successfully
2025-11-17 00:42:40,724:INFO:Starting cross validation
2025-11-17 00:42:40,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:41,169:INFO:Calculating mean and std
2025-11-17 00:42:41,170:INFO:Creating metrics dataframe
2025-11-17 00:42:41,170:INFO:Uploading results into container
2025-11-17 00:42:41,170:INFO:Uploading model into container now
2025-11-17 00:42:41,170:INFO:_master_model_container: 5
2025-11-17 00:42:41,170:INFO:_display_container: 2
2025-11-17 00:42:41,170:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-17 00:42:41,170:INFO:create_model() successfully completed......................................
2025-11-17 00:42:41,390:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:41,390:INFO:Creating metrics dataframe
2025-11-17 00:42:41,406:INFO:Initializing Ridge Classifier
2025-11-17 00:42:41,406:INFO:Total runtime is 0.20493368705113726 minutes
2025-11-17 00:42:41,415:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:41,419:INFO:Initializing create_model()
2025-11-17 00:42:41,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:41,420:INFO:Checking exceptions
2025-11-17 00:42:41,420:INFO:Importing libraries
2025-11-17 00:42:41,420:INFO:Copying training dataset
2025-11-17 00:42:41,431:INFO:Defining folds
2025-11-17 00:42:41,431:INFO:Declaring metric variables
2025-11-17 00:42:41,437:INFO:Importing untrained model
2025-11-17 00:42:41,448:INFO:Ridge Classifier Imported successfully
2025-11-17 00:42:41,463:INFO:Starting cross validation
2025-11-17 00:42:41,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:41,936:INFO:Calculating mean and std
2025-11-17 00:42:41,937:INFO:Creating metrics dataframe
2025-11-17 00:42:41,944:INFO:Uploading results into container
2025-11-17 00:42:41,946:INFO:Uploading model into container now
2025-11-17 00:42:41,948:INFO:_master_model_container: 6
2025-11-17 00:42:41,948:INFO:_display_container: 2
2025-11-17 00:42:41,949:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-17 00:42:41,951:INFO:create_model() successfully completed......................................
2025-11-17 00:42:42,203:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:42,203:INFO:Creating metrics dataframe
2025-11-17 00:42:42,220:INFO:Initializing Random Forest Classifier
2025-11-17 00:42:42,220:INFO:Total runtime is 0.21849344571431475 minutes
2025-11-17 00:42:42,236:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:42,236:INFO:Initializing create_model()
2025-11-17 00:42:42,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:42,236:INFO:Checking exceptions
2025-11-17 00:42:42,238:INFO:Importing libraries
2025-11-17 00:42:42,238:INFO:Copying training dataset
2025-11-17 00:42:42,241:INFO:Defining folds
2025-11-17 00:42:42,241:INFO:Declaring metric variables
2025-11-17 00:42:42,255:INFO:Importing untrained model
2025-11-17 00:42:42,262:INFO:Random Forest Classifier Imported successfully
2025-11-17 00:42:42,276:INFO:Starting cross validation
2025-11-17 00:42:42,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:43,402:INFO:Calculating mean and std
2025-11-17 00:42:43,403:INFO:Creating metrics dataframe
2025-11-17 00:42:43,406:INFO:Uploading results into container
2025-11-17 00:42:43,406:INFO:Uploading model into container now
2025-11-17 00:42:43,408:INFO:_master_model_container: 7
2025-11-17 00:42:43,408:INFO:_display_container: 2
2025-11-17 00:42:43,408:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-17 00:42:43,408:INFO:create_model() successfully completed......................................
2025-11-17 00:42:43,586:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:43,586:INFO:Creating metrics dataframe
2025-11-17 00:42:43,606:INFO:Initializing Quadratic Discriminant Analysis
2025-11-17 00:42:43,606:INFO:Total runtime is 0.24160300095876056 minutes
2025-11-17 00:42:43,614:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:43,614:INFO:Initializing create_model()
2025-11-17 00:42:43,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:43,614:INFO:Checking exceptions
2025-11-17 00:42:43,616:INFO:Importing libraries
2025-11-17 00:42:43,616:INFO:Copying training dataset
2025-11-17 00:42:43,622:INFO:Defining folds
2025-11-17 00:42:43,622:INFO:Declaring metric variables
2025-11-17 00:42:43,635:INFO:Importing untrained model
2025-11-17 00:42:43,643:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-17 00:42:43,658:INFO:Starting cross validation
2025-11-17 00:42:43,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:43,911:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:43,913:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:43,913:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:43,935:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:43,937:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:43,937:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:43,937:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:44,060:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:44,070:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 00:42:44,122:INFO:Calculating mean and std
2025-11-17 00:42:44,122:INFO:Creating metrics dataframe
2025-11-17 00:42:44,130:INFO:Uploading results into container
2025-11-17 00:42:44,131:INFO:Uploading model into container now
2025-11-17 00:42:44,133:INFO:_master_model_container: 8
2025-11-17 00:42:44,133:INFO:_display_container: 2
2025-11-17 00:42:44,134:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-17 00:42:44,134:INFO:create_model() successfully completed......................................
2025-11-17 00:42:44,335:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:44,335:INFO:Creating metrics dataframe
2025-11-17 00:42:44,356:INFO:Initializing Ada Boost Classifier
2025-11-17 00:42:44,357:INFO:Total runtime is 0.25411888758341467 minutes
2025-11-17 00:42:44,365:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:44,365:INFO:Initializing create_model()
2025-11-17 00:42:44,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:44,365:INFO:Checking exceptions
2025-11-17 00:42:44,365:INFO:Importing libraries
2025-11-17 00:42:44,365:INFO:Copying training dataset
2025-11-17 00:42:44,374:INFO:Defining folds
2025-11-17 00:42:44,374:INFO:Declaring metric variables
2025-11-17 00:42:44,386:INFO:Importing untrained model
2025-11-17 00:42:44,395:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:42:44,406:INFO:Starting cross validation
2025-11-17 00:42:44,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:44,618:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,625:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,625:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,625:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,625:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,625:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,625:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:44,634:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:45,004:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:45,004:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:42:45,293:INFO:Calculating mean and std
2025-11-17 00:42:45,295:INFO:Creating metrics dataframe
2025-11-17 00:42:45,299:INFO:Uploading results into container
2025-11-17 00:42:45,301:INFO:Uploading model into container now
2025-11-17 00:42:45,302:INFO:_master_model_container: 9
2025-11-17 00:42:45,302:INFO:_display_container: 2
2025-11-17 00:42:45,302:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:42:45,302:INFO:create_model() successfully completed......................................
2025-11-17 00:42:45,470:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:45,476:INFO:Creating metrics dataframe
2025-11-17 00:42:45,494:INFO:Initializing Gradient Boosting Classifier
2025-11-17 00:42:45,494:INFO:Total runtime is 0.2730595469474792 minutes
2025-11-17 00:42:45,501:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:45,501:INFO:Initializing create_model()
2025-11-17 00:42:45,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:45,501:INFO:Checking exceptions
2025-11-17 00:42:45,504:INFO:Importing libraries
2025-11-17 00:42:45,504:INFO:Copying training dataset
2025-11-17 00:42:45,511:INFO:Defining folds
2025-11-17 00:42:45,511:INFO:Declaring metric variables
2025-11-17 00:42:45,518:INFO:Importing untrained model
2025-11-17 00:42:45,528:INFO:Gradient Boosting Classifier Imported successfully
2025-11-17 00:42:45,542:INFO:Starting cross validation
2025-11-17 00:42:45,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:46,675:INFO:Calculating mean and std
2025-11-17 00:42:46,675:INFO:Creating metrics dataframe
2025-11-17 00:42:46,675:INFO:Uploading results into container
2025-11-17 00:42:46,684:INFO:Uploading model into container now
2025-11-17 00:42:46,684:INFO:_master_model_container: 10
2025-11-17 00:42:46,684:INFO:_display_container: 2
2025-11-17 00:42:46,684:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-17 00:42:46,684:INFO:create_model() successfully completed......................................
2025-11-17 00:42:46,834:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:46,850:INFO:Creating metrics dataframe
2025-11-17 00:42:46,867:INFO:Initializing Linear Discriminant Analysis
2025-11-17 00:42:46,867:INFO:Total runtime is 0.2959494034449259 minutes
2025-11-17 00:42:46,873:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:46,873:INFO:Initializing create_model()
2025-11-17 00:42:46,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:46,873:INFO:Checking exceptions
2025-11-17 00:42:46,873:INFO:Importing libraries
2025-11-17 00:42:46,873:INFO:Copying training dataset
2025-11-17 00:42:46,884:INFO:Defining folds
2025-11-17 00:42:46,884:INFO:Declaring metric variables
2025-11-17 00:42:46,897:INFO:Importing untrained model
2025-11-17 00:42:46,903:INFO:Linear Discriminant Analysis Imported successfully
2025-11-17 00:42:46,913:INFO:Starting cross validation
2025-11-17 00:42:46,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:47,259:INFO:Calculating mean and std
2025-11-17 00:42:47,259:INFO:Creating metrics dataframe
2025-11-17 00:42:47,266:INFO:Uploading results into container
2025-11-17 00:42:47,267:INFO:Uploading model into container now
2025-11-17 00:42:47,270:INFO:_master_model_container: 11
2025-11-17 00:42:47,270:INFO:_display_container: 2
2025-11-17 00:42:47,270:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-17 00:42:47,270:INFO:create_model() successfully completed......................................
2025-11-17 00:42:47,467:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:47,467:INFO:Creating metrics dataframe
2025-11-17 00:42:47,497:INFO:Initializing Extra Trees Classifier
2025-11-17 00:42:47,497:INFO:Total runtime is 0.3064395268758137 minutes
2025-11-17 00:42:47,503:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:47,506:INFO:Initializing create_model()
2025-11-17 00:42:47,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:47,506:INFO:Checking exceptions
2025-11-17 00:42:47,506:INFO:Importing libraries
2025-11-17 00:42:47,506:INFO:Copying training dataset
2025-11-17 00:42:47,517:INFO:Defining folds
2025-11-17 00:42:47,517:INFO:Declaring metric variables
2025-11-17 00:42:47,526:INFO:Importing untrained model
2025-11-17 00:42:47,534:INFO:Extra Trees Classifier Imported successfully
2025-11-17 00:42:47,550:INFO:Starting cross validation
2025-11-17 00:42:47,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:48,647:INFO:Calculating mean and std
2025-11-17 00:42:48,650:INFO:Creating metrics dataframe
2025-11-17 00:42:48,653:INFO:Uploading results into container
2025-11-17 00:42:48,653:INFO:Uploading model into container now
2025-11-17 00:42:48,653:INFO:_master_model_container: 12
2025-11-17 00:42:48,653:INFO:_display_container: 2
2025-11-17 00:42:48,653:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-17 00:42:48,653:INFO:create_model() successfully completed......................................
2025-11-17 00:42:48,825:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:48,825:INFO:Creating metrics dataframe
2025-11-17 00:42:48,852:INFO:Initializing Light Gradient Boosting Machine
2025-11-17 00:42:48,852:INFO:Total runtime is 0.32903210322062165 minutes
2025-11-17 00:42:48,861:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:48,861:INFO:Initializing create_model()
2025-11-17 00:42:48,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:48,861:INFO:Checking exceptions
2025-11-17 00:42:48,861:INFO:Importing libraries
2025-11-17 00:42:48,861:INFO:Copying training dataset
2025-11-17 00:42:48,872:INFO:Defining folds
2025-11-17 00:42:48,872:INFO:Declaring metric variables
2025-11-17 00:42:48,882:INFO:Importing untrained model
2025-11-17 00:42:48,888:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 00:42:48,908:INFO:Starting cross validation
2025-11-17 00:42:48,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:50,228:INFO:Calculating mean and std
2025-11-17 00:42:50,230:INFO:Creating metrics dataframe
2025-11-17 00:42:50,234:INFO:Uploading results into container
2025-11-17 00:42:50,234:INFO:Uploading model into container now
2025-11-17 00:42:50,236:INFO:_master_model_container: 13
2025-11-17 00:42:50,236:INFO:_display_container: 2
2025-11-17 00:42:50,236:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 00:42:50,238:INFO:create_model() successfully completed......................................
2025-11-17 00:42:50,387:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:50,387:INFO:Creating metrics dataframe
2025-11-17 00:42:50,406:INFO:Initializing Dummy Classifier
2025-11-17 00:42:50,406:INFO:Total runtime is 0.35492850144704174 minutes
2025-11-17 00:42:50,411:INFO:SubProcess create_model() called ==================================
2025-11-17 00:42:50,411:INFO:Initializing create_model()
2025-11-17 00:42:50,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C2F6250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:50,411:INFO:Checking exceptions
2025-11-17 00:42:50,411:INFO:Importing libraries
2025-11-17 00:42:50,411:INFO:Copying training dataset
2025-11-17 00:42:50,422:INFO:Defining folds
2025-11-17 00:42:50,422:INFO:Declaring metric variables
2025-11-17 00:42:50,427:INFO:Importing untrained model
2025-11-17 00:42:50,431:INFO:Dummy Classifier Imported successfully
2025-11-17 00:42:50,447:INFO:Starting cross validation
2025-11-17 00:42:50,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:42:50,793:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,797:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,800:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,804:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,812:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,815:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,815:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,909:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,913:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 00:42:50,923:INFO:Calculating mean and std
2025-11-17 00:42:50,923:INFO:Creating metrics dataframe
2025-11-17 00:42:50,923:INFO:Uploading results into container
2025-11-17 00:42:50,923:INFO:Uploading model into container now
2025-11-17 00:42:50,923:INFO:_master_model_container: 14
2025-11-17 00:42:50,923:INFO:_display_container: 2
2025-11-17 00:42:50,923:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-17 00:42:50,923:INFO:create_model() successfully completed......................................
2025-11-17 00:42:51,084:INFO:SubProcess create_model() end ==================================
2025-11-17 00:42:51,084:INFO:Creating metrics dataframe
2025-11-17 00:42:51,107:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-17 00:42:51,127:INFO:Initializing create_model()
2025-11-17 00:42:51,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:42:51,129:INFO:Checking exceptions
2025-11-17 00:42:51,134:INFO:Importing libraries
2025-11-17 00:42:51,134:INFO:Copying training dataset
2025-11-17 00:42:51,142:INFO:Defining folds
2025-11-17 00:42:51,142:INFO:Declaring metric variables
2025-11-17 00:42:51,142:INFO:Importing untrained model
2025-11-17 00:42:51,143:INFO:Declaring custom model
2025-11-17 00:42:51,143:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:42:51,145:INFO:Cross validation set to False
2025-11-17 00:42:51,147:INFO:Fitting Model
2025-11-17 00:42:51,262:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:42:51,575:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:42:51,575:INFO:create_model() successfully completed......................................
2025-11-17 00:42:51,781:INFO:_master_model_container: 14
2025-11-17 00:42:51,781:INFO:_display_container: 2
2025-11-17 00:42:51,781:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:42:51,781:INFO:compare_models() successfully completed......................................
2025-11-17 00:42:51,814:INFO:Initializing tune_model()
2025-11-17 00:42:51,814:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 00:42:51,814:INFO:Checking exceptions
2025-11-17 00:42:51,846:INFO:Copying training dataset
2025-11-17 00:42:51,853:INFO:Checking base model
2025-11-17 00:42:51,854:INFO:Base model : Ada Boost Classifier
2025-11-17 00:42:51,858:INFO:Declaring metric variables
2025-11-17 00:42:51,866:INFO:Defining Hyperparameters
2025-11-17 00:42:52,048:INFO:Tuning with n_jobs=-1
2025-11-17 00:42:52,051:INFO:Initializing RandomizedSearchCV
2025-11-17 00:43:04,901:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-11-17 00:43:04,905:INFO:Hyperparameter search completed
2025-11-17 00:43:04,905:INFO:SubProcess create_model() called ==================================
2025-11-17 00:43:04,907:INFO:Initializing create_model()
2025-11-17 00:43:04,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381BD75450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-11-17 00:43:04,907:INFO:Checking exceptions
2025-11-17 00:43:04,907:INFO:Importing libraries
2025-11-17 00:43:04,908:INFO:Copying training dataset
2025-11-17 00:43:04,912:INFO:Defining folds
2025-11-17 00:43:04,912:INFO:Declaring metric variables
2025-11-17 00:43:04,912:INFO:Importing untrained model
2025-11-17 00:43:04,912:INFO:Declaring custom model
2025-11-17 00:43:04,925:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:43:04,940:INFO:Starting cross validation
2025-11-17 00:43:04,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:43:07,052:INFO:Calculating mean and std
2025-11-17 00:43:07,052:INFO:Creating metrics dataframe
2025-11-17 00:43:07,062:INFO:Finalizing model
2025-11-17 00:43:07,854:INFO:Uploading results into container
2025-11-17 00:43:07,855:INFO:Uploading model into container now
2025-11-17 00:43:07,856:INFO:_master_model_container: 15
2025-11-17 00:43:07,856:INFO:_display_container: 3
2025-11-17 00:43:07,857:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:43:07,857:INFO:create_model() successfully completed......................................
2025-11-17 00:43:08,026:INFO:SubProcess create_model() end ==================================
2025-11-17 00:43:08,026:INFO:choose_better activated
2025-11-17 00:43:08,026:INFO:SubProcess create_model() called ==================================
2025-11-17 00:43:08,026:INFO:Initializing create_model()
2025-11-17 00:43:08,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 00:43:08,026:INFO:Checking exceptions
2025-11-17 00:43:08,037:INFO:Importing libraries
2025-11-17 00:43:08,038:INFO:Copying training dataset
2025-11-17 00:43:08,041:INFO:Defining folds
2025-11-17 00:43:08,041:INFO:Declaring metric variables
2025-11-17 00:43:08,041:INFO:Importing untrained model
2025-11-17 00:43:08,041:INFO:Declaring custom model
2025-11-17 00:43:08,041:INFO:Ada Boost Classifier Imported successfully
2025-11-17 00:43:08,041:INFO:Starting cross validation
2025-11-17 00:43:08,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 00:43:08,256:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,256:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,261:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,265:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,267:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,269:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,277:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,277:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,650:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,655:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 00:43:08,898:INFO:Calculating mean and std
2025-11-17 00:43:08,900:INFO:Creating metrics dataframe
2025-11-17 00:43:08,900:INFO:Finalizing model
2025-11-17 00:43:09,003:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-11-17 00:43:09,115:INFO:Uploading results into container
2025-11-17 00:43:09,115:INFO:Uploading model into container now
2025-11-17 00:43:09,115:INFO:_master_model_container: 16
2025-11-17 00:43:09,115:INFO:_display_container: 4
2025-11-17 00:43:09,115:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 00:43:09,115:INFO:create_model() successfully completed......................................
2025-11-17 00:43:09,266:INFO:SubProcess create_model() end ==================================
2025-11-17 00:43:09,266:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123) result for AUC is 0.9988
2025-11-17 00:43:09,266:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) result for AUC is 0.9991
2025-11-17 00:43:09,268:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123) is best model
2025-11-17 00:43:09,268:INFO:choose_better completed
2025-11-17 00:43:09,288:INFO:_master_model_container: 16
2025-11-17 00:43:09,288:INFO:_display_container: 3
2025-11-17 00:43:09,289:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123)
2025-11-17 00:43:09,289:INFO:tune_model() successfully completed......................................
2025-11-17 00:43:09,545:INFO:Initializing interpret_model()
2025-11-17 00:43:09,545:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=230, random_state=123), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-11-17 00:43:09,545:INFO:Checking exceptions
2025-11-17 00:43:09,545:INFO:Soft dependency imported: shap: 0.44.1
2025-11-17 01:09:59,087:INFO:Initializing get_config()
2025-11-17 01:09:59,096:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, variable=X_train_transformed)
2025-11-17 01:09:59,452:INFO:Variable: X_train returned as            age  monthly_income_usd  app_usage_score  digital_profile_strength  \
530  -0.111143           -0.140644        -1.165609                 -1.546579   
849   0.430512           -1.289928         0.957288                  1.836249   
141  -0.343281            0.508270         0.774522                  0.821140   
353   0.430512            0.280368         0.816698                 -0.864285   
744   0.353133            1.200082         0.560123                 -0.319490   
...        ...                 ...              ...                       ...   
1171 -0.748173            1.492517         0.066507                  0.424546   
1172 -0.345501            0.714308         1.231094                  0.278176   
1173 -0.121836            0.044284        -1.572826                 -0.082970   
1174 -0.457372           -0.046551         0.186215                  1.087524   
1175 -1.039836            0.229614         0.808683                  0.029358   

      num_contacts_uploaded  residence_risk_zone_baja  \
530               -0.308877                  0.930045   
849                0.981661                 -1.148625   
141               -0.954146                  0.930045   
353                0.175075                 -1.148625   
744                0.013758                 -1.148625   
...                     ...                       ...   
1171               0.051273                  0.768910   
1172               0.262126                  0.705706   
1173              -0.731529                  0.858237   
1174               0.180576                 -0.091570   
1175              -0.147414                  0.930045   

      residence_risk_zone_media  residence_risk_zone_alta  \
530                   -0.687779                 -0.409360   
849                    1.562803                 -0.409360   
141                   -0.687779                 -0.409360   
353                   -0.687779                  2.477064   
744                    1.562803                 -0.409360   
...                         ...                       ...   
1171                  -0.513318                 -0.409360   
1172                  -0.444886                 -0.409360   
1173                  -0.610033                 -0.409360   
1174                   0.418326                 -0.409360   
1175                  -0.687779                 -0.409360   

      political_event_last_month  
530                    -0.418694  
849                    -0.418694  
141                    -0.418694  
353                     2.420111  
744                    -0.418694  
...                          ...  
1171                   -0.418694  
1172                   -0.418694  
1173                   -0.418694  
1174                   -0.418694  
1175                   -0.418694  

[876 rows x 9 columns]
2025-11-17 01:09:59,452:INFO:get_config() successfully completed......................................
2025-11-17 01:11:01,857:INFO:Initializing get_config()
2025-11-17 01:11:01,857:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, variable=X_train_transformed)
2025-11-17 01:11:01,895:INFO:Variable: X_train returned as            age  monthly_income_usd  app_usage_score  digital_profile_strength  \
530  -0.111143           -0.140644        -1.165609                 -1.546579   
849   0.430512           -1.289928         0.957288                  1.836249   
141  -0.343281            0.508270         0.774522                  0.821140   
353   0.430512            0.280368         0.816698                 -0.864285   
744   0.353133            1.200082         0.560123                 -0.319490   
...        ...                 ...              ...                       ...   
1171 -0.748173            1.492517         0.066507                  0.424546   
1172 -0.345501            0.714308         1.231094                  0.278176   
1173 -0.121836            0.044284        -1.572826                 -0.082970   
1174 -0.457372           -0.046551         0.186215                  1.087524   
1175 -1.039836            0.229614         0.808683                  0.029358   

      num_contacts_uploaded  residence_risk_zone_baja  \
530               -0.308877                  0.930045   
849                0.981661                 -1.148625   
141               -0.954146                  0.930045   
353                0.175075                 -1.148625   
744                0.013758                 -1.148625   
...                     ...                       ...   
1171               0.051273                  0.768910   
1172               0.262126                  0.705706   
1173              -0.731529                  0.858237   
1174               0.180576                 -0.091570   
1175              -0.147414                  0.930045   

      residence_risk_zone_media  residence_risk_zone_alta  \
530                   -0.687779                 -0.409360   
849                    1.562803                 -0.409360   
141                   -0.687779                 -0.409360   
353                   -0.687779                  2.477064   
744                    1.562803                 -0.409360   
...                         ...                       ...   
1171                  -0.513318                 -0.409360   
1172                  -0.444886                 -0.409360   
1173                  -0.610033                 -0.409360   
1174                   0.418326                 -0.409360   
1175                  -0.687779                 -0.409360   

      political_event_last_month  
530                    -0.418694  
849                    -0.418694  
141                    -0.418694  
353                     2.420111  
744                    -0.418694  
...                          ...  
1171                   -0.418694  
1172                   -0.418694  
1173                   -0.418694  
1174                   -0.418694  
1175                   -0.418694  

[876 rows x 9 columns]
2025-11-17 01:11:01,895:INFO:get_config() successfully completed......................................
2025-11-17 01:16:53,155:INFO:Initializing get_config()
2025-11-17 01:16:53,155:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, variable=X_train_transformed)
2025-11-17 01:16:53,273:INFO:Variable: X_train returned as            age  monthly_income_usd  app_usage_score  digital_profile_strength  \
530  -0.111143           -0.140644        -1.165609                 -1.546579   
849   0.430512           -1.289928         0.957288                  1.836249   
141  -0.343281            0.508270         0.774522                  0.821140   
353   0.430512            0.280368         0.816698                 -0.864285   
744   0.353133            1.200082         0.560123                 -0.319490   
...        ...                 ...              ...                       ...   
1171 -0.748173            1.492517         0.066507                  0.424546   
1172 -0.345501            0.714308         1.231094                  0.278176   
1173 -0.121836            0.044284        -1.572826                 -0.082970   
1174 -0.457372           -0.046551         0.186215                  1.087524   
1175 -1.039836            0.229614         0.808683                  0.029358   

      num_contacts_uploaded  residence_risk_zone_baja  \
530               -0.308877                  0.930045   
849                0.981661                 -1.148625   
141               -0.954146                  0.930045   
353                0.175075                 -1.148625   
744                0.013758                 -1.148625   
...                     ...                       ...   
1171               0.051273                  0.768910   
1172               0.262126                  0.705706   
1173              -0.731529                  0.858237   
1174               0.180576                 -0.091570   
1175              -0.147414                  0.930045   

      residence_risk_zone_media  residence_risk_zone_alta  \
530                   -0.687779                 -0.409360   
849                    1.562803                 -0.409360   
141                   -0.687779                 -0.409360   
353                   -0.687779                  2.477064   
744                    1.562803                 -0.409360   
...                         ...                       ...   
1171                  -0.513318                 -0.409360   
1172                  -0.444886                 -0.409360   
1173                  -0.610033                 -0.409360   
1174                   0.418326                 -0.409360   
1175                  -0.687779                 -0.409360   

      political_event_last_month  
530                    -0.418694  
849                    -0.418694  
141                    -0.418694  
353                     2.420111  
744                    -0.418694  
...                          ...  
1171                   -0.418694  
1172                   -0.418694  
1173                   -0.418694  
1174                   -0.418694  
1175                   -0.418694  

[876 rows x 9 columns]
2025-11-17 01:16:53,278:INFO:get_config() successfully completed......................................
2025-11-17 01:17:09,065:INFO:Initializing get_config()
2025-11-17 01:17:09,065:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023815127690>, variable=X_train_transformed)
2025-11-17 01:17:09,158:INFO:Variable: X_train returned as            age  monthly_income_usd  app_usage_score  digital_profile_strength  \
530  -0.111143           -0.140644        -1.165609                 -1.546579   
849   0.430512           -1.289928         0.957288                  1.836249   
141  -0.343281            0.508270         0.774522                  0.821140   
353   0.430512            0.280368         0.816698                 -0.864285   
744   0.353133            1.200082         0.560123                 -0.319490   
...        ...                 ...              ...                       ...   
1171 -0.748173            1.492517         0.066507                  0.424546   
1172 -0.345501            0.714308         1.231094                  0.278176   
1173 -0.121836            0.044284        -1.572826                 -0.082970   
1174 -0.457372           -0.046551         0.186215                  1.087524   
1175 -1.039836            0.229614         0.808683                  0.029358   

      num_contacts_uploaded  residence_risk_zone_baja  \
530               -0.308877                  0.930045   
849                0.981661                 -1.148625   
141               -0.954146                  0.930045   
353                0.175075                 -1.148625   
744                0.013758                 -1.148625   
...                     ...                       ...   
1171               0.051273                  0.768910   
1172               0.262126                  0.705706   
1173              -0.731529                  0.858237   
1174               0.180576                 -0.091570   
1175              -0.147414                  0.930045   

      residence_risk_zone_media  residence_risk_zone_alta  \
530                   -0.687779                 -0.409360   
849                    1.562803                 -0.409360   
141                   -0.687779                 -0.409360   
353                   -0.687779                  2.477064   
744                    1.562803                 -0.409360   
...                         ...                       ...   
1171                  -0.513318                 -0.409360   
1172                  -0.444886                 -0.409360   
1173                  -0.610033                 -0.409360   
1174                   0.418326                 -0.409360   
1175                  -0.687779                 -0.409360   

      political_event_last_month  
530                    -0.418694  
849                    -0.418694  
141                    -0.418694  
353                     2.420111  
744                    -0.418694  
...                          ...  
1171                   -0.418694  
1172                   -0.418694  
1173                   -0.418694  
1174                   -0.418694  
1175                   -0.418694  

[876 rows x 9 columns]
2025-11-17 01:17:09,158:INFO:get_config() successfully completed......................................
2025-11-17 01:28:37,472:INFO:PyCaret ClassificationExperiment
2025-11-17 01:28:37,472:INFO:Logging name: clf-default-name
2025-11-17 01:28:37,472:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-17 01:28:37,472:INFO:version 3.3.2
2025-11-17 01:28:37,472:INFO:Initializing setup()
2025-11-17 01:28:37,472:INFO:self.USI: 8717
2025-11-17 01:28:37,474:INFO:self._variable_keys: {'y', 'fold_shuffle_param', 'fold_generator', 'log_plots_param', 'X_test', 'gpu_param', 'pipeline', 'gpu_n_jobs_param', 'exp_id', 'y_train', 'fold_groups_param', 'logging_param', 'data', 'is_multiclass', 'html_param', 'y_test', 'target_param', 'seed', 'fix_imbalance', 'memory', '_ml_usecase', 'X', 'idx', '_available_plots', 'exp_name_log', 'X_train', 'n_jobs_param', 'USI'}
2025-11-17 01:28:37,474:INFO:Checking environment
2025-11-17 01:28:37,474:INFO:python_version: 3.11.4
2025-11-17 01:28:37,474:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-17 01:28:37,474:INFO:machine: AMD64
2025-11-17 01:28:37,474:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-17 01:28:37,476:INFO:Memory: svmem(total=8403275776, available=1357926400, percent=83.8, used=7045349376, free=1357926400)
2025-11-17 01:28:37,478:INFO:Physical Core: 4
2025-11-17 01:28:37,478:INFO:Logical Core: 8
2025-11-17 01:28:37,478:INFO:Checking libraries
2025-11-17 01:28:37,478:INFO:System:
2025-11-17 01:28:37,480:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-17 01:28:37,480:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-17 01:28:37,480:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-17 01:28:37,480:INFO:PyCaret required dependencies:
2025-11-17 01:28:37,480:INFO:                 pip: 23.1.2
2025-11-17 01:28:37,480:INFO:          setuptools: 80.9.0
2025-11-17 01:28:37,480:INFO:             pycaret: 3.3.2
2025-11-17 01:28:37,480:INFO:             IPython: 9.6.0
2025-11-17 01:28:37,480:INFO:          ipywidgets: 8.1.7
2025-11-17 01:28:37,484:INFO:                tqdm: 4.67.1
2025-11-17 01:28:37,484:INFO:               numpy: 1.26.4
2025-11-17 01:28:37,484:INFO:              pandas: 2.1.4
2025-11-17 01:28:37,484:INFO:              jinja2: 3.1.6
2025-11-17 01:28:37,484:INFO:               scipy: 1.11.4
2025-11-17 01:28:37,484:INFO:              joblib: 1.3.2
2025-11-17 01:28:37,484:INFO:             sklearn: 1.4.2
2025-11-17 01:28:37,484:INFO:                pyod: 2.0.5
2025-11-17 01:28:37,484:INFO:            imblearn: 0.14.0
2025-11-17 01:28:37,484:INFO:   category_encoders: 2.7.0
2025-11-17 01:28:37,484:INFO:            lightgbm: 4.6.0
2025-11-17 01:28:37,484:INFO:               numba: 0.61.0
2025-11-17 01:28:37,484:INFO:            requests: 2.32.5
2025-11-17 01:28:37,484:INFO:          matplotlib: 3.7.5
2025-11-17 01:28:37,484:INFO:          scikitplot: 0.3.7
2025-11-17 01:28:37,484:INFO:         yellowbrick: 1.5
2025-11-17 01:28:37,484:INFO:              plotly: 5.24.1
2025-11-17 01:28:37,484:INFO:    plotly-resampler: Not installed
2025-11-17 01:28:37,484:INFO:             kaleido: 1.1.0
2025-11-17 01:28:37,484:INFO:           schemdraw: 0.15
2025-11-17 01:28:37,484:INFO:         statsmodels: 0.14.5
2025-11-17 01:28:37,484:INFO:              sktime: 0.26.0
2025-11-17 01:28:37,484:INFO:               tbats: 1.1.3
2025-11-17 01:28:37,484:INFO:            pmdarima: 2.0.4
2025-11-17 01:28:37,484:INFO:              psutil: 7.1.2
2025-11-17 01:28:37,484:INFO:          markupsafe: 3.0.3
2025-11-17 01:28:37,484:INFO:             pickle5: Not installed
2025-11-17 01:28:37,484:INFO:         cloudpickle: 3.1.1
2025-11-17 01:28:37,484:INFO:         deprecation: 2.1.0
2025-11-17 01:28:37,484:INFO:              xxhash: 3.6.0
2025-11-17 01:28:37,484:INFO:           wurlitzer: Not installed
2025-11-17 01:28:37,484:INFO:PyCaret optional dependencies:
2025-11-17 01:28:37,484:INFO:                shap: 0.44.1
2025-11-17 01:28:37,484:INFO:           interpret: 0.7.3
2025-11-17 01:28:37,484:INFO:                umap: 0.5.7
2025-11-17 01:28:37,484:INFO:     ydata_profiling: 4.17.0
2025-11-17 01:28:37,484:INFO:  explainerdashboard: 0.5.1
2025-11-17 01:28:37,484:INFO:             autoviz: Not installed
2025-11-17 01:28:37,484:INFO:           fairlearn: 0.7.0
2025-11-17 01:28:37,484:INFO:          deepchecks: Not installed
2025-11-17 01:28:37,484:INFO:             xgboost: Not installed
2025-11-17 01:28:37,484:INFO:            catboost: Not installed
2025-11-17 01:28:37,484:INFO:              kmodes: Not installed
2025-11-17 01:28:37,484:INFO:             mlxtend: Not installed
2025-11-17 01:28:37,484:INFO:       statsforecast: Not installed
2025-11-17 01:28:37,484:INFO:        tune_sklearn: Not installed
2025-11-17 01:28:37,484:INFO:                 ray: Not installed
2025-11-17 01:28:37,484:INFO:            hyperopt: Not installed
2025-11-17 01:28:37,484:INFO:              optuna: Not installed
2025-11-17 01:28:37,484:INFO:               skopt: Not installed
2025-11-17 01:28:37,484:INFO:              mlflow: 3.5.1
2025-11-17 01:28:37,484:INFO:              gradio: Not installed
2025-11-17 01:28:37,484:INFO:             fastapi: 0.121.0
2025-11-17 01:28:37,484:INFO:             uvicorn: 0.38.0
2025-11-17 01:28:37,484:INFO:              m2cgen: Not installed
2025-11-17 01:28:37,495:INFO:           evidently: Not installed
2025-11-17 01:28:37,495:INFO:               fugue: Not installed
2025-11-17 01:28:37,495:INFO:           streamlit: Not installed
2025-11-17 01:28:37,496:INFO:             prophet: Not installed
2025-11-17 01:28:37,496:INFO:None
2025-11-17 01:28:37,498:INFO:Set up data.
2025-11-17 01:28:37,524:INFO:Set up folding strategy.
2025-11-17 01:28:37,527:INFO:Set up train/test split.
2025-11-17 01:28:37,567:INFO:Set up index.
2025-11-17 01:28:37,567:INFO:Assigning column types.
2025-11-17 01:28:37,584:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-17 01:28:37,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 01:28:37,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 01:28:37,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:37,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 01:28:38,087:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 01:28:38,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,124:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-17 01:28:38,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 01:28:38,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,291:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 01:28:38,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,345:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-17 01:28:38,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:38,603:INFO:Preparing preprocessing pipeline...
2025-11-17 01:28:38,613:INFO:Set up simple imputation.
2025-11-17 01:28:38,613:INFO:Set up encoding of ordinal features.
2025-11-17 01:28:38,613:INFO:Set up encoding of categorical features.
2025-11-17 01:28:38,613:INFO:Set up imbalanced handling.
2025-11-17 01:28:38,613:INFO:Set up feature normalization.
2025-11-17 01:28:38,854:INFO:Finished creating preprocessing pipeline.
2025-11-17 01:28:38,896:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-17 01:28:38,896:INFO:Creating final display dataframe.
2025-11-17 01:28:38,995:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              8717
2025-11-17 01:28:39,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:39,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:39,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:39,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 01:28:39,294:INFO:setup() successfully completed in 2.04s...............
2025-11-17 01:28:39,311:INFO:Initializing compare_models()
2025-11-17 01:28:39,311:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-17 01:28:39,311:INFO:Checking exceptions
2025-11-17 01:28:39,318:INFO:Preparing display monitor
2025-11-17 01:28:39,360:INFO:Initializing Logistic Regression
2025-11-17 01:28:39,360:INFO:Total runtime is 0.0 minutes
2025-11-17 01:28:39,367:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:39,368:INFO:Initializing create_model()
2025-11-17 01:28:39,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:39,368:INFO:Checking exceptions
2025-11-17 01:28:39,370:INFO:Importing libraries
2025-11-17 01:28:39,370:INFO:Copying training dataset
2025-11-17 01:28:39,377:INFO:Defining folds
2025-11-17 01:28:39,377:INFO:Declaring metric variables
2025-11-17 01:28:39,384:INFO:Importing untrained model
2025-11-17 01:28:39,392:INFO:Logistic Regression Imported successfully
2025-11-17 01:28:39,408:INFO:Starting cross validation
2025-11-17 01:28:39,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:51,977:INFO:Calculating mean and std
2025-11-17 01:28:51,977:INFO:Creating metrics dataframe
2025-11-17 01:28:51,977:INFO:Uploading results into container
2025-11-17 01:28:51,977:INFO:Uploading model into container now
2025-11-17 01:28:51,977:INFO:_master_model_container: 1
2025-11-17 01:28:51,977:INFO:_display_container: 2
2025-11-17 01:28:51,989:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-17 01:28:51,989:INFO:create_model() successfully completed......................................
2025-11-17 01:28:53,052:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:53,054:INFO:Creating metrics dataframe
2025-11-17 01:28:53,059:INFO:Initializing K Neighbors Classifier
2025-11-17 01:28:53,059:INFO:Total runtime is 0.22832541863123576 minutes
2025-11-17 01:28:53,074:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:53,074:INFO:Initializing create_model()
2025-11-17 01:28:53,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:53,075:INFO:Checking exceptions
2025-11-17 01:28:53,075:INFO:Importing libraries
2025-11-17 01:28:53,075:INFO:Copying training dataset
2025-11-17 01:28:53,080:INFO:Defining folds
2025-11-17 01:28:53,080:INFO:Declaring metric variables
2025-11-17 01:28:53,087:INFO:Importing untrained model
2025-11-17 01:28:53,092:INFO:K Neighbors Classifier Imported successfully
2025-11-17 01:28:53,109:INFO:Starting cross validation
2025-11-17 01:28:53,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:53,624:INFO:Calculating mean and std
2025-11-17 01:28:53,624:INFO:Creating metrics dataframe
2025-11-17 01:28:53,626:INFO:Uploading results into container
2025-11-17 01:28:53,628:INFO:Uploading model into container now
2025-11-17 01:28:53,628:INFO:_master_model_container: 2
2025-11-17 01:28:53,628:INFO:_display_container: 2
2025-11-17 01:28:53,628:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-17 01:28:53,628:INFO:create_model() successfully completed......................................
2025-11-17 01:28:53,807:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:53,807:INFO:Creating metrics dataframe
2025-11-17 01:28:53,819:INFO:Initializing Naive Bayes
2025-11-17 01:28:53,819:INFO:Total runtime is 0.2409798542658488 minutes
2025-11-17 01:28:53,826:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:53,826:INFO:Initializing create_model()
2025-11-17 01:28:53,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:53,828:INFO:Checking exceptions
2025-11-17 01:28:53,828:INFO:Importing libraries
2025-11-17 01:28:53,829:INFO:Copying training dataset
2025-11-17 01:28:53,838:INFO:Defining folds
2025-11-17 01:28:53,838:INFO:Declaring metric variables
2025-11-17 01:28:53,851:INFO:Importing untrained model
2025-11-17 01:28:53,860:INFO:Naive Bayes Imported successfully
2025-11-17 01:28:53,877:INFO:Starting cross validation
2025-11-17 01:28:53,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:54,378:INFO:Calculating mean and std
2025-11-17 01:28:54,380:INFO:Creating metrics dataframe
2025-11-17 01:28:54,384:INFO:Uploading results into container
2025-11-17 01:28:54,385:INFO:Uploading model into container now
2025-11-17 01:28:54,386:INFO:_master_model_container: 3
2025-11-17 01:28:54,386:INFO:_display_container: 2
2025-11-17 01:28:54,387:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-17 01:28:54,387:INFO:create_model() successfully completed......................................
2025-11-17 01:28:54,584:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:54,584:INFO:Creating metrics dataframe
2025-11-17 01:28:54,602:INFO:Initializing Decision Tree Classifier
2025-11-17 01:28:54,603:INFO:Total runtime is 0.2540523926417033 minutes
2025-11-17 01:28:54,607:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:54,607:INFO:Initializing create_model()
2025-11-17 01:28:54,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:54,607:INFO:Checking exceptions
2025-11-17 01:28:54,607:INFO:Importing libraries
2025-11-17 01:28:54,607:INFO:Copying training dataset
2025-11-17 01:28:54,618:INFO:Defining folds
2025-11-17 01:28:54,618:INFO:Declaring metric variables
2025-11-17 01:28:54,627:INFO:Importing untrained model
2025-11-17 01:28:54,633:INFO:Decision Tree Classifier Imported successfully
2025-11-17 01:28:54,641:INFO:Starting cross validation
2025-11-17 01:28:54,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:55,225:INFO:Calculating mean and std
2025-11-17 01:28:55,225:INFO:Creating metrics dataframe
2025-11-17 01:28:55,225:INFO:Uploading results into container
2025-11-17 01:28:55,230:INFO:Uploading model into container now
2025-11-17 01:28:55,230:INFO:_master_model_container: 4
2025-11-17 01:28:55,230:INFO:_display_container: 2
2025-11-17 01:28:55,230:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-17 01:28:55,233:INFO:create_model() successfully completed......................................
2025-11-17 01:28:55,421:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:55,421:INFO:Creating metrics dataframe
2025-11-17 01:28:55,437:INFO:Initializing SVM - Linear Kernel
2025-11-17 01:28:55,437:INFO:Total runtime is 0.267955489953359 minutes
2025-11-17 01:28:55,447:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:55,447:INFO:Initializing create_model()
2025-11-17 01:28:55,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:55,451:INFO:Checking exceptions
2025-11-17 01:28:55,451:INFO:Importing libraries
2025-11-17 01:28:55,451:INFO:Copying training dataset
2025-11-17 01:28:55,461:INFO:Defining folds
2025-11-17 01:28:55,461:INFO:Declaring metric variables
2025-11-17 01:28:55,474:INFO:Importing untrained model
2025-11-17 01:28:55,485:INFO:SVM - Linear Kernel Imported successfully
2025-11-17 01:28:55,501:INFO:Starting cross validation
2025-11-17 01:28:55,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:55,921:INFO:Calculating mean and std
2025-11-17 01:28:55,921:INFO:Creating metrics dataframe
2025-11-17 01:28:55,924:INFO:Uploading results into container
2025-11-17 01:28:55,925:INFO:Uploading model into container now
2025-11-17 01:28:55,925:INFO:_master_model_container: 5
2025-11-17 01:28:55,925:INFO:_display_container: 2
2025-11-17 01:28:55,926:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-17 01:28:55,926:INFO:create_model() successfully completed......................................
2025-11-17 01:28:56,242:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:56,248:INFO:Creating metrics dataframe
2025-11-17 01:28:56,284:INFO:Initializing Ridge Classifier
2025-11-17 01:28:56,285:INFO:Total runtime is 0.2820632259051005 minutes
2025-11-17 01:28:56,299:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:56,299:INFO:Initializing create_model()
2025-11-17 01:28:56,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:56,302:INFO:Checking exceptions
2025-11-17 01:28:56,302:INFO:Importing libraries
2025-11-17 01:28:56,302:INFO:Copying training dataset
2025-11-17 01:28:56,324:INFO:Defining folds
2025-11-17 01:28:56,325:INFO:Declaring metric variables
2025-11-17 01:28:56,340:INFO:Importing untrained model
2025-11-17 01:28:56,357:INFO:Ridge Classifier Imported successfully
2025-11-17 01:28:56,389:INFO:Starting cross validation
2025-11-17 01:28:56,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:56,894:INFO:Calculating mean and std
2025-11-17 01:28:56,894:INFO:Creating metrics dataframe
2025-11-17 01:28:56,901:INFO:Uploading results into container
2025-11-17 01:28:56,902:INFO:Uploading model into container now
2025-11-17 01:28:56,902:INFO:_master_model_container: 6
2025-11-17 01:28:56,902:INFO:_display_container: 2
2025-11-17 01:28:56,902:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-17 01:28:56,902:INFO:create_model() successfully completed......................................
2025-11-17 01:28:57,154:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:57,154:INFO:Creating metrics dataframe
2025-11-17 01:28:57,170:INFO:Initializing Random Forest Classifier
2025-11-17 01:28:57,170:INFO:Total runtime is 0.2968378225962321 minutes
2025-11-17 01:28:57,186:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:57,186:INFO:Initializing create_model()
2025-11-17 01:28:57,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:57,187:INFO:Checking exceptions
2025-11-17 01:28:57,187:INFO:Importing libraries
2025-11-17 01:28:57,187:INFO:Copying training dataset
2025-11-17 01:28:57,213:INFO:Defining folds
2025-11-17 01:28:57,214:INFO:Declaring metric variables
2025-11-17 01:28:57,222:INFO:Importing untrained model
2025-11-17 01:28:57,242:INFO:Random Forest Classifier Imported successfully
2025-11-17 01:28:57,268:INFO:Starting cross validation
2025-11-17 01:28:57,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:58,378:INFO:Calculating mean and std
2025-11-17 01:28:58,380:INFO:Creating metrics dataframe
2025-11-17 01:28:58,385:INFO:Uploading results into container
2025-11-17 01:28:58,385:INFO:Uploading model into container now
2025-11-17 01:28:58,387:INFO:_master_model_container: 7
2025-11-17 01:28:58,387:INFO:_display_container: 2
2025-11-17 01:28:58,387:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-17 01:28:58,389:INFO:create_model() successfully completed......................................
2025-11-17 01:28:58,634:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:58,634:INFO:Creating metrics dataframe
2025-11-17 01:28:58,654:INFO:Initializing Quadratic Discriminant Analysis
2025-11-17 01:28:58,656:INFO:Total runtime is 0.3215967853864034 minutes
2025-11-17 01:28:58,662:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:58,662:INFO:Initializing create_model()
2025-11-17 01:28:58,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:58,662:INFO:Checking exceptions
2025-11-17 01:28:58,662:INFO:Importing libraries
2025-11-17 01:28:58,662:INFO:Copying training dataset
2025-11-17 01:28:58,672:INFO:Defining folds
2025-11-17 01:28:58,672:INFO:Declaring metric variables
2025-11-17 01:28:58,680:INFO:Importing untrained model
2025-11-17 01:28:58,683:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-17 01:28:58,710:INFO:Starting cross validation
2025-11-17 01:28:58,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:58,887:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:58,889:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:58,889:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:58,889:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:58,898:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:58,909:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:59,038:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:59,041:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 01:28:59,088:INFO:Calculating mean and std
2025-11-17 01:28:59,090:INFO:Creating metrics dataframe
2025-11-17 01:28:59,090:INFO:Uploading results into container
2025-11-17 01:28:59,090:INFO:Uploading model into container now
2025-11-17 01:28:59,098:INFO:_master_model_container: 8
2025-11-17 01:28:59,098:INFO:_display_container: 2
2025-11-17 01:28:59,099:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-17 01:28:59,099:INFO:create_model() successfully completed......................................
2025-11-17 01:28:59,344:INFO:SubProcess create_model() end ==================================
2025-11-17 01:28:59,344:INFO:Creating metrics dataframe
2025-11-17 01:28:59,366:INFO:Initializing Ada Boost Classifier
2025-11-17 01:28:59,366:INFO:Total runtime is 0.3334348479906718 minutes
2025-11-17 01:28:59,375:INFO:SubProcess create_model() called ==================================
2025-11-17 01:28:59,375:INFO:Initializing create_model()
2025-11-17 01:28:59,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:28:59,376:INFO:Checking exceptions
2025-11-17 01:28:59,376:INFO:Importing libraries
2025-11-17 01:28:59,376:INFO:Copying training dataset
2025-11-17 01:28:59,388:INFO:Defining folds
2025-11-17 01:28:59,388:INFO:Declaring metric variables
2025-11-17 01:28:59,401:INFO:Importing untrained model
2025-11-17 01:28:59,408:INFO:Ada Boost Classifier Imported successfully
2025-11-17 01:28:59,428:INFO:Starting cross validation
2025-11-17 01:28:59,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:28:59,639:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,641:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,641:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,650:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,652:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,662:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,671:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:28:59,673:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:29:00,052:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:29:00,052:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 01:29:00,233:INFO:Calculating mean and std
2025-11-17 01:29:00,233:INFO:Creating metrics dataframe
2025-11-17 01:29:00,233:INFO:Uploading results into container
2025-11-17 01:29:00,233:INFO:Uploading model into container now
2025-11-17 01:29:00,233:INFO:_master_model_container: 9
2025-11-17 01:29:00,233:INFO:_display_container: 2
2025-11-17 01:29:00,233:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 01:29:00,233:INFO:create_model() successfully completed......................................
2025-11-17 01:29:00,439:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:00,442:INFO:Creating metrics dataframe
2025-11-17 01:29:00,464:INFO:Initializing Gradient Boosting Classifier
2025-11-17 01:29:00,464:INFO:Total runtime is 0.35173574288686116 minutes
2025-11-17 01:29:00,471:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:00,472:INFO:Initializing create_model()
2025-11-17 01:29:00,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:00,474:INFO:Checking exceptions
2025-11-17 01:29:00,474:INFO:Importing libraries
2025-11-17 01:29:00,474:INFO:Copying training dataset
2025-11-17 01:29:00,484:INFO:Defining folds
2025-11-17 01:29:00,484:INFO:Declaring metric variables
2025-11-17 01:29:00,492:INFO:Importing untrained model
2025-11-17 01:29:00,502:INFO:Gradient Boosting Classifier Imported successfully
2025-11-17 01:29:00,524:INFO:Starting cross validation
2025-11-17 01:29:00,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:01,674:INFO:Calculating mean and std
2025-11-17 01:29:01,678:INFO:Creating metrics dataframe
2025-11-17 01:29:01,682:INFO:Uploading results into container
2025-11-17 01:29:01,683:INFO:Uploading model into container now
2025-11-17 01:29:01,683:INFO:_master_model_container: 10
2025-11-17 01:29:01,683:INFO:_display_container: 2
2025-11-17 01:29:01,688:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-17 01:29:01,688:INFO:create_model() successfully completed......................................
2025-11-17 01:29:01,935:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:01,944:INFO:Creating metrics dataframe
2025-11-17 01:29:01,970:INFO:Initializing Linear Discriminant Analysis
2025-11-17 01:29:01,970:INFO:Total runtime is 0.3768408377965291 minutes
2025-11-17 01:29:01,977:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:01,977:INFO:Initializing create_model()
2025-11-17 01:29:01,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:01,977:INFO:Checking exceptions
2025-11-17 01:29:01,979:INFO:Importing libraries
2025-11-17 01:29:01,979:INFO:Copying training dataset
2025-11-17 01:29:01,991:INFO:Defining folds
2025-11-17 01:29:01,991:INFO:Declaring metric variables
2025-11-17 01:29:01,999:INFO:Importing untrained model
2025-11-17 01:29:02,006:INFO:Linear Discriminant Analysis Imported successfully
2025-11-17 01:29:02,023:INFO:Starting cross validation
2025-11-17 01:29:02,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:02,442:INFO:Calculating mean and std
2025-11-17 01:29:02,446:INFO:Creating metrics dataframe
2025-11-17 01:29:02,451:INFO:Uploading results into container
2025-11-17 01:29:02,452:INFO:Uploading model into container now
2025-11-17 01:29:02,454:INFO:_master_model_container: 11
2025-11-17 01:29:02,454:INFO:_display_container: 2
2025-11-17 01:29:02,454:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-17 01:29:02,454:INFO:create_model() successfully completed......................................
2025-11-17 01:29:02,695:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:02,695:INFO:Creating metrics dataframe
2025-11-17 01:29:02,716:INFO:Initializing Extra Trees Classifier
2025-11-17 01:29:02,716:INFO:Total runtime is 0.389276123046875 minutes
2025-11-17 01:29:02,728:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:02,728:INFO:Initializing create_model()
2025-11-17 01:29:02,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:02,728:INFO:Checking exceptions
2025-11-17 01:29:02,728:INFO:Importing libraries
2025-11-17 01:29:02,729:INFO:Copying training dataset
2025-11-17 01:29:02,738:INFO:Defining folds
2025-11-17 01:29:02,738:INFO:Declaring metric variables
2025-11-17 01:29:02,749:INFO:Importing untrained model
2025-11-17 01:29:02,760:INFO:Extra Trees Classifier Imported successfully
2025-11-17 01:29:02,778:INFO:Starting cross validation
2025-11-17 01:29:02,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:03,825:INFO:Calculating mean and std
2025-11-17 01:29:03,827:INFO:Creating metrics dataframe
2025-11-17 01:29:03,829:INFO:Uploading results into container
2025-11-17 01:29:03,830:INFO:Uploading model into container now
2025-11-17 01:29:03,831:INFO:_master_model_container: 12
2025-11-17 01:29:03,831:INFO:_display_container: 2
2025-11-17 01:29:03,831:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-17 01:29:03,831:INFO:create_model() successfully completed......................................
2025-11-17 01:29:04,165:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:04,167:INFO:Creating metrics dataframe
2025-11-17 01:29:04,192:INFO:Initializing Light Gradient Boosting Machine
2025-11-17 01:29:04,192:INFO:Total runtime is 0.4138679464658101 minutes
2025-11-17 01:29:04,202:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:04,202:INFO:Initializing create_model()
2025-11-17 01:29:04,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:04,202:INFO:Checking exceptions
2025-11-17 01:29:04,202:INFO:Importing libraries
2025-11-17 01:29:04,202:INFO:Copying training dataset
2025-11-17 01:29:04,214:INFO:Defining folds
2025-11-17 01:29:04,214:INFO:Declaring metric variables
2025-11-17 01:29:04,220:INFO:Importing untrained model
2025-11-17 01:29:04,234:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 01:29:04,254:INFO:Starting cross validation
2025-11-17 01:29:04,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:05,641:INFO:Calculating mean and std
2025-11-17 01:29:05,643:INFO:Creating metrics dataframe
2025-11-17 01:29:05,647:INFO:Uploading results into container
2025-11-17 01:29:05,649:INFO:Uploading model into container now
2025-11-17 01:29:05,649:INFO:_master_model_container: 13
2025-11-17 01:29:05,649:INFO:_display_container: 2
2025-11-17 01:29:05,653:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 01:29:05,653:INFO:create_model() successfully completed......................................
2025-11-17 01:29:05,838:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:05,838:INFO:Creating metrics dataframe
2025-11-17 01:29:05,849:INFO:Initializing Dummy Classifier
2025-11-17 01:29:05,849:INFO:Total runtime is 0.44148679971694943 minutes
2025-11-17 01:29:05,866:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:05,866:INFO:Initializing create_model()
2025-11-17 01:29:05,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821604910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:05,868:INFO:Checking exceptions
2025-11-17 01:29:05,868:INFO:Importing libraries
2025-11-17 01:29:05,868:INFO:Copying training dataset
2025-11-17 01:29:05,879:INFO:Defining folds
2025-11-17 01:29:05,879:INFO:Declaring metric variables
2025-11-17 01:29:05,889:INFO:Importing untrained model
2025-11-17 01:29:05,899:INFO:Dummy Classifier Imported successfully
2025-11-17 01:29:05,916:INFO:Starting cross validation
2025-11-17 01:29:05,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:06,210:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,213:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,213:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,217:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,226:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,232:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,234:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,240:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,330:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,332:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 01:29:06,346:INFO:Calculating mean and std
2025-11-17 01:29:06,347:INFO:Creating metrics dataframe
2025-11-17 01:29:06,349:INFO:Uploading results into container
2025-11-17 01:29:06,350:INFO:Uploading model into container now
2025-11-17 01:29:06,350:INFO:_master_model_container: 14
2025-11-17 01:29:06,350:INFO:_display_container: 2
2025-11-17 01:29:06,350:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-17 01:29:06,350:INFO:create_model() successfully completed......................................
2025-11-17 01:29:06,544:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:06,544:INFO:Creating metrics dataframe
2025-11-17 01:29:06,575:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-17 01:29:06,599:INFO:Initializing create_model()
2025-11-17 01:29:06,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:06,599:INFO:Checking exceptions
2025-11-17 01:29:06,604:INFO:Importing libraries
2025-11-17 01:29:06,604:INFO:Copying training dataset
2025-11-17 01:29:06,615:INFO:Defining folds
2025-11-17 01:29:06,615:INFO:Declaring metric variables
2025-11-17 01:29:06,615:INFO:Importing untrained model
2025-11-17 01:29:06,615:INFO:Declaring custom model
2025-11-17 01:29:06,619:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 01:29:06,623:INFO:Cross validation set to False
2025-11-17 01:29:06,623:INFO:Fitting Model
2025-11-17 01:29:06,796:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 01:29:06,798:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2025-11-17 01:29:06,798:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-17 01:29:06,798:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 01:29:06,798:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 01:29:06,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 01:29:06,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:06,970:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 01:29:06,970:INFO:create_model() successfully completed......................................
2025-11-17 01:29:07,321:INFO:_master_model_container: 14
2025-11-17 01:29:07,321:INFO:_display_container: 2
2025-11-17 01:29:07,328:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 01:29:07,329:INFO:compare_models() successfully completed......................................
2025-11-17 01:29:07,441:INFO:Initializing tune_model()
2025-11-17 01:29:07,444:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 01:29:07,445:INFO:Checking exceptions
2025-11-17 01:29:07,523:INFO:Copying training dataset
2025-11-17 01:29:07,539:INFO:Checking base model
2025-11-17 01:29:07,539:INFO:Base model : Light Gradient Boosting Machine
2025-11-17 01:29:07,592:INFO:Declaring metric variables
2025-11-17 01:29:07,610:INFO:Defining Hyperparameters
2025-11-17 01:29:07,902:INFO:Tuning with n_jobs=-1
2025-11-17 01:29:07,902:INFO:Initializing RandomizedSearchCV
2025-11-17 01:29:15,863:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2025-11-17 01:29:15,865:INFO:Hyperparameter search completed
2025-11-17 01:29:15,865:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:15,867:INFO:Initializing create_model()
2025-11-17 01:29:15,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381ED32ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2025-11-17 01:29:15,868:INFO:Checking exceptions
2025-11-17 01:29:15,868:INFO:Importing libraries
2025-11-17 01:29:15,869:INFO:Copying training dataset
2025-11-17 01:29:15,878:INFO:Defining folds
2025-11-17 01:29:15,880:INFO:Declaring metric variables
2025-11-17 01:29:15,884:INFO:Importing untrained model
2025-11-17 01:29:15,884:INFO:Declaring custom model
2025-11-17 01:29:15,893:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 01:29:15,903:INFO:Starting cross validation
2025-11-17 01:29:15,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:16,884:INFO:Calculating mean and std
2025-11-17 01:29:16,886:INFO:Creating metrics dataframe
2025-11-17 01:29:16,896:INFO:Finalizing model
2025-11-17 01:29:16,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2025-11-17 01:29:16,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-11-17 01:29:16,974:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-17 01:29:16,986:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2025-11-17 01:29:16,986:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-11-17 01:29:16,986:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-17 01:29:16,986:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 01:29:16,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.
2025-11-17 01:29:16,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-17 01:29:16,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-17 01:29:16,988:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 01:29:16,988:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 01:29:16,989:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 01:29:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:17,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 01:29:17,077:INFO:Uploading results into container
2025-11-17 01:29:17,079:INFO:Uploading model into container now
2025-11-17 01:29:17,079:INFO:_master_model_container: 15
2025-11-17 01:29:17,079:INFO:_display_container: 3
2025-11-17 01:29:17,081:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 01:29:17,081:INFO:create_model() successfully completed......................................
2025-11-17 01:29:17,292:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:17,292:INFO:choose_better activated
2025-11-17 01:29:17,308:INFO:SubProcess create_model() called ==================================
2025-11-17 01:29:17,308:INFO:Initializing create_model()
2025-11-17 01:29:17,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 01:29:17,308:INFO:Checking exceptions
2025-11-17 01:29:17,316:INFO:Importing libraries
2025-11-17 01:29:17,316:INFO:Copying training dataset
2025-11-17 01:29:17,329:INFO:Defining folds
2025-11-17 01:29:17,329:INFO:Declaring metric variables
2025-11-17 01:29:17,329:INFO:Importing untrained model
2025-11-17 01:29:17,329:INFO:Declaring custom model
2025-11-17 01:29:17,333:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 01:29:17,333:INFO:Starting cross validation
2025-11-17 01:29:17,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 01:29:18,852:INFO:Calculating mean and std
2025-11-17 01:29:18,852:INFO:Creating metrics dataframe
2025-11-17 01:29:18,855:INFO:Finalizing model
2025-11-17 01:29:18,935:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 01:29:18,935:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-11-17 01:29:18,935:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-17 01:29:18,935:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 01:29:18,935:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 01:29:18,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 01:29:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:18,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 01:29:19,002:INFO:Uploading results into container
2025-11-17 01:29:19,002:INFO:Uploading model into container now
2025-11-17 01:29:19,004:INFO:_master_model_container: 16
2025-11-17 01:29:19,004:INFO:_display_container: 4
2025-11-17 01:29:19,004:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 01:29:19,004:INFO:create_model() successfully completed......................................
2025-11-17 01:29:19,207:INFO:SubProcess create_model() end ==================================
2025-11-17 01:29:19,207:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.981
2025-11-17 01:29:19,207:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.9924
2025-11-17 01:29:19,207:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-17 01:29:19,207:INFO:choose_better completed
2025-11-17 01:29:19,223:INFO:_master_model_container: 16
2025-11-17 01:29:19,223:INFO:_display_container: 3
2025-11-17 01:29:19,235:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 01:29:19,235:INFO:tune_model() successfully completed......................................
2025-11-17 01:29:19,622:INFO:Initializing get_config()
2025-11-17 01:29:19,623:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023821504450>, variable=X_train_transformed)
2025-11-17 01:29:19,703:INFO:Variable: X_train returned as            age  monthly_income_usd  app_usage_score  digital_profile_strength  \
530  -0.111143           -0.140644        -1.165609                 -1.546579   
849   0.430512           -1.289928         0.957288                  1.836249   
141  -0.343281            0.508270         0.774522                  0.821140   
353   0.430512            0.280368         0.816698                 -0.864285   
744   0.353133            1.200082         0.560123                 -0.319490   
...        ...                 ...              ...                       ...   
1171 -0.748173            1.492517         0.066507                  0.424546   
1172 -0.345501            0.714308         1.231094                  0.278176   
1173 -0.121836            0.044284        -1.572826                 -0.082970   
1174 -0.457372           -0.046551         0.186215                  1.087524   
1175 -1.039836            0.229614         0.808683                  0.029358   

      num_contacts_uploaded  residence_risk_zone_baja  \
530               -0.308877                  0.930045   
849                0.981661                 -1.148625   
141               -0.954146                  0.930045   
353                0.175075                 -1.148625   
744                0.013758                 -1.148625   
...                     ...                       ...   
1171               0.051273                  0.768910   
1172               0.262126                  0.705706   
1173              -0.731529                  0.858237   
1174               0.180576                 -0.091570   
1175              -0.147414                  0.930045   

      residence_risk_zone_media  residence_risk_zone_alta  \
530                   -0.687779                 -0.409360   
849                    1.562803                 -0.409360   
141                   -0.687779                 -0.409360   
353                   -0.687779                  2.477064   
744                    1.562803                 -0.409360   
...                         ...                       ...   
1171                  -0.513318                 -0.409360   
1172                  -0.444886                 -0.409360   
1173                  -0.610033                 -0.409360   
1174                   0.418326                 -0.409360   
1175                  -0.687779                 -0.409360   

      political_event_last_month  
530                    -0.418694  
849                    -0.418694  
141                    -0.418694  
353                     2.420111  
744                    -0.418694  
...                          ...  
1171                   -0.418694  
1172                   -0.418694  
1173                   -0.418694  
1174                   -0.418694  
1175                   -0.418694  

[876 rows x 9 columns]
2025-11-17 01:29:19,703:INFO:get_config() successfully completed......................................
2025-11-17 01:29:19,806:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\shap\explainers\_tree.py:429: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray

2025-11-17 20:32:28,709:INFO:PyCaret ClassificationExperiment
2025-11-17 20:32:28,709:INFO:Logging name: clf-default-name
2025-11-17 20:32:28,709:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-17 20:32:28,709:INFO:version 3.3.2
2025-11-17 20:32:28,709:INFO:Initializing setup()
2025-11-17 20:32:28,709:INFO:self.USI: 1dce
2025-11-17 20:32:28,709:INFO:self._variable_keys: {'y', 'fold_shuffle_param', 'fold_generator', 'log_plots_param', 'X_test', 'gpu_param', 'pipeline', 'gpu_n_jobs_param', 'exp_id', 'y_train', 'fold_groups_param', 'logging_param', 'data', 'is_multiclass', 'html_param', 'y_test', 'target_param', 'seed', 'fix_imbalance', 'memory', '_ml_usecase', 'X', 'idx', '_available_plots', 'exp_name_log', 'X_train', 'n_jobs_param', 'USI'}
2025-11-17 20:32:28,718:INFO:Checking environment
2025-11-17 20:32:28,718:INFO:python_version: 3.11.4
2025-11-17 20:32:28,718:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-11-17 20:32:28,718:INFO:machine: AMD64
2025-11-17 20:32:28,718:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-17 20:32:28,726:INFO:Memory: svmem(total=8403275776, available=986714112, percent=88.3, used=7416561664, free=986714112)
2025-11-17 20:32:28,726:INFO:Physical Core: 4
2025-11-17 20:32:28,731:INFO:Logical Core: 8
2025-11-17 20:32:28,731:INFO:Checking libraries
2025-11-17 20:32:28,737:INFO:System:
2025-11-17 20:32:28,740:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-11-17 20:32:28,740:INFO:executable: c:\Users\serge\AppData\Local\Programs\Python\Python311\python.exe
2025-11-17 20:32:28,741:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-17 20:32:28,741:INFO:PyCaret required dependencies:
2025-11-17 20:32:28,749:INFO:                 pip: 23.1.2
2025-11-17 20:32:28,749:INFO:          setuptools: 80.9.0
2025-11-17 20:32:28,749:INFO:             pycaret: 3.3.2
2025-11-17 20:32:28,751:INFO:             IPython: 9.6.0
2025-11-17 20:32:28,751:INFO:          ipywidgets: 8.1.7
2025-11-17 20:32:28,751:INFO:                tqdm: 4.67.1
2025-11-17 20:32:28,751:INFO:               numpy: 1.26.4
2025-11-17 20:32:28,751:INFO:              pandas: 2.1.4
2025-11-17 20:32:28,751:INFO:              jinja2: 3.1.6
2025-11-17 20:32:28,751:INFO:               scipy: 1.11.4
2025-11-17 20:32:28,754:INFO:              joblib: 1.3.2
2025-11-17 20:32:28,754:INFO:             sklearn: 1.4.2
2025-11-17 20:32:28,754:INFO:                pyod: 2.0.5
2025-11-17 20:32:28,754:INFO:            imblearn: 0.14.0
2025-11-17 20:32:28,754:INFO:   category_encoders: 2.7.0
2025-11-17 20:32:28,754:INFO:            lightgbm: 4.6.0
2025-11-17 20:32:28,754:INFO:               numba: 0.61.0
2025-11-17 20:32:28,756:INFO:            requests: 2.32.5
2025-11-17 20:32:28,756:INFO:          matplotlib: 3.7.5
2025-11-17 20:32:28,756:INFO:          scikitplot: 0.3.7
2025-11-17 20:32:28,756:INFO:         yellowbrick: 1.5
2025-11-17 20:32:28,756:INFO:              plotly: 5.24.1
2025-11-17 20:32:28,756:INFO:    plotly-resampler: Not installed
2025-11-17 20:32:28,756:INFO:             kaleido: 1.1.0
2025-11-17 20:32:28,756:INFO:           schemdraw: 0.15
2025-11-17 20:32:28,756:INFO:         statsmodels: 0.14.5
2025-11-17 20:32:28,756:INFO:              sktime: 0.26.0
2025-11-17 20:32:28,760:INFO:               tbats: 1.1.3
2025-11-17 20:32:28,760:INFO:            pmdarima: 2.0.4
2025-11-17 20:32:28,760:INFO:              psutil: 7.1.2
2025-11-17 20:32:28,760:INFO:          markupsafe: 3.0.3
2025-11-17 20:32:28,760:INFO:             pickle5: Not installed
2025-11-17 20:32:28,760:INFO:         cloudpickle: 3.1.1
2025-11-17 20:32:28,760:INFO:         deprecation: 2.1.0
2025-11-17 20:32:28,760:INFO:              xxhash: 3.6.0
2025-11-17 20:32:28,760:INFO:           wurlitzer: Not installed
2025-11-17 20:32:28,760:INFO:PyCaret optional dependencies:
2025-11-17 20:32:28,768:INFO:                shap: 0.44.1
2025-11-17 20:32:28,768:INFO:           interpret: 0.7.3
2025-11-17 20:32:28,770:INFO:                umap: 0.5.7
2025-11-17 20:32:28,770:INFO:     ydata_profiling: 4.17.0
2025-11-17 20:32:28,770:INFO:  explainerdashboard: 0.5.1
2025-11-17 20:32:28,770:INFO:             autoviz: Not installed
2025-11-17 20:32:28,772:INFO:           fairlearn: 0.7.0
2025-11-17 20:32:28,773:INFO:          deepchecks: Not installed
2025-11-17 20:32:28,773:INFO:             xgboost: Not installed
2025-11-17 20:32:28,773:INFO:            catboost: Not installed
2025-11-17 20:32:28,773:INFO:              kmodes: Not installed
2025-11-17 20:32:28,773:INFO:             mlxtend: Not installed
2025-11-17 20:32:28,773:INFO:       statsforecast: Not installed
2025-11-17 20:32:28,775:INFO:        tune_sklearn: Not installed
2025-11-17 20:32:28,775:INFO:                 ray: Not installed
2025-11-17 20:32:28,775:INFO:            hyperopt: Not installed
2025-11-17 20:32:28,775:INFO:              optuna: Not installed
2025-11-17 20:32:28,775:INFO:               skopt: Not installed
2025-11-17 20:32:28,775:INFO:              mlflow: 3.5.1
2025-11-17 20:32:28,775:INFO:              gradio: Not installed
2025-11-17 20:32:28,775:INFO:             fastapi: 0.121.0
2025-11-17 20:32:28,778:INFO:             uvicorn: 0.38.0
2025-11-17 20:32:28,778:INFO:              m2cgen: Not installed
2025-11-17 20:32:28,778:INFO:           evidently: Not installed
2025-11-17 20:32:28,778:INFO:               fugue: Not installed
2025-11-17 20:32:28,778:INFO:           streamlit: Not installed
2025-11-17 20:32:28,778:INFO:             prophet: Not installed
2025-11-17 20:32:28,780:INFO:None
2025-11-17 20:32:28,783:INFO:Set up data.
2025-11-17 20:32:28,836:INFO:Set up folding strategy.
2025-11-17 20:32:28,845:INFO:Set up train/test split.
2025-11-17 20:32:28,954:INFO:Set up index.
2025-11-17 20:32:28,956:INFO:Assigning column types.
2025-11-17 20:32:28,978:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-17 20:32:29,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 20:32:29,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 20:32:29,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:29,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:29,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-17 20:32:29,711:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 20:32:29,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:29,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:29,846:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-17 20:32:30,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 20:32:30,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,369:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-17 20:32:30,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,532:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-17 20:32:30,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:30,972:INFO:Preparing preprocessing pipeline...
2025-11-17 20:32:30,979:INFO:Set up simple imputation.
2025-11-17 20:32:30,987:INFO:Set up encoding of ordinal features.
2025-11-17 20:32:31,000:INFO:Set up encoding of categorical features.
2025-11-17 20:32:31,000:INFO:Set up imbalanced handling.
2025-11-17 20:32:31,002:INFO:Set up feature normalization.
2025-11-17 20:32:31,401:INFO:Finished creating preprocessing pipeline.
2025-11-17 20:32:31,468:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\serge\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'monthly_income_usd',
                                             'app_usage_score',
                                             'digital_profile_strength',
                                             'num_contacts_uploaded'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-11-17 20:32:31,468:INFO:Creating final display dataframe.
2025-11-17 20:32:31,669:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          approved
2                   Target type            Binary
3           Original data shape         (1000, 9)
4        Transformed data shape        (1176, 10)
5   Transformed train set shape         (876, 10)
6    Transformed test set shape         (300, 10)
7               Ignore features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              1dce
2025-11-17 20:32:31,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:31,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:32,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:32,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-17 20:32:32,122:INFO:setup() successfully completed in 4.2s...............
2025-11-17 20:32:32,324:INFO:Initializing compare_models()
2025-11-17 20:32:32,326:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-17 20:32:32,326:INFO:Checking exceptions
2025-11-17 20:32:32,333:INFO:Preparing display monitor
2025-11-17 20:32:32,464:INFO:Initializing Logistic Regression
2025-11-17 20:32:32,465:INFO:Total runtime is 2.518892288208008e-05 minutes
2025-11-17 20:32:32,477:INFO:SubProcess create_model() called ==================================
2025-11-17 20:32:32,480:INFO:Initializing create_model()
2025-11-17 20:32:32,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:32:32,480:INFO:Checking exceptions
2025-11-17 20:32:32,480:INFO:Importing libraries
2025-11-17 20:32:32,483:INFO:Copying training dataset
2025-11-17 20:32:32,494:INFO:Defining folds
2025-11-17 20:32:32,494:INFO:Declaring metric variables
2025-11-17 20:32:32,506:INFO:Importing untrained model
2025-11-17 20:32:32,512:INFO:Logistic Regression Imported successfully
2025-11-17 20:32:32,528:INFO:Starting cross validation
2025-11-17 20:32:32,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:23,114:INFO:Calculating mean and std
2025-11-17 20:33:23,123:INFO:Creating metrics dataframe
2025-11-17 20:33:23,137:INFO:Uploading results into container
2025-11-17 20:33:23,141:INFO:Uploading model into container now
2025-11-17 20:33:23,145:INFO:_master_model_container: 1
2025-11-17 20:33:23,146:INFO:_display_container: 2
2025-11-17 20:33:23,148:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-17 20:33:23,148:INFO:create_model() successfully completed......................................
2025-11-17 20:33:26,838:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:26,838:INFO:Creating metrics dataframe
2025-11-17 20:33:26,854:INFO:Initializing K Neighbors Classifier
2025-11-17 20:33:26,866:INFO:Total runtime is 0.9065053343772888 minutes
2025-11-17 20:33:26,873:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:26,873:INFO:Initializing create_model()
2025-11-17 20:33:26,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:26,873:INFO:Checking exceptions
2025-11-17 20:33:26,873:INFO:Importing libraries
2025-11-17 20:33:26,873:INFO:Copying training dataset
2025-11-17 20:33:26,885:INFO:Defining folds
2025-11-17 20:33:26,885:INFO:Declaring metric variables
2025-11-17 20:33:26,893:INFO:Importing untrained model
2025-11-17 20:33:26,901:INFO:K Neighbors Classifier Imported successfully
2025-11-17 20:33:26,913:INFO:Starting cross validation
2025-11-17 20:33:26,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:27,526:INFO:Calculating mean and std
2025-11-17 20:33:27,526:INFO:Creating metrics dataframe
2025-11-17 20:33:27,536:INFO:Uploading results into container
2025-11-17 20:33:27,537:INFO:Uploading model into container now
2025-11-17 20:33:27,537:INFO:_master_model_container: 2
2025-11-17 20:33:27,537:INFO:_display_container: 2
2025-11-17 20:33:27,540:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-17 20:33:27,540:INFO:create_model() successfully completed......................................
2025-11-17 20:33:27,798:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:27,798:INFO:Creating metrics dataframe
2025-11-17 20:33:27,823:INFO:Initializing Naive Bayes
2025-11-17 20:33:27,823:INFO:Total runtime is 0.9226489861806233 minutes
2025-11-17 20:33:27,834:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:27,836:INFO:Initializing create_model()
2025-11-17 20:33:27,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:27,836:INFO:Checking exceptions
2025-11-17 20:33:27,838:INFO:Importing libraries
2025-11-17 20:33:27,838:INFO:Copying training dataset
2025-11-17 20:33:27,855:INFO:Defining folds
2025-11-17 20:33:27,857:INFO:Declaring metric variables
2025-11-17 20:33:27,866:INFO:Importing untrained model
2025-11-17 20:33:27,876:INFO:Naive Bayes Imported successfully
2025-11-17 20:33:27,891:INFO:Starting cross validation
2025-11-17 20:33:27,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:28,480:INFO:Calculating mean and std
2025-11-17 20:33:28,484:INFO:Creating metrics dataframe
2025-11-17 20:33:28,490:INFO:Uploading results into container
2025-11-17 20:33:28,492:INFO:Uploading model into container now
2025-11-17 20:33:28,492:INFO:_master_model_container: 3
2025-11-17 20:33:28,492:INFO:_display_container: 2
2025-11-17 20:33:28,492:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-17 20:33:28,492:INFO:create_model() successfully completed......................................
2025-11-17 20:33:28,874:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:28,879:INFO:Creating metrics dataframe
2025-11-17 20:33:28,898:INFO:Initializing Decision Tree Classifier
2025-11-17 20:33:28,898:INFO:Total runtime is 0.9405746459960936 minutes
2025-11-17 20:33:28,907:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:28,907:INFO:Initializing create_model()
2025-11-17 20:33:28,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:28,907:INFO:Checking exceptions
2025-11-17 20:33:28,907:INFO:Importing libraries
2025-11-17 20:33:28,907:INFO:Copying training dataset
2025-11-17 20:33:28,926:INFO:Defining folds
2025-11-17 20:33:28,926:INFO:Declaring metric variables
2025-11-17 20:33:28,940:INFO:Importing untrained model
2025-11-17 20:33:28,959:INFO:Decision Tree Classifier Imported successfully
2025-11-17 20:33:28,978:INFO:Starting cross validation
2025-11-17 20:33:28,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:29,609:INFO:Calculating mean and std
2025-11-17 20:33:29,609:INFO:Creating metrics dataframe
2025-11-17 20:33:29,620:INFO:Uploading results into container
2025-11-17 20:33:29,622:INFO:Uploading model into container now
2025-11-17 20:33:29,625:INFO:_master_model_container: 4
2025-11-17 20:33:29,625:INFO:_display_container: 2
2025-11-17 20:33:29,625:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-17 20:33:29,625:INFO:create_model() successfully completed......................................
2025-11-17 20:33:29,879:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:29,881:INFO:Creating metrics dataframe
2025-11-17 20:33:29,909:INFO:Initializing SVM - Linear Kernel
2025-11-17 20:33:29,909:INFO:Total runtime is 0.9574199000994363 minutes
2025-11-17 20:33:29,924:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:29,924:INFO:Initializing create_model()
2025-11-17 20:33:29,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:29,926:INFO:Checking exceptions
2025-11-17 20:33:29,926:INFO:Importing libraries
2025-11-17 20:33:29,926:INFO:Copying training dataset
2025-11-17 20:33:29,946:INFO:Defining folds
2025-11-17 20:33:29,946:INFO:Declaring metric variables
2025-11-17 20:33:29,968:INFO:Importing untrained model
2025-11-17 20:33:29,982:INFO:SVM - Linear Kernel Imported successfully
2025-11-17 20:33:29,991:INFO:Starting cross validation
2025-11-17 20:33:30,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:30,687:INFO:Calculating mean and std
2025-11-17 20:33:30,687:INFO:Creating metrics dataframe
2025-11-17 20:33:30,695:INFO:Uploading results into container
2025-11-17 20:33:30,695:INFO:Uploading model into container now
2025-11-17 20:33:30,701:INFO:_master_model_container: 5
2025-11-17 20:33:30,701:INFO:_display_container: 2
2025-11-17 20:33:30,702:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-17 20:33:30,702:INFO:create_model() successfully completed......................................
2025-11-17 20:33:31,205:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:31,205:INFO:Creating metrics dataframe
2025-11-17 20:33:31,250:INFO:Initializing Ridge Classifier
2025-11-17 20:33:31,250:INFO:Total runtime is 0.9797743717829386 minutes
2025-11-17 20:33:31,277:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:31,277:INFO:Initializing create_model()
2025-11-17 20:33:31,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:31,277:INFO:Checking exceptions
2025-11-17 20:33:31,277:INFO:Importing libraries
2025-11-17 20:33:31,277:INFO:Copying training dataset
2025-11-17 20:33:31,293:INFO:Defining folds
2025-11-17 20:33:31,293:INFO:Declaring metric variables
2025-11-17 20:33:31,326:INFO:Importing untrained model
2025-11-17 20:33:31,342:INFO:Ridge Classifier Imported successfully
2025-11-17 20:33:31,383:INFO:Starting cross validation
2025-11-17 20:33:31,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:32,086:INFO:Calculating mean and std
2025-11-17 20:33:32,088:INFO:Creating metrics dataframe
2025-11-17 20:33:32,088:INFO:Uploading results into container
2025-11-17 20:33:32,088:INFO:Uploading model into container now
2025-11-17 20:33:32,088:INFO:_master_model_container: 6
2025-11-17 20:33:32,088:INFO:_display_container: 2
2025-11-17 20:33:32,088:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-17 20:33:32,088:INFO:create_model() successfully completed......................................
2025-11-17 20:33:32,327:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:32,327:INFO:Creating metrics dataframe
2025-11-17 20:33:32,343:INFO:Initializing Random Forest Classifier
2025-11-17 20:33:32,343:INFO:Total runtime is 0.9979846755663553 minutes
2025-11-17 20:33:32,351:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:32,351:INFO:Initializing create_model()
2025-11-17 20:33:32,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:32,351:INFO:Checking exceptions
2025-11-17 20:33:32,351:INFO:Importing libraries
2025-11-17 20:33:32,351:INFO:Copying training dataset
2025-11-17 20:33:32,358:INFO:Defining folds
2025-11-17 20:33:32,358:INFO:Declaring metric variables
2025-11-17 20:33:32,374:INFO:Importing untrained model
2025-11-17 20:33:32,382:INFO:Random Forest Classifier Imported successfully
2025-11-17 20:33:32,399:INFO:Starting cross validation
2025-11-17 20:33:32,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:34,538:INFO:Calculating mean and std
2025-11-17 20:33:34,544:INFO:Creating metrics dataframe
2025-11-17 20:33:34,553:INFO:Uploading results into container
2025-11-17 20:33:34,560:INFO:Uploading model into container now
2025-11-17 20:33:34,560:INFO:_master_model_container: 7
2025-11-17 20:33:34,560:INFO:_display_container: 2
2025-11-17 20:33:34,560:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-17 20:33:34,567:INFO:create_model() successfully completed......................................
2025-11-17 20:33:34,883:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:34,883:INFO:Creating metrics dataframe
2025-11-17 20:33:34,900:INFO:Initializing Quadratic Discriminant Analysis
2025-11-17 20:33:34,900:INFO:Total runtime is 1.040609041849772 minutes
2025-11-17 20:33:34,916:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:34,916:INFO:Initializing create_model()
2025-11-17 20:33:34,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:34,916:INFO:Checking exceptions
2025-11-17 20:33:34,916:INFO:Importing libraries
2025-11-17 20:33:34,916:INFO:Copying training dataset
2025-11-17 20:33:34,933:INFO:Defining folds
2025-11-17 20:33:34,933:INFO:Declaring metric variables
2025-11-17 20:33:34,947:INFO:Importing untrained model
2025-11-17 20:33:34,954:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-17 20:33:34,979:INFO:Starting cross validation
2025-11-17 20:33:34,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:35,254:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,254:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,254:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,254:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,254:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,254:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,526:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-17 20:33:35,613:INFO:Calculating mean and std
2025-11-17 20:33:35,615:INFO:Creating metrics dataframe
2025-11-17 20:33:35,621:INFO:Uploading results into container
2025-11-17 20:33:35,621:INFO:Uploading model into container now
2025-11-17 20:33:35,621:INFO:_master_model_container: 8
2025-11-17 20:33:35,621:INFO:_display_container: 2
2025-11-17 20:33:35,621:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-17 20:33:35,621:INFO:create_model() successfully completed......................................
2025-11-17 20:33:35,896:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:35,896:INFO:Creating metrics dataframe
2025-11-17 20:33:35,917:INFO:Initializing Ada Boost Classifier
2025-11-17 20:33:35,917:INFO:Total runtime is 1.057555556297302 minutes
2025-11-17 20:33:35,928:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:35,928:INFO:Initializing create_model()
2025-11-17 20:33:35,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:35,928:INFO:Checking exceptions
2025-11-17 20:33:35,928:INFO:Importing libraries
2025-11-17 20:33:35,928:INFO:Copying training dataset
2025-11-17 20:33:35,944:INFO:Defining folds
2025-11-17 20:33:35,944:INFO:Declaring metric variables
2025-11-17 20:33:35,953:INFO:Importing untrained model
2025-11-17 20:33:35,964:INFO:Ada Boost Classifier Imported successfully
2025-11-17 20:33:35,985:INFO:Starting cross validation
2025-11-17 20:33:35,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:36,321:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:36,321:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:36,341:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:36,342:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:36,351:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:36,950:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:36,955:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-17 20:33:37,551:INFO:Calculating mean and std
2025-11-17 20:33:37,554:INFO:Creating metrics dataframe
2025-11-17 20:33:37,566:INFO:Uploading results into container
2025-11-17 20:33:37,569:INFO:Uploading model into container now
2025-11-17 20:33:37,574:INFO:_master_model_container: 9
2025-11-17 20:33:37,574:INFO:_display_container: 2
2025-11-17 20:33:37,576:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-17 20:33:37,576:INFO:create_model() successfully completed......................................
2025-11-17 20:33:37,929:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:37,929:INFO:Creating metrics dataframe
2025-11-17 20:33:37,949:INFO:Initializing Gradient Boosting Classifier
2025-11-17 20:33:37,949:INFO:Total runtime is 1.0914206504821775 minutes
2025-11-17 20:33:37,960:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:37,962:INFO:Initializing create_model()
2025-11-17 20:33:37,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:37,962:INFO:Checking exceptions
2025-11-17 20:33:37,962:INFO:Importing libraries
2025-11-17 20:33:37,962:INFO:Copying training dataset
2025-11-17 20:33:37,971:INFO:Defining folds
2025-11-17 20:33:37,971:INFO:Declaring metric variables
2025-11-17 20:33:37,981:INFO:Importing untrained model
2025-11-17 20:33:37,992:INFO:Gradient Boosting Classifier Imported successfully
2025-11-17 20:33:38,021:INFO:Starting cross validation
2025-11-17 20:33:38,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:40,186:INFO:Calculating mean and std
2025-11-17 20:33:40,193:INFO:Creating metrics dataframe
2025-11-17 20:33:40,204:INFO:Uploading results into container
2025-11-17 20:33:40,209:INFO:Uploading model into container now
2025-11-17 20:33:40,212:INFO:_master_model_container: 10
2025-11-17 20:33:40,214:INFO:_display_container: 2
2025-11-17 20:33:40,214:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-17 20:33:40,217:INFO:create_model() successfully completed......................................
2025-11-17 20:33:40,574:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:40,574:INFO:Creating metrics dataframe
2025-11-17 20:33:40,600:INFO:Initializing Linear Discriminant Analysis
2025-11-17 20:33:40,600:INFO:Total runtime is 1.1356084863344826 minutes
2025-11-17 20:33:40,613:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:40,613:INFO:Initializing create_model()
2025-11-17 20:33:40,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:40,615:INFO:Checking exceptions
2025-11-17 20:33:40,615:INFO:Importing libraries
2025-11-17 20:33:40,615:INFO:Copying training dataset
2025-11-17 20:33:40,627:INFO:Defining folds
2025-11-17 20:33:40,627:INFO:Declaring metric variables
2025-11-17 20:33:40,635:INFO:Importing untrained model
2025-11-17 20:33:40,652:INFO:Linear Discriminant Analysis Imported successfully
2025-11-17 20:33:40,668:INFO:Starting cross validation
2025-11-17 20:33:40,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:41,321:INFO:Calculating mean and std
2025-11-17 20:33:41,321:INFO:Creating metrics dataframe
2025-11-17 20:33:41,331:INFO:Uploading results into container
2025-11-17 20:33:41,331:INFO:Uploading model into container now
2025-11-17 20:33:41,337:INFO:_master_model_container: 11
2025-11-17 20:33:41,337:INFO:_display_container: 2
2025-11-17 20:33:41,337:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-17 20:33:41,337:INFO:create_model() successfully completed......................................
2025-11-17 20:33:41,799:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:41,799:INFO:Creating metrics dataframe
2025-11-17 20:33:41,825:INFO:Initializing Extra Trees Classifier
2025-11-17 20:33:41,825:INFO:Total runtime is 1.156015634536743 minutes
2025-11-17 20:33:41,833:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:41,833:INFO:Initializing create_model()
2025-11-17 20:33:41,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:41,841:INFO:Checking exceptions
2025-11-17 20:33:41,841:INFO:Importing libraries
2025-11-17 20:33:41,841:INFO:Copying training dataset
2025-11-17 20:33:41,854:INFO:Defining folds
2025-11-17 20:33:41,856:INFO:Declaring metric variables
2025-11-17 20:33:41,865:INFO:Importing untrained model
2025-11-17 20:33:41,874:INFO:Extra Trees Classifier Imported successfully
2025-11-17 20:33:41,899:INFO:Starting cross validation
2025-11-17 20:33:41,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:44,305:INFO:Calculating mean and std
2025-11-17 20:33:44,314:INFO:Creating metrics dataframe
2025-11-17 20:33:44,314:INFO:Uploading results into container
2025-11-17 20:33:44,322:INFO:Uploading model into container now
2025-11-17 20:33:44,322:INFO:_master_model_container: 12
2025-11-17 20:33:44,322:INFO:_display_container: 2
2025-11-17 20:33:44,327:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-17 20:33:44,330:INFO:create_model() successfully completed......................................
2025-11-17 20:33:44,883:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:44,883:INFO:Creating metrics dataframe
2025-11-17 20:33:44,945:INFO:Initializing Light Gradient Boosting Machine
2025-11-17 20:33:44,950:INFO:Total runtime is 1.2081132173538205 minutes
2025-11-17 20:33:44,978:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:44,980:INFO:Initializing create_model()
2025-11-17 20:33:44,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:44,980:INFO:Checking exceptions
2025-11-17 20:33:44,980:INFO:Importing libraries
2025-11-17 20:33:44,980:INFO:Copying training dataset
2025-11-17 20:33:45,011:INFO:Defining folds
2025-11-17 20:33:45,011:INFO:Declaring metric variables
2025-11-17 20:33:45,031:INFO:Importing untrained model
2025-11-17 20:33:45,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 20:33:45,110:INFO:Starting cross validation
2025-11-17 20:33:45,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:47,908:INFO:Calculating mean and std
2025-11-17 20:33:47,912:INFO:Creating metrics dataframe
2025-11-17 20:33:47,921:INFO:Uploading results into container
2025-11-17 20:33:47,928:INFO:Uploading model into container now
2025-11-17 20:33:47,928:INFO:_master_model_container: 13
2025-11-17 20:33:47,928:INFO:_display_container: 2
2025-11-17 20:33:47,930:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:33:47,930:INFO:create_model() successfully completed......................................
2025-11-17 20:33:48,359:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:48,359:INFO:Creating metrics dataframe
2025-11-17 20:33:48,498:INFO:Initializing Dummy Classifier
2025-11-17 20:33:48,500:INFO:Total runtime is 1.2672807256380714 minutes
2025-11-17 20:33:48,529:INFO:SubProcess create_model() called ==================================
2025-11-17 20:33:48,531:INFO:Initializing create_model()
2025-11-17 20:33:48,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381C397450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:48,532:INFO:Checking exceptions
2025-11-17 20:33:48,532:INFO:Importing libraries
2025-11-17 20:33:48,532:INFO:Copying training dataset
2025-11-17 20:33:48,550:INFO:Defining folds
2025-11-17 20:33:48,550:INFO:Declaring metric variables
2025-11-17 20:33:48,566:INFO:Importing untrained model
2025-11-17 20:33:48,577:INFO:Dummy Classifier Imported successfully
2025-11-17 20:33:48,594:INFO:Starting cross validation
2025-11-17 20:33:48,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:33:48,994:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:48,996:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:48,996:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:48,998:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,023:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,033:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,035:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,047:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,232:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,238:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-17 20:33:49,263:INFO:Calculating mean and std
2025-11-17 20:33:49,263:INFO:Creating metrics dataframe
2025-11-17 20:33:49,271:INFO:Uploading results into container
2025-11-17 20:33:49,271:INFO:Uploading model into container now
2025-11-17 20:33:49,271:INFO:_master_model_container: 14
2025-11-17 20:33:49,271:INFO:_display_container: 2
2025-11-17 20:33:49,271:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-17 20:33:49,271:INFO:create_model() successfully completed......................................
2025-11-17 20:33:49,697:INFO:SubProcess create_model() end ==================================
2025-11-17 20:33:49,697:INFO:Creating metrics dataframe
2025-11-17 20:33:49,759:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-11-17 20:33:49,810:INFO:Initializing create_model()
2025-11-17 20:33:49,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:33:49,816:INFO:Checking exceptions
2025-11-17 20:33:49,825:INFO:Importing libraries
2025-11-17 20:33:49,825:INFO:Copying training dataset
2025-11-17 20:33:49,850:INFO:Defining folds
2025-11-17 20:33:49,850:INFO:Declaring metric variables
2025-11-17 20:33:49,850:INFO:Importing untrained model
2025-11-17 20:33:49,850:INFO:Declaring custom model
2025-11-17 20:33:49,858:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 20:33:49,863:INFO:Cross validation set to False
2025-11-17 20:33:49,863:INFO:Fitting Model
2025-11-17 20:33:50,163:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 20:33:50,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.
2025-11-17 20:33:50,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-17 20:33:50,168:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 20:33:50,171:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 20:33:50,171:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 20:33:50,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:33:50,405:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:33:50,406:INFO:create_model() successfully completed......................................
2025-11-17 20:33:50,933:INFO:_master_model_container: 14
2025-11-17 20:33:50,933:INFO:_display_container: 2
2025-11-17 20:33:50,939:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:33:50,941:INFO:compare_models() successfully completed......................................
2025-11-17 20:33:51,085:INFO:Initializing tune_model()
2025-11-17 20:33:51,085:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 20:33:51,089:INFO:Checking exceptions
2025-11-17 20:33:51,217:INFO:Copying training dataset
2025-11-17 20:33:51,233:INFO:Checking base model
2025-11-17 20:33:51,234:INFO:Base model : Light Gradient Boosting Machine
2025-11-17 20:33:51,264:INFO:Declaring metric variables
2025-11-17 20:33:51,297:INFO:Defining Hyperparameters
2025-11-17 20:33:51,646:INFO:Tuning with n_jobs=-1
2025-11-17 20:33:51,646:INFO:Initializing RandomizedSearchCV
2025-11-17 20:34:06,450:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2025-11-17 20:34:06,452:INFO:Hyperparameter search completed
2025-11-17 20:34:06,452:INFO:SubProcess create_model() called ==================================
2025-11-17 20:34:06,454:INFO:Initializing create_model()
2025-11-17 20:34:06,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023821518290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2025-11-17 20:34:06,456:INFO:Checking exceptions
2025-11-17 20:34:06,456:INFO:Importing libraries
2025-11-17 20:34:06,456:INFO:Copying training dataset
2025-11-17 20:34:06,474:INFO:Defining folds
2025-11-17 20:34:06,474:INFO:Declaring metric variables
2025-11-17 20:34:06,481:INFO:Importing untrained model
2025-11-17 20:34:06,483:INFO:Declaring custom model
2025-11-17 20:34:06,501:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 20:34:06,519:INFO:Starting cross validation
2025-11-17 20:34:06,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:34:07,996:INFO:Calculating mean and std
2025-11-17 20:34:07,997:INFO:Creating metrics dataframe
2025-11-17 20:34:08,011:INFO:Finalizing model
2025-11-17 20:34:08,125:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2025-11-17 20:34:08,125:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-11-17 20:34:08,125:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-17 20:34:08,130:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2025-11-17 20:34:08,130:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-11-17 20:34:08,130:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-17 20:34:08,130:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 20:34:08,133:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.
2025-11-17 20:34:08,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-17 20:34:08,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-17 20:34:08,133:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 20:34:08,133:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 20:34:08,133:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 20:34:08,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:08,243:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:34:08,267:INFO:Uploading results into container
2025-11-17 20:34:08,270:INFO:Uploading model into container now
2025-11-17 20:34:08,270:INFO:_master_model_container: 15
2025-11-17 20:34:08,270:INFO:_display_container: 3
2025-11-17 20:34:08,272:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:34:08,273:INFO:create_model() successfully completed......................................
2025-11-17 20:34:08,534:INFO:SubProcess create_model() end ==================================
2025-11-17 20:34:08,534:INFO:choose_better activated
2025-11-17 20:34:08,542:INFO:SubProcess create_model() called ==================================
2025-11-17 20:34:08,542:INFO:Initializing create_model()
2025-11-17 20:34:08,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:34:08,547:INFO:Checking exceptions
2025-11-17 20:34:08,550:INFO:Importing libraries
2025-11-17 20:34:08,550:INFO:Copying training dataset
2025-11-17 20:34:08,558:INFO:Defining folds
2025-11-17 20:34:08,558:INFO:Declaring metric variables
2025-11-17 20:34:08,558:INFO:Importing untrained model
2025-11-17 20:34:08,558:INFO:Declaring custom model
2025-11-17 20:34:08,563:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 20:34:08,563:INFO:Starting cross validation
2025-11-17 20:34:08,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:34:10,605:INFO:Calculating mean and std
2025-11-17 20:34:10,605:INFO:Creating metrics dataframe
2025-11-17 20:34:10,609:INFO:Finalizing model
2025-11-17 20:34:10,702:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 20:34:10,706:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2025-11-17 20:34:10,706:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-17 20:34:10,706:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 20:34:10,706:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 20:34:10,706:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 20:34:10,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:34:10,832:INFO:Uploading results into container
2025-11-17 20:34:10,834:INFO:Uploading model into container now
2025-11-17 20:34:10,835:INFO:_master_model_container: 16
2025-11-17 20:34:10,835:INFO:_display_container: 4
2025-11-17 20:34:10,835:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:34:10,835:INFO:create_model() successfully completed......................................
2025-11-17 20:34:11,042:INFO:SubProcess create_model() end ==================================
2025-11-17 20:34:11,042:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.981
2025-11-17 20:34:11,050:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.9924
2025-11-17 20:34:11,051:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-17 20:34:11,051:INFO:choose_better completed
2025-11-17 20:34:11,067:INFO:_master_model_container: 16
2025-11-17 20:34:11,067:INFO:_display_container: 3
2025-11-17 20:34:11,067:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:34:11,067:INFO:tune_model() successfully completed......................................
2025-11-17 20:34:11,383:INFO:Initializing get_config()
2025-11-17 20:34:11,389:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, variable=X_train_transformed)
2025-11-17 20:34:11,489:INFO:Variable: X_train returned as            age  monthly_income_usd  app_usage_score  digital_profile_strength  \
530  -0.111143           -0.140644        -1.165609                 -1.546579   
849   0.430512           -1.289928         0.957288                  1.836249   
141  -0.343281            0.508270         0.774522                  0.821140   
353   0.430512            0.280368         0.816698                 -0.864285   
744   0.353133            1.200082         0.560123                 -0.319490   
...        ...                 ...              ...                       ...   
1171 -0.748173            1.492517         0.066507                  0.424546   
1172 -0.345501            0.714308         1.231094                  0.278176   
1173 -0.121836            0.044284        -1.572826                 -0.082970   
1174 -0.457372           -0.046551         0.186215                  1.087524   
1175 -1.039836            0.229614         0.808683                  0.029358   

      num_contacts_uploaded  residence_risk_zone_baja  \
530               -0.308877                  0.930045   
849                0.981661                 -1.148625   
141               -0.954146                  0.930045   
353                0.175075                 -1.148625   
744                0.013758                 -1.148625   
...                     ...                       ...   
1171               0.051273                  0.768910   
1172               0.262126                  0.705706   
1173              -0.731529                  0.858237   
1174               0.180576                 -0.091570   
1175              -0.147414                  0.930045   

      residence_risk_zone_media  residence_risk_zone_alta  \
530                   -0.687779                 -0.409360   
849                    1.562803                 -0.409360   
141                   -0.687779                 -0.409360   
353                   -0.687779                  2.477064   
744                    1.562803                 -0.409360   
...                         ...                       ...   
1171                  -0.513318                 -0.409360   
1172                  -0.444886                 -0.409360   
1173                  -0.610033                 -0.409360   
1174                   0.418326                 -0.409360   
1175                  -0.687779                 -0.409360   

      political_event_last_month  
530                    -0.418694  
849                    -0.418694  
141                    -0.418694  
353                     2.420111  
744                    -0.418694  
...                          ...  
1171                   -0.418694  
1172                   -0.418694  
1173                   -0.418694  
1174                   -0.418694  
1175                   -0.418694  

[876 rows x 9 columns]
2025-11-17 20:34:11,489:INFO:get_config() successfully completed......................................
2025-11-17 20:34:11,603:WARNING:c:\Users\serge\AppData\Local\Programs\Python\Python311\Lib\site-packages\shap\explainers\_tree.py:429: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray

2025-11-17 20:34:53,963:INFO:Initializing tune_model()
2025-11-17 20:34:53,963:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-17 20:34:53,963:INFO:Checking exceptions
2025-11-17 20:34:54,023:INFO:Copying training dataset
2025-11-17 20:34:54,032:INFO:Checking base model
2025-11-17 20:34:54,032:INFO:Base model : Light Gradient Boosting Machine
2025-11-17 20:34:54,040:INFO:Declaring metric variables
2025-11-17 20:34:54,049:INFO:Defining Hyperparameters
2025-11-17 20:34:54,383:INFO:Tuning with n_jobs=-1
2025-11-17 20:34:54,383:INFO:Initializing RandomizedSearchCV
2025-11-17 20:35:05,321:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2025-11-17 20:35:05,323:INFO:Hyperparameter search completed
2025-11-17 20:35:05,323:INFO:SubProcess create_model() called ==================================
2025-11-17 20:35:05,327:INFO:Initializing create_model()
2025-11-17 20:35:05,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002381EDFC450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2025-11-17 20:35:05,328:INFO:Checking exceptions
2025-11-17 20:35:05,328:INFO:Importing libraries
2025-11-17 20:35:05,328:INFO:Copying training dataset
2025-11-17 20:35:05,342:INFO:Defining folds
2025-11-17 20:35:05,344:INFO:Declaring metric variables
2025-11-17 20:35:05,355:INFO:Importing untrained model
2025-11-17 20:35:05,355:INFO:Declaring custom model
2025-11-17 20:35:05,369:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 20:35:05,389:INFO:Starting cross validation
2025-11-17 20:35:05,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:35:07,039:INFO:Calculating mean and std
2025-11-17 20:35:07,043:INFO:Creating metrics dataframe
2025-11-17 20:35:07,059:INFO:Finalizing model
2025-11-17 20:35:07,198:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2025-11-17 20:35:07,198:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-11-17 20:35:07,198:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-17 20:35:07,200:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2025-11-17 20:35:07,200:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-11-17 20:35:07,200:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-17 20:35:07,202:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 20:35:07,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.
2025-11-17 20:35:07,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-17 20:35:07,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-17 20:35:07,202:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 20:35:07,202:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 20:35:07,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 20:35:07,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,252:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:07,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-17 20:35:07,377:INFO:Uploading results into container
2025-11-17 20:35:07,380:INFO:Uploading model into container now
2025-11-17 20:35:07,382:INFO:_master_model_container: 17
2025-11-17 20:35:07,382:INFO:_display_container: 4
2025-11-17 20:35:07,385:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:35:07,385:INFO:create_model() successfully completed......................................
2025-11-17 20:35:07,650:INFO:SubProcess create_model() end ==================================
2025-11-17 20:35:07,650:INFO:choose_better activated
2025-11-17 20:35:07,663:INFO:SubProcess create_model() called ==================================
2025-11-17 20:35:07,666:INFO:Initializing create_model()
2025-11-17 20:35:07,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002381E6D52D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-17 20:35:07,666:INFO:Checking exceptions
2025-11-17 20:35:07,666:INFO:Importing libraries
2025-11-17 20:35:07,666:INFO:Copying training dataset
2025-11-17 20:35:07,685:INFO:Defining folds
2025-11-17 20:35:07,685:INFO:Declaring metric variables
2025-11-17 20:35:07,685:INFO:Importing untrained model
2025-11-17 20:35:07,687:INFO:Declaring custom model
2025-11-17 20:35:07,689:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-17 20:35:07,692:INFO:Starting cross validation
2025-11-17 20:35:07,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-17 20:35:10,074:INFO:Calculating mean and std
2025-11-17 20:35:10,076:INFO:Creating metrics dataframe
2025-11-17 20:35:10,081:INFO:Finalizing model
2025-11-17 20:35:10,205:INFO:[LightGBM] [Info] Number of positive: 438, number of negative: 438
2025-11-17 20:35:10,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-11-17 20:35:10,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-17 20:35:10,205:INFO:[LightGBM] [Info] Total Bins 1002
2025-11-17 20:35:10,205:INFO:[LightGBM] [Info] Number of data points in the train set: 876, number of used features: 9
2025-11-17 20:35:10,207:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-17 20:35:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-17 20:35:10,346:INFO:Uploading results into container
2025-11-17 20:35:10,346:INFO:Uploading model into container now
2025-11-17 20:35:10,348:INFO:_master_model_container: 18
2025-11-17 20:35:10,349:INFO:_display_container: 5
2025-11-17 20:35:10,351:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:35:10,351:INFO:create_model() successfully completed......................................
2025-11-17 20:35:10,596:INFO:SubProcess create_model() end ==================================
2025-11-17 20:35:10,602:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.981
2025-11-17 20:35:10,602:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.9924
2025-11-17 20:35:10,602:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-17 20:35:10,602:INFO:choose_better completed
2025-11-17 20:35:10,635:INFO:_master_model_container: 18
2025-11-17 20:35:10,637:INFO:_display_container: 4
2025-11-17 20:35:10,637:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-17 20:35:10,637:INFO:tune_model() successfully completed......................................
